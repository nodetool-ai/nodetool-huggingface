{
  "name": "nodetool-huggingface",
  "description": "HuggingFace nodes for Nodetool",
  "version": "0.6.2-rc.6",
  "authors": [
    "Matthias Georgi <matti.georgi@gmail.com>"
  ],
  "repo_id": "",
  "nodes": [
    {
      "title": "LoRA Selector",
      "description": "Selects up to 5 LoRA models to apply to a Stable Diffusion model.\n    lora, model customization, fine-tuning, SD\n\n    Use cases:\n    - Combining multiple LoRA models for unique image styles\n    - Fine-tuning Stable Diffusion models with specific attributes\n    - Experimenting with different LoRA combinations",
      "namespace": "huggingface.lora",
      "node_type": "huggingface.lora.LoRASelector",
      "properties": [
        {
          "name": "lora1",
          "type": {
            "type": "hf.lora_sd"
          },
          "default": {
            "type": "hf.lora_sd",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Lora1",
          "description": "First LoRA model"
        },
        {
          "name": "strength1",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength1",
          "description": "Strength for first LoRA",
          "min": 0.0,
          "max": 2.0
        },
        {
          "name": "lora2",
          "type": {
            "type": "hf.lora_sd"
          },
          "default": {
            "type": "hf.lora_sd",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Lora2",
          "description": "Second LoRA model"
        },
        {
          "name": "strength2",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength2",
          "description": "Strength for second LoRA",
          "min": 0.0,
          "max": 2.0
        },
        {
          "name": "lora3",
          "type": {
            "type": "hf.lora_sd"
          },
          "default": {
            "type": "hf.lora_sd",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Lora3",
          "description": "Third LoRA model"
        },
        {
          "name": "strength3",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength3",
          "description": "Strength for third LoRA",
          "min": 0.0,
          "max": 2.0
        },
        {
          "name": "lora4",
          "type": {
            "type": "hf.lora_sd"
          },
          "default": {
            "type": "hf.lora_sd",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Lora4",
          "description": "Fourth LoRA model"
        },
        {
          "name": "strength4",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength4",
          "description": "Strength for fourth LoRA",
          "min": 0.0,
          "max": 2.0
        },
        {
          "name": "lora5",
          "type": {
            "type": "hf.lora_sd"
          },
          "default": {
            "type": "hf.lora_sd",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Lora5",
          "description": "Fifth LoRA model"
        },
        {
          "name": "strength5",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength5",
          "description": "Strength for fifth LoRA",
          "min": 0.0,
          "max": 2.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "hf.lora_sd_config"
              }
            ]
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "danbrown/loras:2d_sprite.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "2d_sprite.safetensors",
          "size_on_disk": 37863537,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:ghibli_scenery.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "ghibli_scenery.safetensors",
          "size_on_disk": 151111762,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:add_detail.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "add_detail.safetensors",
          "size_on_disk": 37861176,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:colorwater.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "colorwater.safetensors",
          "size_on_disk": 151111114,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:sxz_game_assets.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "sxz_game_assets.safetensors",
          "size_on_disk": 151114099,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:3Danaglyph.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "3Danaglyph.safetensors",
          "size_on_disk": 151108831,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:akiratoriyama_style.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "akiratoriyama_style.safetensors",
          "size_on_disk": 302069805,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:animeoutlineV4.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "animeoutlineV4.safetensors",
          "size_on_disk": 18986312,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:aqua_konosuba.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "aqua_konosuba.safetensors",
          "size_on_disk": 151074560,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:arakihirohiko_style.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "arakihirohiko_style.safetensors",
          "size_on_disk": 78025834,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:arcane_style.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "arcane_style.safetensors",
          "size_on_disk": 302104229,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:canetaazul.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "canetaazul.safetensors",
          "size_on_disk": 151109011,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:cyberpunk_tarot.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "cyberpunk_tarot.safetensors",
          "size_on_disk": 151125126,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:discoelysium_style.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "discoelysium_style.safetensors",
          "size_on_disk": 151112313,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:esdeath_akamegakill.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "esdeath_akamegakill.safetensors",
          "size_on_disk": 236046182,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:fire_vfx.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "fire_vfx.safetensors",
          "size_on_disk": 172342464,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:flamingeye.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "flamingeye.safetensors",
          "size_on_disk": 151121110,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:funnycreatures.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "funnycreatures.safetensors",
          "size_on_disk": 151108831,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:gacha_splash.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "gacha_splash.safetensors",
          "size_on_disk": 151126110,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:gigachad.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "gigachad.safetensors",
          "size_on_disk": 151111885,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:gyokai_style.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "gyokai_style.safetensors",
          "size_on_disk": 151125722,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:harold.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "harold.safetensors",
          "size_on_disk": 75613063,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:hiderohoribes_style.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "hiderohoribes_style.safetensors",
          "size_on_disk": 26031740,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:ilyakuvshinov_style.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "ilyakuvshinov_style.safetensors",
          "size_on_disk": 37881890,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:jacksparrow.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "jacksparrow.safetensors",
          "size_on_disk": 151108831,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:jimlee_style.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "jimlee_style.safetensors",
          "size_on_disk": 151108831,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:komowataharuka_chibiart.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "komowataharuka_chibiart.safetensors",
          "size_on_disk": 151130160,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:lightning_vfx.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "lightning_vfx.safetensors",
          "size_on_disk": 80330354,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:lucy_cyberpunk.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "lucy_cyberpunk.safetensors",
          "size_on_disk": 151074558,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:luisap_pixelart.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "luisap_pixelart.safetensors",
          "size_on_disk": 932809,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:mumei_kabaneri.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "mumei_kabaneri.safetensors",
          "size_on_disk": 151112410,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:myheroacademia_style.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "myheroacademia_style.safetensors",
          "size_on_disk": 302069805,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:neoartcore.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "neoartcore.safetensors",
          "size_on_disk": 151108831,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:ochakouraraka.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "ochakouraraka.safetensors",
          "size_on_disk": 9565173,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:onepiece_style.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "onepiece_style.safetensors",
          "size_on_disk": 302068911,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:paimon_genshinimpact.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "paimon_genshinimpact.safetensors",
          "size_on_disk": 151110127,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:peanutscomics_style.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "peanutscomics_style.safetensors",
          "size_on_disk": 54357317,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:pepefrog.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "pepefrog.safetensors",
          "size_on_disk": 151260201,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:persona5_portraits.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "persona5_portraits.safetensors",
          "size_on_disk": 19624598,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:persona5_style.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "persona5_style.safetensors",
          "size_on_disk": 151116853,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:pixhell.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "pixhell.safetensors",
          "size_on_disk": 151109839,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:princesszelda.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "princesszelda.safetensors",
          "size_on_disk": 302069806,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:satoshiuruchihara_style.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "satoshiuruchihara_style.safetensors",
          "size_on_disk": 453157754,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:shinobu_demonslayer.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "shinobu_demonslayer.safetensors",
          "size_on_disk": 151111222,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:sokolov_style.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "sokolov_style.safetensors",
          "size_on_disk": 151108831,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:standingbackgroundv1.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "standingbackgroundv1.safetensors",
          "size_on_disk": 37861172,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:sun_shadow_style.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "sun_shadow_style.safetensors",
          "size_on_disk": 151115842,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:thickeranimelines.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "thickeranimelines.safetensors",
          "size_on_disk": 151108831,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:threesidedview.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "threesidedview.safetensors",
          "size_on_disk": 151110147,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:twitch_emotes.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "twitch_emotes.safetensors",
          "size_on_disk": 9549785,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:water_vfx.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "water_vfx.safetensors",
          "size_on_disk": 4833133,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:wlop_style.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "wlop_style.safetensors",
          "size_on_disk": 19004975,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        },
        {
          "id": "danbrown/loras:zerotwo_darling.safetensors",
          "type": "hf.lora_sd",
          "name": "danbrown/loras",
          "repo_id": "danbrown/loras",
          "path": "zerotwo_darling.safetensors",
          "size_on_disk": 151108831,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 10
        }
      ],
      "basic_fields": [
        "lora1",
        "strength1",
        "lora2",
        "strength2",
        "lora3",
        "strength3",
        "lora4",
        "strength4",
        "lora5",
        "strength5"
      ]
    },
    {
      "title": "LoRA XL Selector",
      "description": "Selects up to 5 LoRA models to apply to a Stable Diffusion XL model.\n    lora, model customization, fine-tuning, SDXL\n\n    Use cases:\n    - Combining multiple LoRA models for unique image styles\n    - Fine-tuning Stable Diffusion XL models with specific attributes\n    - Experimenting with different LoRA combinations",
      "namespace": "huggingface.lora",
      "node_type": "huggingface.lora.LoRASelectorXL",
      "properties": [
        {
          "name": "lora1",
          "type": {
            "type": "hf.lora_sdxl"
          },
          "default": {
            "type": "hf.lora_sdxl",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Lora1",
          "description": "First LoRA model"
        },
        {
          "name": "strength1",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength1",
          "description": "Strength for first LoRA",
          "min": 0.0,
          "max": 2.0
        },
        {
          "name": "lora2",
          "type": {
            "type": "hf.lora_sdxl"
          },
          "default": {
            "type": "hf.lora_sdxl",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Lora2",
          "description": "Second LoRA model"
        },
        {
          "name": "strength2",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength2",
          "description": "Strength for second LoRA",
          "min": 0.0,
          "max": 2.0
        },
        {
          "name": "lora3",
          "type": {
            "type": "hf.lora_sdxl"
          },
          "default": {
            "type": "hf.lora_sdxl",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Lora3",
          "description": "Third LoRA model"
        },
        {
          "name": "strength3",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength3",
          "description": "Strength for third LoRA",
          "min": 0.0,
          "max": 2.0
        },
        {
          "name": "lora4",
          "type": {
            "type": "hf.lora_sdxl"
          },
          "default": {
            "type": "hf.lora_sdxl",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Lora4",
          "description": "Fourth LoRA model"
        },
        {
          "name": "strength4",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength4",
          "description": "Strength for fourth LoRA",
          "min": 0.0,
          "max": 2.0
        },
        {
          "name": "lora5",
          "type": {
            "type": "hf.lora_sdxl"
          },
          "default": {
            "type": "hf.lora_sdxl",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Lora5",
          "description": "Fifth LoRA model"
        },
        {
          "name": "strength5",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Strength5",
          "description": "Strength for fifth LoRA",
          "min": 0.0,
          "max": 2.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "hf.lora_sdxl_config"
              }
            ]
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "CiroN2022/toy-face:toy_face_sdxl.safetensors",
          "type": "hf.lora_sdxl",
          "name": "CiroN2022/toy-face",
          "repo_id": "CiroN2022/toy-face",
          "path": "toy_face_sdxl.safetensors",
          "size_on_disk": 170543292,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "stable-diffusion",
            "lora",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:adapter:stabilityai/stable-diffusion-xl-base-1.0",
            "license:other",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 200,
          "likes": 15
        },
        {
          "id": "nerijs/pixel-art-xl:pixel-art-xl.safetensors",
          "type": "hf.lora_sdxl",
          "name": "nerijs/pixel-art-xl",
          "repo_id": "nerijs/pixel-art-xl",
          "path": "pixel-art-xl.safetensors",
          "size_on_disk": 170543052,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "stable-diffusion",
            "lora",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:adapter:stabilityai/stable-diffusion-xl-base-1.0",
            "license:creativeml-openrail-m",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 4650,
          "likes": 568
        },
        {
          "id": "goofyai/3d_render_style_xl:3d_render_style_xl.safetensors",
          "type": "hf.lora_sdxl",
          "name": "goofyai/3d_render_style_xl",
          "repo_id": "goofyai/3d_render_style_xl",
          "path": "3d_render_style_xl.safetensors",
          "size_on_disk": 85450700,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "stable-diffusion",
            "lora",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:adapter:stabilityai/stable-diffusion-xl-base-1.0",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 588,
          "likes": 132
        },
        {
          "id": "artificialguybr/CuteCartoonRedmond-V2:CuteCartoonRedmond-CuteCartoon-CuteCartoonAF.safetensors",
          "type": "hf.lora_sdxl",
          "name": "artificialguybr/CuteCartoonRedmond-V2",
          "repo_id": "artificialguybr/CuteCartoonRedmond-V2",
          "path": "CuteCartoonRedmond-CuteCartoon-CuteCartoonAF.safetensors",
          "size_on_disk": 170540036,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "stable-diffusion",
            "lora",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:adapter:stabilityai/stable-diffusion-xl-base-1.0",
            "license:creativeml-openrail-m",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 135,
          "likes": 9
        },
        {
          "id": "blink7630/graphic-novel-illustration:Graphic_Novel_Illustration-000007.safetensors",
          "type": "hf.lora_sdxl",
          "name": "blink7630/graphic-novel-illustration",
          "repo_id": "blink7630/graphic-novel-illustration",
          "path": "Graphic_Novel_Illustration-000007.safetensors",
          "size_on_disk": 456580292,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "stable-diffusion",
            "lora",
            "template:sd-lora",
            "comic book",
            "style",
            "graphic novel",
            "illustration",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:adapter:stabilityai/stable-diffusion-xl-base-1.0",
            "license:other",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 54,
          "likes": 39
        },
        {
          "id": "robert123231/coloringbookgenerator:ColoringBookRedmond-ColoringBook-ColoringBookAF.safetensors",
          "type": "hf.lora_sdxl",
          "name": "robert123231/coloringbookgenerator",
          "repo_id": "robert123231/coloringbookgenerator",
          "path": "ColoringBookRedmond-ColoringBook-ColoringBookAF.safetensors",
          "size_on_disk": 170540036,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "stable-diffusion",
            "lora",
            "template:sd-lora",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:adapter:stabilityai/stable-diffusion-xl-base-1.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 13,
          "likes": 8
        },
        {
          "id": "Linaqruf/anime-detailer-xl-lora:anime-detailer-xl-lora.safetensors",
          "type": "hf.lora_sdxl",
          "name": "Linaqruf/anime-detailer-xl-lora",
          "repo_id": "Linaqruf/anime-detailer-xl-lora",
          "path": "anime-detailer-xl-lora.safetensors",
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "stable-diffusion",
            "lora",
            "safetensors",
            "stable-diffusion-xl",
            "en",
            "base_model:Linaqruf/animagine-xl-2.0",
            "base_model:adapter:Linaqruf/animagine-xl-2.0",
            "license:openrail++",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 8437,
          "likes": 60
        }
      ],
      "basic_fields": [
        "lora1",
        "strength1",
        "lora2",
        "strength2",
        "lora3",
        "strength3",
        "lora4",
        "strength4",
        "lora5",
        "strength5"
      ]
    },
    {
      "title": "Question Answering",
      "description": "Answers questions based on a given context.\n    text, question answering, natural language processing\n\n    Use cases:\n    - Automated customer support\n    - Information retrieval from documents\n    - Reading comprehension tasks\n    - Enhancing search functionality",
      "namespace": "huggingface.question_answering",
      "node_type": "huggingface.question_answering.QuestionAnswering",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.question_answering"
          },
          "default": {
            "type": "hf.question_answering",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for question answering"
        },
        {
          "name": "context",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Context",
          "description": "The context or passage to answer questions from"
        },
        {
          "name": "question",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Question",
          "description": "The question to be answered based on the context"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "answer"
        },
        {
          "type": {
            "type": "float"
          },
          "name": "score"
        },
        {
          "type": {
            "type": "int"
          },
          "name": "start"
        },
        {
          "type": {
            "type": "int"
          },
          "name": "end"
        }
      ],
      "recommended_models": [
        {
          "id": "distilbert-base-cased-distilled-squad",
          "type": "hf.question_answering",
          "name": "distilbert-base-cased-distilled-squad",
          "repo_id": "distilbert-base-cased-distilled-squad",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 261431925,
          "pipeline_tag": "question-answering",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "rust",
            "safetensors",
            "openvino",
            "distilbert",
            "question-answering",
            "en",
            "dataset:squad",
            "arxiv:1910.01108",
            "arxiv:1910.09700",
            "license:apache-2.0",
            "model-index",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 228537,
          "likes": 263
        },
        {
          "id": "bert-large-uncased-whole-word-masking-finetuned-squad",
          "type": "hf.question_answering",
          "name": "bert-large-uncased-whole-word-masking-finetuned-squad",
          "repo_id": "bert-large-uncased-whole-word-masking-finetuned-squad",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 1341320821,
          "pipeline_tag": "question-answering",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "jax",
            "safetensors",
            "bert",
            "question-answering",
            "en",
            "dataset:bookcorpus",
            "dataset:wikipedia",
            "arxiv:1810.04805",
            "license:apache-2.0",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 172474,
          "likes": 180
        },
        {
          "id": "deepset/roberta-base-squad2",
          "type": "hf.question_answering",
          "name": "deepset/roberta-base-squad2",
          "repo_id": "deepset/roberta-base-squad2",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 497611004,
          "pipeline_tag": "question-answering",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "jax",
            "rust",
            "safetensors",
            "roberta",
            "question-answering",
            "en",
            "dataset:squad_v2",
            "base_model:FacebookAI/roberta-base",
            "base_model:finetune:FacebookAI/roberta-base",
            "license:cc-by-4.0",
            "model-index",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 714922,
          "likes": 927
        },
        {
          "id": "distilbert-base-uncased-distilled-squad",
          "type": "hf.question_answering",
          "name": "distilbert-base-uncased-distilled-squad",
          "repo_id": "distilbert-base-uncased-distilled-squad",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 266168105,
          "pipeline_tag": "question-answering",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "tflite",
            "coreml",
            "safetensors",
            "distilbert",
            "question-answering",
            "en",
            "dataset:squad",
            "arxiv:1910.01108",
            "arxiv:1910.09700",
            "license:apache-2.0",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 74582,
          "likes": 118
        }
      ],
      "basic_fields": [
        "model",
        "context",
        "question"
      ]
    },
    {
      "title": "Table Question Answering",
      "description": "Answers questions based on tabular data.\n    table, question answering, natural language processing\n\n    Use cases:\n    - Querying databases using natural language\n    - Analyzing spreadsheet data with questions\n    - Extracting insights from tabular reports\n    - Automated data exploration",
      "namespace": "huggingface.question_answering",
      "node_type": "huggingface.question_answering.TableQuestionAnswering",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.table_question_answering"
          },
          "default": {
            "type": "hf.table_question_answering",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for table question answering"
        },
        {
          "name": "dataframe",
          "type": {
            "type": "dataframe"
          },
          "default": {
            "type": "dataframe",
            "uri": "",
            "asset_id": null,
            "data": null,
            "columns": null
          },
          "title": "Table",
          "description": "The input table to query"
        },
        {
          "name": "question",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Question",
          "description": "The question to be answered based on the table"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "answer"
        },
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "tuple",
                "type_args": [
                  {
                    "type": "int"
                  },
                  {
                    "type": "int"
                  }
                ]
              }
            ]
          },
          "name": "coordinates"
        },
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "name": "cells"
        },
        {
          "type": {
            "type": "str"
          },
          "name": "aggregator"
        }
      ],
      "recommended_models": [
        {
          "id": "google/tapas-base-finetuned-wtq",
          "type": "hf.table_question_answering",
          "name": "google/tapas-base-finetuned-wtq",
          "repo_id": "google/tapas-base-finetuned-wtq",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 264329,
          "pipeline_tag": "table-question-answering",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "tapas",
            "table-question-answering",
            "en",
            "dataset:wikitablequestions",
            "arxiv:2004.02349",
            "arxiv:2010.00571",
            "arxiv:1508.00305",
            "license:apache-2.0",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 25807,
          "likes": 232
        },
        {
          "id": "google/tapas-large-finetuned-wtq",
          "type": "hf.table_question_answering",
          "name": "google/tapas-large-finetuned-wtq",
          "repo_id": "google/tapas-large-finetuned-wtq",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 1347249613,
          "pipeline_tag": "table-question-answering",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "safetensors",
            "tapas",
            "table-question-answering",
            "en",
            "dataset:wikitablequestions",
            "arxiv:2004.02349",
            "arxiv:2010.00571",
            "arxiv:1508.00305",
            "license:apache-2.0",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 3671,
          "likes": 148
        },
        {
          "id": "microsoft/tapex-large-finetuned-tabfact",
          "type": "hf.table_question_answering",
          "name": "microsoft/tapex-large-finetuned-tabfact",
          "repo_id": "microsoft/tapex-large-finetuned-tabfact",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 1358708,
          "pipeline_tag": "table-question-answering",
          "tags": [
            "transformers",
            "pytorch",
            "bart",
            "text-classification",
            "tapex",
            "table-question-answering",
            "en",
            "dataset:tab_fact",
            "arxiv:2107.07653",
            "license:mit",
            "autotrain_compatible",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 108,
          "likes": 8
        }
      ],
      "basic_fields": [
        "model",
        "dataframe",
        "question"
      ]
    },
    {
      "title": "Fill Mask",
      "description": "Fills in a masked token in a given text.\n    text, fill-mask, natural language processing\n\n    Use cases:\n    - Text completion\n    - Sentence prediction\n    - Language understanding tasks\n    - Generating text options",
      "namespace": "huggingface.fill_mask",
      "node_type": "huggingface.fill_mask.FillMask",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.fill_mask"
          },
          "default": {
            "type": "hf.fill_mask",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID",
          "description": "The model ID to use for fill-mask task"
        },
        {
          "name": "inputs",
          "type": {
            "type": "str"
          },
          "default": "The capital of France is [MASK].",
          "title": "Inputs",
          "description": "The input text with [MASK] token to be filled"
        },
        {
          "name": "top_k",
          "type": {
            "type": "int"
          },
          "default": 5,
          "title": "Top K",
          "description": "Number of top predictions to return"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "dict",
            "type_args": [
              {
                "type": "str"
              },
              {
                "type": "any"
              }
            ]
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "bert-base-uncased",
          "type": "hf.fill_mask",
          "name": "bert-base-uncased",
          "repo_id": "bert-base-uncased",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 441148573,
          "pipeline_tag": "fill-mask",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "jax",
            "rust",
            "coreml",
            "onnx",
            "safetensors",
            "bert",
            "fill-mask",
            "exbert",
            "en",
            "dataset:bookcorpus",
            "dataset:wikipedia",
            "arxiv:1810.04805",
            "license:apache-2.0",
            "autotrain_compatible",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 58674990,
          "likes": 2475
        },
        {
          "id": "roberta-base",
          "type": "hf.fill_mask",
          "name": "roberta-base",
          "repo_id": "roberta-base",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 502132854,
          "pipeline_tag": "fill-mask",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "jax",
            "rust",
            "safetensors",
            "roberta",
            "fill-mask",
            "exbert",
            "en",
            "dataset:bookcorpus",
            "dataset:wikipedia",
            "arxiv:1907.11692",
            "arxiv:1806.02847",
            "license:mit",
            "autotrain_compatible",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 10230487,
          "likes": 534
        },
        {
          "id": "distilbert-base-uncased",
          "type": "hf.fill_mask",
          "name": "distilbert-base-uncased",
          "repo_id": "distilbert-base-uncased",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 268652869,
          "pipeline_tag": "fill-mask",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "jax",
            "rust",
            "safetensors",
            "distilbert",
            "fill-mask",
            "exbert",
            "en",
            "dataset:bookcorpus",
            "dataset:wikipedia",
            "arxiv:1910.01108",
            "license:apache-2.0",
            "autotrain_compatible",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 14745766,
          "likes": 791
        },
        {
          "id": "albert-base-v2",
          "type": "hf.fill_mask",
          "name": "albert-base-v2",
          "repo_id": "albert-base-v2",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 48686272,
          "pipeline_tag": "fill-mask",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "jax",
            "rust",
            "safetensors",
            "albert",
            "fill-mask",
            "en",
            "dataset:bookcorpus",
            "dataset:wikipedia",
            "arxiv:1909.11942",
            "license:apache-2.0",
            "autotrain_compatible",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 549796,
          "likes": 134
        }
      ],
      "basic_fields": [
        "model",
        "inputs",
        "top_k"
      ]
    },
    {
      "title": "Translation",
      "description": "Translates text from one language to another.\n    text, translation, natural language processing\n\n    Use cases:\n    - Multilingual content creation\n    - Cross-language communication\n    - Localization of applications and websites\n\n    Note: some models support more languages than others.",
      "namespace": "huggingface.translation",
      "node_type": "huggingface.translation.Translation",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.translation"
          },
          "default": {
            "type": "hf.translation",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on HuggingFace",
          "description": "The model ID to use for translation"
        },
        {
          "name": "inputs",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Input Text",
          "description": "The text to translate"
        },
        {
          "name": "source_lang",
          "type": {
            "type": "enum",
            "values": [
              "ar",
              "bn",
              "bs",
              "zh",
              "hr",
              "cs",
              "da",
              "nl",
              "en",
              "fil",
              "fi",
              "fr",
              "de",
              "el",
              "he",
              "hi",
              "id",
              "it",
              "ja",
              "ko",
              "ms",
              "me",
              "no",
              "pl",
              "pt",
              "pa",
              "ru",
              "ro",
              "sr",
              "sk",
              "sl",
              "es",
              "sv",
              "th",
              "tr",
              "vi"
            ],
            "type_name": "nodetool.nodes.huggingface.translation.Translation.LanguageCode"
          },
          "default": "en",
          "title": "Source Language",
          "description": "The source language code (e.g., 'en' for English)"
        },
        {
          "name": "target_lang",
          "type": {
            "type": "enum",
            "values": [
              "ar",
              "bn",
              "bs",
              "zh",
              "hr",
              "cs",
              "da",
              "nl",
              "en",
              "fil",
              "fi",
              "fr",
              "de",
              "el",
              "he",
              "hi",
              "id",
              "it",
              "ja",
              "ko",
              "ms",
              "me",
              "no",
              "pl",
              "pt",
              "pa",
              "ru",
              "ro",
              "sr",
              "sk",
              "sl",
              "es",
              "sv",
              "th",
              "tr",
              "vi"
            ],
            "type_name": "nodetool.nodes.huggingface.translation.Translation.LanguageCode"
          },
          "default": "fr",
          "title": "Target Language",
          "description": "The target language code (e.g., 'fr' for French)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "google-t5/t5-base",
          "type": "hf.translation",
          "name": "google-t5/t5-base",
          "repo_id": "google-t5/t5-base",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 893037098,
          "pipeline_tag": "translation",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "jax",
            "rust",
            "safetensors",
            "t5",
            "text2text-generation",
            "summarization",
            "translation",
            "en",
            "fr",
            "ro",
            "de",
            "dataset:c4",
            "arxiv:1805.12471",
            "arxiv:1708.00055",
            "arxiv:1704.05426",
            "arxiv:1606.05250",
            "arxiv:1808.09121",
            "arxiv:1810.12885",
            "arxiv:1905.10044",
            "arxiv:1910.09700",
            "license:apache-2.0",
            "text-generation-inference",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 1796931,
          "likes": 755
        },
        {
          "id": "google-t5/t5-large",
          "type": "hf.translation",
          "name": "google-t5/t5-large",
          "repo_id": "google-t5/t5-large",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 2952127439,
          "pipeline_tag": "translation",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "jax",
            "safetensors",
            "t5",
            "text2text-generation",
            "summarization",
            "translation",
            "en",
            "fr",
            "ro",
            "de",
            "multilingual",
            "dataset:c4",
            "arxiv:1805.12471",
            "arxiv:1708.00055",
            "arxiv:1704.05426",
            "arxiv:1606.05250",
            "arxiv:1808.09121",
            "arxiv:1810.12885",
            "arxiv:1905.10044",
            "arxiv:1910.09700",
            "license:apache-2.0",
            "text-generation-inference",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 209458,
          "likes": 230
        },
        {
          "id": "google-t5/t5-small",
          "type": "hf.translation",
          "name": "google-t5/t5-small",
          "repo_id": "google-t5/t5-small",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 243436086,
          "pipeline_tag": "translation",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "jax",
            "rust",
            "onnx",
            "safetensors",
            "t5",
            "text2text-generation",
            "summarization",
            "translation",
            "en",
            "fr",
            "ro",
            "de",
            "multilingual",
            "dataset:c4",
            "arxiv:1805.12471",
            "arxiv:1708.00055",
            "arxiv:1704.05426",
            "arxiv:1606.05250",
            "arxiv:1808.09121",
            "arxiv:1810.12885",
            "arxiv:1905.10044",
            "arxiv:1910.09700",
            "license:apache-2.0",
            "text-generation-inference",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 2480015,
          "likes": 504
        }
      ],
      "basic_fields": [
        "model",
        "inputs",
        "source_lang",
        "target_lang"
      ]
    },
    {
      "title": "Image To Text",
      "description": "Generates textual descriptions from images.\n    image, captioning, OCR, image-to-text\n\n    Use cases:\n    - Generate captions for images\n    - Extract text from images (OCR)\n    - Describe image content for visually impaired users\n    - Build accessibility features for visual content",
      "namespace": "huggingface.image_to_text",
      "node_type": "huggingface.image_to_text.ImageToText",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.image_to_text"
          },
          "default": {
            "type": "hf.image_to_text",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for image-to-text generation"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Input Image",
          "description": "The image to generate text from"
        },
        {
          "name": "max_new_tokens",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Max New Tokens",
          "description": "The maximum number of tokens to generate (if supported by model)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "Salesforce/blip-image-captioning-base",
          "type": "hf.image_to_text",
          "name": "Salesforce/blip-image-captioning-base",
          "repo_id": "Salesforce/blip-image-captioning-base",
          "allow_patterns": [
            "*.safetensors",
            "*.json",
            "*.txt",
            "*.model"
          ],
          "size_on_disk": 948385,
          "pipeline_tag": "image-to-text",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "blip",
            "image-to-text",
            "image-captioning",
            "arxiv:2201.12086",
            "license:bsd-3-clause",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 2730491,
          "likes": 812
        },
        {
          "id": "Salesforce/blip2-opt-2.7b",
          "type": "hf.image_to_text",
          "name": "Salesforce/blip2-opt-2.7b",
          "repo_id": "Salesforce/blip2-opt-2.7b",
          "allow_patterns": [
            "*.safetensors",
            "*.json",
            "*.txt",
            "*.model"
          ],
          "size_on_disk": 14984267092,
          "pipeline_tag": "image-text-to-text",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "blip-2",
            "image-to-text",
            "vision",
            "image-captioning",
            "visual-question-answering",
            "image-text-to-text",
            "en",
            "arxiv:2301.12597",
            "license:mit",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 792694,
          "likes": 423
        },
        {
          "id": "microsoft/git-base",
          "type": "hf.image_to_text",
          "name": "microsoft/git-base",
          "repo_id": "microsoft/git-base",
          "allow_patterns": [
            "*.safetensors",
            "*.json",
            "*.txt",
            "*.model"
          ],
          "size_on_disk": 707472970,
          "pipeline_tag": "image-to-text",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "git",
            "image-to-text",
            "vision",
            "image-captioning",
            "en",
            "arxiv:2205.14100",
            "license:mit",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 15511,
          "likes": 106
        },
        {
          "id": "nlpconnect/vit-gpt2-image-captioning",
          "type": "hf.image_to_text",
          "name": "nlpconnect/vit-gpt2-image-captioning",
          "repo_id": "nlpconnect/vit-gpt2-image-captioning",
          "allow_patterns": [
            "*.safetensors",
            "*.json",
            "*.txt",
            "*.model"
          ],
          "size_on_disk": 2615156,
          "pipeline_tag": "image-to-text",
          "tags": [
            "transformers",
            "pytorch",
            "vision-encoder-decoder",
            "image-to-text",
            "image-captioning",
            "doi:10.57967/hf/0222",
            "license:apache-2.0",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 2393171,
          "likes": 916
        }
      ],
      "basic_fields": [
        "model",
        "image"
      ]
    },
    {
      "title": "Load Image To Text Model",
      "description": "",
      "namespace": "huggingface.image_to_text",
      "node_type": "huggingface.image_to_text.LoadImageToTextModel",
      "properties": [
        {
          "name": "repo_id",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for image-to-text generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "hf.image_to_text"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "repo_id"
      ]
    },
    {
      "title": "Image To Text",
      "description": "Generates text descriptions from images.\n    image, text, captioning, vision-language\n\n    Use cases:\n    - Automatic image captioning\n    - Assisting visually impaired users\n    - Enhancing image search capabilities\n    - Generating alt text for web images",
      "namespace": "huggingface.multimodal",
      "node_type": "huggingface.multimodal.ImageToText",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.image_to_text"
          },
          "default": {
            "type": "hf.image_to_text",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for image-to-text generation"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Input Image",
          "description": "The image to generate text from"
        },
        {
          "name": "max_new_tokens",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Max New Tokens",
          "description": "The maximum number of tokens to generate"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "Salesforce/blip-image-captioning-base",
          "type": "hf.image_to_text",
          "name": "Salesforce/blip-image-captioning-base",
          "repo_id": "Salesforce/blip-image-captioning-base",
          "allow_patterns": [
            "*.bin",
            "*.json",
            "*.txt    "
          ],
          "size_on_disk": 990537726,
          "pipeline_tag": "image-to-text",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "blip",
            "image-to-text",
            "image-captioning",
            "arxiv:2201.12086",
            "license:bsd-3-clause",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 2730491,
          "likes": 812
        },
        {
          "id": "Salesforce/blip-image-captioning-large",
          "type": "hf.image_to_text",
          "name": "Salesforce/blip-image-captioning-large",
          "repo_id": "Salesforce/blip-image-captioning-large",
          "allow_patterns": [
            "*.bin",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 1880092519,
          "pipeline_tag": "image-to-text",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "safetensors",
            "blip",
            "image-to-text",
            "image-captioning",
            "arxiv:2201.12086",
            "license:bsd-3-clause",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 1050767,
          "likes": 1432
        },
        {
          "id": "nlpconnect/vit-gpt2-image-captioning",
          "type": "hf.image_to_text",
          "name": "nlpconnect/vit-gpt2-image-captioning",
          "repo_id": "nlpconnect/vit-gpt2-image-captioning",
          "allow_patterns": [
            "*.bin",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 984757149,
          "pipeline_tag": "image-to-text",
          "tags": [
            "transformers",
            "pytorch",
            "vision-encoder-decoder",
            "image-to-text",
            "image-captioning",
            "doi:10.57967/hf/0222",
            "license:apache-2.0",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 2393171,
          "likes": 916
        },
        {
          "id": "microsoft/git-base-coco",
          "type": "hf.image_to_text",
          "name": "microsoft/git-base-coco",
          "repo_id": "microsoft/git-base-coco",
          "allow_patterns": [
            "*.bin",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 707534943,
          "pipeline_tag": "image-to-text",
          "tags": [
            "transformers",
            "pytorch",
            "git",
            "image-to-text",
            "vision",
            "image-captioning",
            "en",
            "arxiv:2205.14100",
            "license:mit",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 86873,
          "likes": 19
        }
      ],
      "basic_fields": [
        "model",
        "image",
        "max_new_tokens"
      ]
    },
    {
      "title": "Visual Question Answering",
      "description": "Answers questions about images.\n    image, text, question answering, multimodal\n\n    Use cases:\n    - Image content analysis\n    - Automated image captioning\n    - Visual information retrieval\n    - Accessibility tools for visually impaired users",
      "namespace": "huggingface.multimodal",
      "node_type": "huggingface.multimodal.VisualQuestionAnswering",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.visual_question_answering"
          },
          "default": {
            "type": "hf.visual_question_answering",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for visual question answering"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The image to analyze"
        },
        {
          "name": "question",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Question",
          "description": "The question to be answered about the image"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "Salesforce/blip-vqa-base",
          "type": "hf.visual_question_answering",
          "name": "Salesforce/blip-vqa-base",
          "repo_id": "Salesforce/blip-vqa-base",
          "allow_patterns": [
            "*.bin",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 1539915254,
          "pipeline_tag": "visual-question-answering",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "safetensors",
            "blip",
            "visual-question-answering",
            "arxiv:2201.12086",
            "license:bsd-3-clause",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 268819,
          "likes": 184
        }
      ],
      "basic_fields": [
        "model",
        "image",
        "question"
      ]
    },
    {
      "title": "Image Text To Text",
      "description": "Answers questions or follows instructions given both an image and text.\n    image, text, visual question answering, multimodal, VLM\n\n    Use cases:\n    - Visual question answering with free-form reasoning\n    - Zero-shot object localization or structure extraction via instructions\n    - OCR-free document understanding when combined with prompts\n    - Multi-turn, instruction-following conversations grounded in an image",
      "namespace": "huggingface.image_text_to_text",
      "node_type": "huggingface.image_text_to_text.ImageTextToText",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.image_text_to_text"
          },
          "default": {
            "type": "hf.image_text_to_text",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model",
          "description": "The image-text-to-text model to use."
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Input Image",
          "description": "The image to analyze."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "Describe this image.",
          "title": "Prompt",
          "description": "Instruction or question for the model about the image."
        },
        {
          "name": "max_new_tokens",
          "type": {
            "type": "int"
          },
          "default": 256,
          "title": "Max New Tokens",
          "description": "Maximum number of tokens to generate.",
          "min": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "HuggingFaceTB/SmolVLM-Instruct",
          "type": "hf.image_text_to_text",
          "name": "HuggingFaceTB/SmolVLM-Instruct",
          "repo_id": "HuggingFaceTB/SmolVLM-Instruct",
          "allow_patterns": [
            "*.safetensors",
            "*.json",
            "*.txt",
            "*.model"
          ],
          "size_on_disk": 4497435403,
          "pipeline_tag": "image-text-to-text",
          "tags": [
            "transformers",
            "onnx",
            "safetensors",
            "idefics3",
            "image-to-text",
            "image-text-to-text",
            "conversational",
            "en",
            "dataset:HuggingFaceM4/the_cauldron",
            "dataset:HuggingFaceM4/Docmatix",
            "arxiv:2504.05299",
            "base_model:HuggingFaceTB/SmolLM2-1.7B-Instruct",
            "base_model:quantized:HuggingFaceTB/SmolLM2-1.7B-Instruct",
            "license:apache-2.0",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 75086,
          "likes": 561
        },
        {
          "id": "zai-org/GLM-4.5V",
          "type": "hf.image_text_to_text",
          "name": "zai-org/GLM-4.5V",
          "repo_id": "zai-org/GLM-4.5V",
          "allow_patterns": [
            "*.safetensors",
            "*.json",
            "*.txt",
            "*.model"
          ],
          "size_on_disk": 215446280228,
          "pipeline_tag": "image-text-to-text",
          "tags": [
            "transformers",
            "safetensors",
            "glm4v_moe",
            "image-text-to-text",
            "conversational",
            "zh",
            "en",
            "arxiv:2507.01006",
            "base_model:zai-org/GLM-4.5-Air-Base",
            "base_model:finetune:zai-org/GLM-4.5-Air-Base",
            "license:mit",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 43442,
          "likes": 693
        },
        {
          "id": "Qwen/Qwen2.5-VL-3B-Instruct",
          "type": "hf.image_text_to_text",
          "name": "Qwen/Qwen2.5-VL-3B-Instruct",
          "repo_id": "Qwen/Qwen2.5-VL-3B-Instruct",
          "allow_patterns": [
            "*.safetensors",
            "*.json",
            "*.txt",
            "*.model"
          ],
          "size_on_disk": 7520892432,
          "pipeline_tag": "image-text-to-text",
          "tags": [
            "transformers",
            "safetensors",
            "qwen2_5_vl",
            "image-to-text",
            "multimodal",
            "image-text-to-text",
            "conversational",
            "en",
            "arxiv:2309.00071",
            "arxiv:2409.12191",
            "arxiv:2308.12966",
            "text-generation-inference",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 8222143,
          "likes": 556
        },
        {
          "id": "llava-hf/llava-interleave-qwen-0.5b-hf",
          "type": "hf.image_text_to_text",
          "name": "llava-hf/llava-interleave-qwen-0.5b-hf",
          "repo_id": "llava-hf/llava-interleave-qwen-0.5b-hf",
          "allow_patterns": [
            "*.safetensors",
            "*.json",
            "*.txt",
            "*.model"
          ],
          "size_on_disk": 1739639693,
          "pipeline_tag": "image-text-to-text",
          "tags": [
            "transformers",
            "onnx",
            "safetensors",
            "llava",
            "image-to-text",
            "vision",
            "image-text-to-text",
            "conversational",
            "en",
            "arxiv:2407.07895",
            "license:other",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 6843,
          "likes": 35
        }
      ],
      "basic_fields": [
        "model",
        "image",
        "prompt"
      ]
    },
    {
      "title": "Load Image Text To Text Model",
      "description": "Load a Hugging Face image-text-to-text model/pipeline by repo_id.\n\n    Use cases:\n    - Produces a configurable `HFImageTextToText` model reference for downstream nodes\n    - Ensures the selected model can be loaded with the \"image-text-to-text\" task",
      "namespace": "huggingface.image_text_to_text",
      "node_type": "huggingface.image_text_to_text.LoadImageTextToTextModel",
      "properties": [
        {
          "name": "repo_id",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Model ID on Hugging Face",
          "description": "The model repository ID to use for image-text-to-text generation."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "hf.image_text_to_text"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "repo_id"
      ]
    },
    {
      "title": "CogVideoX",
      "description": "Generates videos from text prompts using CogVideoX, a large diffusion transformer model.\n    video, generation, AI, text-to-video, transformer, diffusion\n\n    Use cases:\n    - Create high-quality videos from text descriptions\n    - Generate longer and more consistent videos\n    - Produce cinematic content for creative projects\n    - Create animated scenes for storytelling\n    - Generate video content for marketing and media",
      "namespace": "huggingface.text_to_video",
      "node_type": "huggingface.text_to_video.CogVideoX",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "A detailed wooden toy ship with intricately carved masts and sails is seen gliding smoothly over a plush, blue carpet that mimics the waves of the sea. The ship's hull is painted a rich brown, with tiny windows. The carpet, soft and textured, provides a perfect backdrop, resembling an oceanic expanse. Surrounding the ship are various other toys and children's items, hinting at a playful environment. The scene captures the innocence and imagination of childhood, with the toy ship's journey symbolizing endless adventures in a whimsical, indoor setting.",
          "title": "Prompt",
          "description": "A text prompt describing the desired video."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "A text prompt describing what to avoid in the video."
        },
        {
          "name": "num_frames",
          "type": {
            "type": "int"
          },
          "default": 49,
          "title": "Num Frames",
          "description": "The number of frames in the video. Must be divisible by 8 + 1 (e.g., 49, 81, 113).",
          "min": 49.0,
          "max": 113.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 6.0,
          "title": "Guidance Scale",
          "description": "The scale for classifier-free guidance.",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "The number of denoising steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 480,
          "title": "Height",
          "description": "The height of the generated video in pixels.",
          "min": 256.0,
          "max": 1024.0
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 720,
          "title": "Width",
          "description": "The width of the generated video in pixels.",
          "min": 256.0,
          "max": 1024.0
        },
        {
          "name": "fps",
          "type": {
            "type": "int"
          },
          "default": 8,
          "title": "Fps",
          "description": "Frames per second for the output video.",
          "min": 1.0,
          "max": 30.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0
        },
        {
          "name": "max_sequence_length",
          "type": {
            "type": "int"
          },
          "default": 226,
          "title": "Max Sequence Length",
          "description": "Maximum sequence length in encoded prompt.",
          "min": 1.0,
          "max": 512.0
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload to reduce VRAM usage."
        },
        {
          "name": "enable_vae_slicing",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Vae Slicing",
          "description": "Enable VAE slicing to reduce VRAM usage."
        },
        {
          "name": "enable_vae_tiling",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Vae Tiling",
          "description": "Enable VAE tiling to reduce VRAM usage for large videos."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "THUDM/CogVideoX-2b",
          "type": "hf.text_to_video",
          "name": "THUDM/CogVideoX-2b",
          "repo_id": "THUDM/CogVideoX-2b",
          "allow_patterns": [
            "**/*.safetensors",
            "**/*.json",
            "**/*.txt",
            "*.json"
          ],
          "size_on_disk": 13774736163,
          "pipeline_tag": "text-to-video",
          "tags": [
            "diffusers",
            "safetensors",
            "cogvideox",
            "video-generation",
            "thudm",
            "text-to-video",
            "en",
            "arxiv:2408.06072",
            "license:apache-2.0",
            "diffusers:CogVideoXPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 79420,
          "likes": 340
        },
        {
          "id": "THUDM/CogVideoX-5b",
          "type": "hf.text_to_video",
          "name": "THUDM/CogVideoX-5b",
          "repo_id": "THUDM/CogVideoX-5b",
          "allow_patterns": [
            "**/*.safetensors",
            "**/*.json",
            "**/*.txt",
            "*.json"
          ],
          "size_on_disk": 21527871871,
          "pipeline_tag": "text-to-video",
          "tags": [
            "diffusers",
            "safetensors",
            "cogvideox",
            "video-generation",
            "thudm",
            "text-to-video",
            "en",
            "arxiv:2408.06072",
            "license:other",
            "diffusers:CogVideoXPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 55519,
          "likes": 651
        }
      ],
      "basic_fields": [
        "prompt",
        "num_frames",
        "height",
        "width"
      ]
    },
    {
      "title": "Wan (Text-to-Video)",
      "description": "Generates videos from text prompts using Wan text-to-video pipeline.\n    video, generation, AI, text-to-video, diffusion, Wan\n\n    Use cases:\n    - Create high-quality videos from text descriptions\n    - Efficient 1.3B model for consumer GPUs or 14B for maximum quality",
      "namespace": "huggingface.text_to_video",
      "node_type": "huggingface.text_to_video.Wan_T2V",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "A robot standing on a mountain top at sunset, cinematic lighting, high detail",
          "title": "Prompt",
          "description": "A text prompt describing the desired video."
        },
        {
          "name": "model_variant",
          "type": {
            "type": "enum",
            "values": [
              "Wan-AI/Wan2.2-T2V-A14B-Diffusers",
              "Wan-AI/Wan2.1-T2V-14B-Diffusers",
              "Wan-AI/Wan2.2-TI2V-5B-Diffusers"
            ],
            "type_name": "nodetool.nodes.huggingface.text_to_video.Wan_T2V.WanModel"
          },
          "default": "Wan-AI/Wan2.2-T2V-A14B-Diffusers",
          "title": "Model Variant",
          "description": "Select the Wan model to use."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "A text prompt describing what to avoid in the video."
        },
        {
          "name": "num_frames",
          "type": {
            "type": "int"
          },
          "default": 49,
          "title": "Num Frames",
          "description": "The number of frames in the video.",
          "min": 16.0,
          "max": 129.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "The scale for classifier-free guidance.",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "The number of denoising steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 480,
          "title": "Height",
          "description": "The height of the generated video in pixels.",
          "min": 256.0,
          "max": 1080.0
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 720,
          "title": "Width",
          "description": "The width of the generated video in pixels.",
          "min": 256.0,
          "max": 1920.0
        },
        {
          "name": "fps",
          "type": {
            "type": "int"
          },
          "default": 16,
          "title": "Fps",
          "description": "Frames per second for the output video.",
          "min": 1.0,
          "max": 60.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0
        },
        {
          "name": "max_sequence_length",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Max Sequence Length",
          "description": "Maximum sequence length in encoded prompt.",
          "min": 64.0,
          "max": 1024.0
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload to reduce VRAM usage."
        },
        {
          "name": "enable_vae_slicing",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Vae Slicing",
          "description": "Enable VAE slicing to reduce VRAM usage."
        },
        {
          "name": "enable_vae_tiling",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Vae Tiling",
          "description": "Enable VAE tiling to reduce VRAM usage for large videos."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "Wan-AI/Wan2.2-T2V-A14B-Diffusers",
          "type": "hf.text_to_video",
          "name": "Wan-AI/Wan2.2-T2V-A14B-Diffusers",
          "repo_id": "Wan-AI/Wan2.2-T2V-A14B-Diffusers",
          "allow_patterns": [
            "**/*.safetensors",
            "**/*.json",
            "**/*.txt",
            "*.json"
          ],
          "size_on_disk": 126194725893,
          "pipeline_tag": "text-to-video",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-video",
            "arxiv:2503.20314",
            "arxiv:2309.14509",
            "license:apache-2.0",
            "diffusers:WanPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 206451,
          "likes": 89
        },
        {
          "id": "Wan-AI/Wan2.1-T2V-14B-Diffusers",
          "type": "hf.text_to_video",
          "name": "Wan-AI/Wan2.1-T2V-14B-Diffusers",
          "repo_id": "Wan-AI/Wan2.1-T2V-14B-Diffusers",
          "allow_patterns": [
            "**/*.safetensors",
            "**/*.json",
            "**/*.txt",
            "*.json"
          ],
          "size_on_disk": 80402370670,
          "pipeline_tag": "text-to-video",
          "tags": [
            "diffusers",
            "safetensors",
            "video generation",
            "text-to-video",
            "en",
            "zh",
            "license:apache-2.0",
            "diffusers:WanPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 14176,
          "likes": 46
        },
        {
          "id": "Wan-AI/Wan2.2-TI2V-5B-Diffusers",
          "type": "hf.text_to_video",
          "name": "Wan-AI/Wan2.2-TI2V-5B-Diffusers",
          "repo_id": "Wan-AI/Wan2.2-TI2V-5B-Diffusers",
          "allow_patterns": [
            "**/*.safetensors",
            "**/*.json",
            "**/*.txt",
            "*.json"
          ],
          "size_on_disk": 34196870087,
          "pipeline_tag": "text-to-video",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-video",
            "en",
            "zh",
            "arxiv:2503.20314",
            "license:apache-2.0",
            "diffusers:WanPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 43979,
          "likes": 85
        }
      ],
      "basic_fields": [
        "prompt",
        "num_frames",
        "height",
        "width",
        "model_variant"
      ]
    },
    {
      "title": "Summarize",
      "description": "Summarizes text using a Hugging Face model.\n    text, summarization, AI, LLM",
      "namespace": "huggingface.summarization",
      "node_type": "huggingface.summarization.Summarize",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.text_generation"
          },
          "default": {
            "type": "hf.text_generation",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for the text generation"
        },
        {
          "name": "inputs",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Inputs",
          "description": "The input text to summarize"
        },
        {
          "name": "max_length",
          "type": {
            "type": "int"
          },
          "default": 100,
          "title": "Max Length",
          "description": "The maximum length of the generated text"
        },
        {
          "name": "do_sample",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Do Sample",
          "description": "Whether to sample from the model"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "Falconsai/text_summarization",
          "type": "hf.text_generation",
          "name": "Falconsai/text_summarization",
          "repo_id": "Falconsai/text_summarization",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 246921089,
          "pipeline_tag": "summarization",
          "tags": [
            "transformers",
            "pytorch",
            "coreml",
            "onnx",
            "safetensors",
            "t5",
            "text2text-generation",
            "summarization",
            "en",
            "license:apache-2.0",
            "text-generation-inference",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 29664,
          "likes": 274
        },
        {
          "id": "Falconsai/medical_summarization",
          "type": "hf.text_generation",
          "name": "Falconsai/medical_summarization",
          "repo_id": "Falconsai/medical_summarization",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 244471620,
          "pipeline_tag": "summarization",
          "tags": [
            "transformers",
            "pytorch",
            "coreml",
            "safetensors",
            "t5",
            "text2text-generation",
            "medical",
            "summarization",
            "en",
            "license:apache-2.0",
            "text-generation-inference",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 3257,
          "likes": 141
        },
        {
          "id": "imvladikon/het5_summarization",
          "type": "hf.text_generation",
          "name": "imvladikon/het5_summarization",
          "repo_id": "imvladikon/het5_summarization",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 979495909,
          "pipeline_tag": "summarization",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "t5",
            "text2text-generation",
            "summarization",
            "he",
            "text-generation-inference",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 3,
          "likes": 0
        }
      ],
      "basic_fields": [
        "model",
        "inputs"
      ]
    },
    {
      "title": "Depth Estimation",
      "description": "Estimates depth from a single image.\n    image, depth estimation, 3D, huggingface\n\n    Use cases:\n    - Generate depth maps for 3D modeling\n    - Assist in augmented reality applications\n    - Enhance computer vision systems for robotics\n    - Improve scene understanding in autonomous vehicles",
      "namespace": "huggingface.depth_estimation",
      "node_type": "huggingface.depth_estimation.DepthEstimation",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.depth_estimation"
          },
          "default": {
            "type": "hf.depth_estimation",
            "repo_id": "LiheYoung/depth-anything-base-hf",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for depth estimation"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The input image for depth estimation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "depth-anything/Depth-Anything-V2-Small-hf",
          "type": "hf.depth_estimation",
          "name": "depth-anything/Depth-Anything-V2-Small-hf",
          "repo_id": "depth-anything/Depth-Anything-V2-Small-hf",
          "size_on_disk": 99181304,
          "pipeline_tag": "depth-estimation",
          "tags": [
            "transformers",
            "safetensors",
            "depth_anything",
            "depth-estimation",
            "depth",
            "relative depth",
            "arxiv:2406.09414",
            "arxiv:2401.10891",
            "license:apache-2.0",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 534767,
          "likes": 25
        },
        {
          "id": "depth-anything/Depth-Anything-V2-Base-hf",
          "type": "hf.depth_estimation",
          "name": "depth-anything/Depth-Anything-V2-Base-hf",
          "repo_id": "depth-anything/Depth-Anything-V2-Base-hf",
          "size_on_disk": 389924651,
          "pipeline_tag": "depth-estimation",
          "tags": [
            "transformers",
            "safetensors",
            "depth_anything",
            "depth-estimation",
            "depth",
            "relative depth",
            "arxiv:2406.09414",
            "arxiv:2401.10891",
            "license:cc-by-nc-4.0",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 975451,
          "likes": 2
        },
        {
          "id": "depth-anything/Depth-Anything-V2-Large-hf",
          "type": "hf.depth_estimation",
          "name": "depth-anything/Depth-Anything-V2-Large-hf",
          "repo_id": "depth-anything/Depth-Anything-V2-Large-hf",
          "size_on_disk": 1341331020,
          "pipeline_tag": "depth-estimation",
          "tags": [
            "transformers",
            "safetensors",
            "depth_anything",
            "depth-estimation",
            "depth",
            "relative depth",
            "arxiv:2406.09414",
            "arxiv:2401.10891",
            "license:cc-by-nc-4.0",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 821798,
          "likes": 27
        },
        {
          "id": "Intel/dpt-large",
          "type": "hf.depth_estimation",
          "name": "Intel/dpt-large",
          "repo_id": "Intel/dpt-large",
          "allow_patterns": [
            "README.md",
            "*.safetensors",
            "*.json",
            "**/*.json",
            "txt"
          ],
          "size_on_disk": 1367465032,
          "pipeline_tag": "depth-estimation",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "dpt",
            "depth-estimation",
            "vision",
            "arxiv:2103.13413",
            "license:apache-2.0",
            "model-index",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 127180,
          "likes": 197
        }
      ],
      "basic_fields": [
        "model",
        "image"
      ]
    },
    {
      "title": "Token Classification",
      "description": "Performs token classification tasks such as Named Entity Recognition (NER).\n    text, token classification, named entity recognition, natural language processing\n\n    Use cases:\n    - Named Entity Recognition in text\n    - Part-of-speech tagging\n    - Chunking and shallow parsing\n    - Information extraction from unstructured text",
      "namespace": "huggingface.token_classification",
      "node_type": "huggingface.token_classification.TokenClassification",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.token_classification"
          },
          "default": {
            "type": "hf.token_classification",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for token classification"
        },
        {
          "name": "inputs",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Input Text",
          "description": "The input text for token classification"
        },
        {
          "name": "aggregation_strategy",
          "type": {
            "type": "enum",
            "values": [
              "simple",
              "first",
              "average",
              "max"
            ],
            "type_name": "nodetool.nodes.huggingface.token_classification.TokenClassification.AggregationStrategy"
          },
          "default": "simple",
          "title": "Aggregation Strategy",
          "description": "Strategy to aggregate tokens into entities"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "dataframe"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "model",
        "inputs",
        "aggregation_strategy"
      ]
    },
    {
      "title": "Find Segment",
      "description": "Extracts a specific segment from a list of segmentation masks.\n    image, segmentation, object detection, mask",
      "namespace": "huggingface.image_segmentation",
      "node_type": "huggingface.image_segmentation.FindSegment",
      "properties": [
        {
          "name": "segments",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "image_segmentation_result"
              }
            ]
          },
          "default": [],
          "title": "Segmentation Masks",
          "description": "The segmentation masks to search"
        },
        {
          "name": "segment_label",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Label",
          "description": "The label of the segment to extract"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "segments",
        "segment_label"
      ]
    },
    {
      "title": "SAM2 Segmentation",
      "description": "Performs semantic segmentation on images using SAM2 (Segment Anything Model 2).\n    image, segmentation, object detection, scene parsing, mask\n\n    Use cases:\n    - Automatic segmentation of objects in images\n    - Instance segmentation for computer vision tasks\n    - Interactive segmentation with point prompts\n    - Scene understanding and object detection",
      "namespace": "huggingface.image_segmentation",
      "node_type": "huggingface.image_segmentation.SAM2Segmentation",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Input Image",
          "description": "The input image to segment"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "image"
              }
            ]
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "facebook/sam2-hiera-large",
          "type": "hf.model",
          "name": "facebook/sam2-hiera-large",
          "repo_id": "facebook/sam2-hiera-large",
          "size_on_disk": 1795815850,
          "pipeline_tag": "mask-generation",
          "tags": [
            "transformers",
            "safetensors",
            "sam2_video",
            "feature-extraction",
            "mask-generation",
            "arxiv:2408.00714",
            "license:apache-2.0",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 200638,
          "likes": 113
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Image Segmentation",
      "description": "Performs semantic segmentation on images, identifying and labeling different regions.\n    image, segmentation, object detection, scene parsing\n\n    Use cases:\n    - Segmenting objects in images\n    - Segmenting facial features in images",
      "namespace": "huggingface.image_segmentation",
      "node_type": "huggingface.image_segmentation.Segmentation",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.image_segmentation"
          },
          "default": {
            "type": "hf.image_segmentation",
            "repo_id": "nvidia/segformer-b3-finetuned-ade-512-512",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for the segmentation"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The input image to segment"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "image_segmentation_result"
              }
            ]
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "nvidia/segformer-b3-finetuned-ade-512-512",
          "type": "hf.image_segmentation",
          "name": "nvidia/segformer-b3-finetuned-ade-512-512",
          "repo_id": "nvidia/segformer-b3-finetuned-ade-512-512",
          "allow_patterns": [
            "README.md",
            "*.bin",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 189618295,
          "pipeline_tag": "image-segmentation",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "segformer",
            "vision",
            "image-segmentation",
            "dataset:scene_parse_150",
            "arxiv:2105.15203",
            "license:other",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 13273,
          "likes": 12
        },
        {
          "id": "mattmdjaga/segformer_b2_clothes",
          "type": "hf.image_segmentation",
          "name": "mattmdjaga/segformer_b2_clothes",
          "repo_id": "mattmdjaga/segformer_b2_clothes",
          "allow_patterns": [
            "README.md",
            "*.bin",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 109887076,
          "pipeline_tag": "image-segmentation",
          "tags": [
            "transformers",
            "pytorch",
            "onnx",
            "safetensors",
            "segformer",
            "vision",
            "image-segmentation",
            "dataset:mattmdjaga/human_parsing_dataset",
            "arxiv:2105.15203",
            "license:other",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 138670,
          "likes": 464
        }
      ],
      "basic_fields": [
        "model",
        "image"
      ]
    },
    {
      "title": "Visualize Segmentation",
      "description": "Visualizes segmentation masks on images with labels.\n    image, segmentation, visualization, mask\n\n    Use cases:\n    - Visualize results of image segmentation models\n    - Analyze and compare different segmentation techniques\n    - Create labeled images for presentations or reports",
      "namespace": "huggingface.image_segmentation",
      "node_type": "huggingface.image_segmentation.VisualizeSegmentation",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The input image to visualize"
        },
        {
          "name": "segments",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "image_segmentation_result"
              }
            ]
          },
          "default": [],
          "title": "Segmentation Masks",
          "description": "The segmentation masks to visualize"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "segments"
      ]
    },
    {
      "title": "Image Classifier",
      "description": "Classifies images into predefined categories.\n    image, classification, labeling, categorization\n\n    Use cases:\n    - Content moderation by detecting inappropriate images\n    - Organizing photo libraries by automatically tagging images",
      "namespace": "huggingface.image_classification",
      "node_type": "huggingface.image_classification.ImageClassifier",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.image_classification"
          },
          "default": {
            "type": "hf.image_classification",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for the classification"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The input image to classify"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "dict",
            "type_args": [
              {
                "type": "str"
              },
              {
                "type": "float"
              }
            ]
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "google/vit-base-patch16-224",
          "type": "hf.image_classification",
          "name": "google/vit-base-patch16-224",
          "repo_id": "google/vit-base-patch16-224",
          "allow_patterns": [
            "README.md",
            "*.safetensors",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 346369365,
          "pipeline_tag": "image-classification",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "jax",
            "safetensors",
            "vit",
            "image-classification",
            "vision",
            "dataset:imagenet-1k",
            "dataset:imagenet-21k",
            "arxiv:2010.11929",
            "arxiv:2006.03677",
            "license:apache-2.0",
            "autotrain_compatible",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 3288870,
          "likes": 896
        },
        {
          "id": "microsoft/resnet-50",
          "type": "hf.image_classification",
          "name": "microsoft/resnet-50",
          "repo_id": "microsoft/resnet-50",
          "allow_patterns": [
            "README.md",
            "*.safetensors",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 102555318,
          "pipeline_tag": "image-classification",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "jax",
            "safetensors",
            "resnet",
            "image-classification",
            "vision",
            "dataset:imagenet-1k",
            "arxiv:1512.03385",
            "license:apache-2.0",
            "autotrain_compatible",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 254629,
          "likes": 459
        },
        {
          "id": "microsoft/resnet-18",
          "type": "hf.image_classification",
          "name": "microsoft/resnet-18",
          "repo_id": "microsoft/resnet-18",
          "allow_patterns": [
            "README.md",
            "*.safetensors",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 46884396,
          "pipeline_tag": "image-classification",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "safetensors",
            "resnet",
            "image-classification",
            "vision",
            "dataset:imagenet-1k",
            "arxiv:1512.03385",
            "license:apache-2.0",
            "autotrain_compatible",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 177678,
          "likes": 61
        },
        {
          "id": "apple/mobilevit-small",
          "type": "hf.image_classification",
          "name": "apple/mobilevit-small",
          "repo_id": "apple/mobilevit-small",
          "allow_patterns": [
            "README.md",
            "*.bin",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 44860946,
          "pipeline_tag": "image-classification",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "coreml",
            "mobilevit",
            "image-classification",
            "vision",
            "dataset:imagenet-1k",
            "arxiv:2110.02178",
            "license:other",
            "autotrain_compatible",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 1439008,
          "likes": 82
        },
        {
          "id": "apple/mobilevit-xx-small",
          "type": "hf.image_classification",
          "name": "apple/mobilevit-xx-small",
          "repo_id": "apple/mobilevit-xx-small",
          "allow_patterns": [
            "README.md",
            "*.bin",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 10391397,
          "pipeline_tag": "image-classification",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "coreml",
            "mobilevit",
            "image-classification",
            "vision",
            "dataset:imagenet-1k",
            "arxiv:2110.02178",
            "license:other",
            "autotrain_compatible",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 6870,
          "likes": 20
        },
        {
          "id": "nateraw/vit-age-classifier",
          "type": "hf.image_classification",
          "name": "nateraw/vit-age-classifier",
          "repo_id": "nateraw/vit-age-classifier",
          "allow_patterns": [
            "README.md",
            "*.safetensors",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 343247506,
          "pipeline_tag": "image-classification",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "vit",
            "image-classification",
            "dataset:nateraw/fairface",
            "doi:10.57967/hf/1259",
            "autotrain_compatible",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 421769,
          "likes": 141
        },
        {
          "id": "Falconsai/nsfw_image_detection",
          "type": "hf.image_classification",
          "name": "Falconsai/nsfw_image_detection",
          "repo_id": "Falconsai/nsfw_image_detection",
          "allow_patterns": [
            "README.md",
            "*.safetensors",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 343234197,
          "pipeline_tag": "image-classification",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "vit",
            "image-classification",
            "arxiv:2010.11929",
            "license:apache-2.0",
            "autotrain_compatible",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 70681193,
          "likes": 890
        },
        {
          "id": "rizvandwiki/gender-classification-2",
          "type": "hf.image_classification",
          "name": "rizvandwiki/gender-classification-2",
          "repo_id": "rizvandwiki/gender-classification-2",
          "allow_patterns": [
            "README.md",
            "*.safetensors",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 343225777,
          "pipeline_tag": "image-classification",
          "tags": [
            "transformers",
            "pytorch",
            "tensorboard",
            "safetensors",
            "vit",
            "image-classification",
            "huggingpics",
            "model-index",
            "autotrain_compatible",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 419349,
          "likes": 36
        }
      ],
      "basic_fields": [
        "model",
        "image"
      ]
    },
    {
      "title": "Zero-Shot Image Classifier",
      "description": "Classifies images into categories without the need for training data.\n    image, classification, labeling, categorization\n\n    Use cases:\n    - Quickly categorize images without training data\n    - Identify objects in images without predefined labels\n    - Automate image tagging for large datasets",
      "namespace": "huggingface.image_classification",
      "node_type": "huggingface.image_classification.ZeroShotImageClassifier",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.zero_shot_image_classification"
          },
          "default": {
            "type": "hf.zero_shot_image_classification",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for the classification"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The input image to classify"
        },
        {
          "name": "candidate_labels",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Candidate Labels",
          "description": "The candidate labels to classify the image against, separated by commas"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "dict",
            "type_args": [
              {
                "type": "str"
              },
              {
                "type": "float"
              }
            ]
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "openai/clip-vit-base-patch32",
          "type": "hf.zero_shot_image_classification",
          "name": "openai/clip-vit-base-patch32",
          "repo_id": "openai/clip-vit-base-patch32",
          "allow_patterns": [
            "README.md",
            "pytorch_model.bin",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 608871522,
          "pipeline_tag": "zero-shot-image-classification",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "jax",
            "clip",
            "zero-shot-image-classification",
            "vision",
            "arxiv:2103.00020",
            "arxiv:1908.04913",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 19197138,
          "likes": 808
        },
        {
          "id": "laion/CLIP-ViT-H-14-laion2B-s32B-b79K",
          "type": "hf.zero_shot_image_classification",
          "name": "laion/CLIP-ViT-H-14-laion2B-s32B-b79K",
          "repo_id": "laion/CLIP-ViT-H-14-laion2B-s32B-b79K",
          "allow_patterns": [
            "README.md",
            "pytorch_model.bin",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 3948362264,
          "pipeline_tag": "zero-shot-image-classification",
          "tags": [
            "open_clip",
            "pytorch",
            "safetensors",
            "clip",
            "zero-shot-image-classification",
            "arxiv:1910.04867",
            "license:mit",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 1358326,
          "likes": 419
        },
        {
          "id": "laion/CLIP-ViT-g-14-laion2B-s12B-b42K",
          "type": "hf.zero_shot_image_classification",
          "name": "laion/CLIP-ViT-g-14-laion2B-s12B-b42K",
          "repo_id": "laion/CLIP-ViT-g-14-laion2B-s12B-b42K",
          "allow_patterns": [
            "README.md",
            "pytorch_model.bin",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 5470681040,
          "tags": [
            "open_clip",
            "pytorch",
            "safetensors",
            "clip",
            "arxiv:1910.04867",
            "license:mit",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 54467,
          "likes": 44
        }
      ],
      "basic_fields": [
        "model",
        "image",
        "candidate_labels"
      ]
    },
    {
      "title": "Wan (Image-to-Video)",
      "description": "Generates a video from an input image using Wan image-to-video pipelines.\n    video, generation, AI, image-to-video, diffusion, Wan\n\n    Use cases:\n    - Turn a single image into a dynamic clip with prompt guidance\n    - Choose between Wan 2.2 A14B, Wan 2.1 14B 480P, and Wan 2.1 14B 720P models",
      "namespace": "huggingface.image_to_video",
      "node_type": "huggingface.image_to_video.Wan_I2V",
      "properties": [
        {
          "name": "input_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Input Image",
          "description": "The input image to generate the video from."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "An astronaut walking on the moon, cinematic lighting, high detail",
          "title": "Prompt",
          "description": "A text prompt describing the desired video."
        },
        {
          "name": "model_variant",
          "type": {
            "type": "enum",
            "values": [
              "Wan-AI/Wan2.2-I2V-A14B-Diffusers",
              "Wan-AI/Wan2.1-I2V-14B-480P-Diffusers",
              "Wan-AI/Wan2.1-I2V-14B-720P-Diffusers"
            ],
            "type_name": "nodetool.nodes.huggingface.image_to_video.Wan_I2V.WanI2VModel"
          },
          "default": "Wan-AI/Wan2.2-I2V-A14B-Diffusers",
          "title": "Model Variant",
          "description": "Select the Wan I2V model to use."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "A text prompt describing what to avoid in the video."
        },
        {
          "name": "num_frames",
          "type": {
            "type": "int"
          },
          "default": 81,
          "title": "Num Frames",
          "description": "The number of frames in the video.",
          "min": 16.0,
          "max": 129.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "The scale for classifier-free guidance.",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "The number of denoising steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 480,
          "title": "Height",
          "description": "The height of the generated video in pixels.",
          "min": 256.0,
          "max": 1080.0
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 832,
          "title": "Width",
          "description": "The width of the generated video in pixels.",
          "min": 256.0,
          "max": 1920.0
        },
        {
          "name": "fps",
          "type": {
            "type": "int"
          },
          "default": 16,
          "title": "Fps",
          "description": "Frames per second for the output video.",
          "min": 1.0,
          "max": 60.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0
        },
        {
          "name": "max_sequence_length",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Max Sequence Length",
          "description": "Maximum sequence length in encoded prompt.",
          "min": 64.0,
          "max": 1024.0
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload to reduce VRAM usage."
        },
        {
          "name": "enable_vae_slicing",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Vae Slicing",
          "description": "Enable VAE slicing to reduce VRAM usage."
        },
        {
          "name": "enable_vae_tiling",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Vae Tiling",
          "description": "Enable VAE tiling to reduce VRAM usage for large videos."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "Wan-AI/Wan2.2-I2V-A14B-Diffusers",
          "type": "hf.text_to_video",
          "name": "Wan-AI/Wan2.2-I2V-A14B-Diffusers",
          "repo_id": "Wan-AI/Wan2.2-I2V-A14B-Diffusers",
          "allow_patterns": [
            "**/*.safetensors",
            "**/*.json",
            "**/*.txt",
            "*.json"
          ],
          "size_on_disk": 126198002795,
          "pipeline_tag": "image-to-video",
          "tags": [
            "diffusers",
            "safetensors",
            "image-to-video",
            "en",
            "zh",
            "arxiv:2503.20314",
            "license:apache-2.0",
            "diffusers:WanImageToVideoPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 103628,
          "likes": 163
        },
        {
          "id": "Wan-AI/Wan2.1-I2V-14B-480P-Diffusers",
          "type": "hf.text_to_video",
          "name": "Wan-AI/Wan2.1-I2V-14B-480P-Diffusers",
          "repo_id": "Wan-AI/Wan2.1-I2V-14B-480P-Diffusers",
          "allow_patterns": [
            "**/*.safetensors",
            "**/*.json",
            "**/*.txt",
            "*.json"
          ],
          "size_on_disk": 90093008067,
          "pipeline_tag": "image-to-video",
          "tags": [
            "diffusers",
            "safetensors",
            "video",
            "video-generation",
            "image-to-video",
            "en",
            "zh",
            "license:apache-2.0",
            "diffusers:WanImageToVideoPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 96839,
          "likes": 57
        },
        {
          "id": "Wan-AI/Wan2.1-I2V-14B-720P-Diffusers",
          "type": "hf.text_to_video",
          "name": "Wan-AI/Wan2.1-I2V-14B-720P-Diffusers",
          "repo_id": "Wan-AI/Wan2.1-I2V-14B-720P-Diffusers",
          "allow_patterns": [
            "**/*.safetensors",
            "**/*.json",
            "**/*.txt",
            "*.json"
          ],
          "size_on_disk": 90093008067,
          "pipeline_tag": "image-to-video",
          "tags": [
            "diffusers",
            "safetensors",
            "video",
            "video genration",
            "image-to-video",
            "en",
            "zh",
            "license:apache-2.0",
            "diffusers:WanImageToVideoPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 27168,
          "likes": 47
        }
      ],
      "basic_fields": [
        "input_image",
        "prompt",
        "num_frames",
        "height",
        "width",
        "model_variant"
      ]
    },
    {
      "title": "Reranker",
      "description": "Reranks pairs of text based on their semantic similarity.\n    text, ranking, reranking, natural language processing\n\n    Use cases:\n    - Improve search results ranking\n    - Question-answer pair scoring\n    - Document relevance ranking",
      "namespace": "huggingface.ranking",
      "node_type": "huggingface.ranking.Reranker",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.reranker"
          },
          "default": {
            "type": "hf.reranker",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for reranking"
        },
        {
          "name": "query",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Query Text",
          "description": "The query text to compare against candidates"
        },
        {
          "name": "candidates",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Candidate Texts",
          "description": "List of candidate texts to rank"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "dict",
            "type_args": [
              {
                "type": "str"
              },
              {
                "type": "float"
              }
            ]
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "BAAI/bge-reranker-v2-m3",
          "type": "hf.reranker",
          "name": "BAAI/bge-reranker-v2-m3",
          "repo_id": "BAAI/bge-reranker-v2-m3",
          "allow_patterns": [
            "*.safetensors",
            "*.txt",
            "*.json"
          ],
          "size_on_disk": 2288173057,
          "pipeline_tag": "text-classification",
          "tags": [
            "sentence-transformers",
            "safetensors",
            "xlm-roberta",
            "text-classification",
            "transformers",
            "text-embeddings-inference",
            "multilingual",
            "arxiv:2312.15503",
            "arxiv:2402.03216",
            "license:apache-2.0",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 2892404,
          "likes": 799
        },
        {
          "id": "BAAI/bge-reranker-base",
          "type": "hf.reranker",
          "name": "BAAI/bge-reranker-base",
          "repo_id": "BAAI/bge-reranker-base",
          "allow_patterns": [
            "*.safetensors",
            "*.txt",
            "*.json"
          ],
          "size_on_disk": 1129305768,
          "pipeline_tag": "text-classification",
          "tags": [
            "sentence-transformers",
            "pytorch",
            "onnx",
            "safetensors",
            "xlm-roberta",
            "mteb",
            "text-embeddings-inference",
            "text-classification",
            "en",
            "zh",
            "arxiv:2401.03462",
            "arxiv:2312.15503",
            "arxiv:2311.13534",
            "arxiv:2310.07554",
            "arxiv:2309.07597",
            "license:mit",
            "model-index",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 1259983,
          "likes": 215
        },
        {
          "id": "BAAI/bge-reranker-large",
          "type": "hf.reranker",
          "name": "BAAI/bge-reranker-large",
          "repo_id": "BAAI/bge-reranker-large",
          "allow_patterns": [
            "*.safetensors",
            "*.txt",
            "*.json"
          ],
          "size_on_disk": 2256718402,
          "pipeline_tag": "feature-extraction",
          "tags": [
            "transformers",
            "pytorch",
            "onnx",
            "safetensors",
            "xlm-roberta",
            "text-classification",
            "mteb",
            "feature-extraction",
            "en",
            "zh",
            "arxiv:2401.03462",
            "arxiv:2312.15503",
            "arxiv:2311.13534",
            "arxiv:2310.07554",
            "arxiv:2309.07597",
            "license:mit",
            "model-index",
            "autotrain_compatible",
            "text-embeddings-inference",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 1076049,
          "likes": 434
        }
      ],
      "basic_fields": [
        "model",
        "query",
        "candidates"
      ]
    },
    {
      "title": "Text Classifier",
      "description": "Classifies text into predefined categories using a Hugging Face model.\n    text, classification, zero-shot, natural language processing",
      "namespace": "huggingface.text_classification",
      "node_type": "huggingface.text_classification.TextClassifier",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.text_classification"
          },
          "default": {
            "type": "hf.text_classification",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for the classification"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Inputs",
          "description": "The input text to the model"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "dict",
            "type_args": [
              {
                "type": "str"
              },
              {
                "type": "float"
              }
            ]
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "cardiffnlp/twitter-roberta-base-sentiment-latest",
          "type": "hf.text_classification",
          "name": "cardiffnlp/twitter-roberta-base-sentiment-latest",
          "repo_id": "cardiffnlp/twitter-roberta-base-sentiment-latest",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.bin"
          ],
          "size_on_disk": 502401839,
          "pipeline_tag": "text-classification",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "roberta",
            "text-classification",
            "en",
            "dataset:tweet_eval",
            "arxiv:2202.03829",
            "license:cc-by-4.0",
            "autotrain_compatible",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 4642720,
          "likes": 732
        },
        {
          "id": "michellejieli/emotion_text_classifier",
          "type": "hf.text_classification",
          "name": "michellejieli/emotion_text_classifier",
          "repo_id": "michellejieli/emotion_text_classifier",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.bin"
          ],
          "size_on_disk": 331902714,
          "pipeline_tag": "text-classification",
          "tags": [
            "transformers",
            "pytorch",
            "roberta",
            "text-classification",
            "distilroberta",
            "sentiment",
            "emotion",
            "twitter",
            "reddit",
            "en",
            "autotrain_compatible",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 1319902,
          "likes": 139
        }
      ],
      "basic_fields": [
        "model",
        "prompt"
      ]
    },
    {
      "title": "Zero Shot Text Classifier",
      "description": "Performs zero-shot classification on text.\n    text, classification, zero-shot, natural language processing\n\n    Use cases:\n    - Classify text into custom categories without training\n    - Topic detection in documents\n    - Sentiment analysis with custom sentiment labels\n    - Intent classification in conversational AI",
      "namespace": "huggingface.text_classification",
      "node_type": "huggingface.text_classification.ZeroShotTextClassifier",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.zero_shot_classification"
          },
          "default": {
            "type": "hf.zero_shot_classification",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for zero-shot classification"
        },
        {
          "name": "inputs",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Input Text",
          "description": "The text to classify"
        },
        {
          "name": "candidate_labels",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Candidate Labels",
          "description": "Comma-separated list of candidate labels for classification"
        },
        {
          "name": "multi_label",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Multi-label Classification",
          "description": "Whether to perform multi-label classification"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "dict",
            "type_args": [
              {
                "type": "str"
              },
              {
                "type": "float"
              }
            ]
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "facebook/bart-large-mnli",
          "type": "hf.zero_shot_classification",
          "name": "facebook/bart-large-mnli",
          "repo_id": "facebook/bart-large-mnli",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 1632149330,
          "pipeline_tag": "zero-shot-classification",
          "tags": [
            "transformers",
            "pytorch",
            "jax",
            "rust",
            "safetensors",
            "bart",
            "text-classification",
            "zero-shot-classification",
            "dataset:multi_nli",
            "arxiv:1910.13461",
            "arxiv:1909.00161",
            "license:mit",
            "autotrain_compatible",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 3657160,
          "likes": 1483
        },
        {
          "id": "MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli",
          "type": "hf.zero_shot_classification",
          "name": "MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli",
          "repo_id": "MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 377536975,
          "pipeline_tag": "zero-shot-classification",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "deberta-v2",
            "text-classification",
            "zero-shot-classification",
            "en",
            "dataset:multi_nli",
            "dataset:facebook/anli",
            "dataset:fever",
            "arxiv:2006.03654",
            "license:mit",
            "model-index",
            "autotrain_compatible",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 190403,
          "likes": 219
        },
        {
          "id": "MoritzLaurer/mDeBERTa-v3-base-mnli-xnli",
          "type": "hf.zero_shot_classification",
          "name": "MoritzLaurer/mDeBERTa-v3-base-mnli-xnli",
          "repo_id": "MoritzLaurer/mDeBERTa-v3-base-mnli-xnli",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 573986073,
          "pipeline_tag": "zero-shot-classification",
          "tags": [
            "transformers",
            "pytorch",
            "onnx",
            "safetensors",
            "deberta-v2",
            "text-classification",
            "zero-shot-classification",
            "nli",
            "multilingual",
            "en",
            "ar",
            "bg",
            "de",
            "el",
            "es",
            "fr",
            "hi",
            "ru",
            "sw",
            "th",
            "tr",
            "ur",
            "vi",
            "zh",
            "dataset:multi_nli",
            "dataset:xnli",
            "arxiv:2111.09543",
            "arxiv:1809.05053",
            "arxiv:1911.02116",
            "license:mit",
            "autotrain_compatible",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 271285,
          "likes": 274
        },
        {
          "id": "tasksource/ModernBERT-base-nli",
          "type": "hf.zero_shot_classification",
          "name": "tasksource/ModernBERT-base-nli",
          "repo_id": "tasksource/ModernBERT-base-nli",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 602053461,
          "pipeline_tag": "zero-shot-classification",
          "tags": [
            "transformers",
            "safetensors",
            "modernbert",
            "text-classification",
            "instruct",
            "natural-language-inference",
            "nli",
            "mnli",
            "zero-shot-classification",
            "en",
            "dataset:nyu-mll/glue",
            "dataset:facebook/anli",
            "base_model:answerdotai/ModernBERT-base",
            "base_model:finetune:answerdotai/ModernBERT-base",
            "license:apache-2.0",
            "autotrain_compatible",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 2226,
          "likes": 22
        },
        {
          "id": "cross-encoder/nli-deberta-v3-base",
          "type": "hf.zero_shot_classification",
          "name": "cross-encoder/nli-deberta-v3-base",
          "repo_id": "cross-encoder/nli-deberta-v3-base",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 746385901,
          "pipeline_tag": "zero-shot-classification",
          "tags": [
            "sentence-transformers",
            "pytorch",
            "onnx",
            "safetensors",
            "deberta-v2",
            "text-classification",
            "transformers",
            "zero-shot-classification",
            "en",
            "dataset:nyu-mll/multi_nli",
            "dataset:stanfordnlp/snli",
            "base_model:microsoft/deberta-v3-base",
            "base_model:quantized:microsoft/deberta-v3-base",
            "license:apache-2.0",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 28352,
          "likes": 37
        },
        {
          "id": "microsoft/deberta-v2-xlarge-mnli",
          "type": "hf.zero_shot_classification",
          "name": "microsoft/deberta-v2-xlarge-mnli",
          "repo_id": "microsoft/deberta-v2-xlarge-mnli",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 1022,
          "pipeline_tag": "text-classification",
          "tags": [
            "transformers",
            "pytorch",
            "deberta-v2",
            "text-classification",
            "deberta",
            "deberta-mnli",
            "en",
            "arxiv:2006.03654",
            "license:mit",
            "autotrain_compatible",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 75568,
          "likes": 9
        },
        {
          "id": "roberta-large-mnli",
          "type": "hf.zero_shot_classification",
          "name": "roberta-large-mnli",
          "repo_id": "roberta-large-mnli",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 1428409833,
          "pipeline_tag": "text-classification",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "jax",
            "safetensors",
            "roberta",
            "text-classification",
            "autogenerated-modelcard",
            "en",
            "dataset:multi_nli",
            "dataset:wikipedia",
            "dataset:bookcorpus",
            "arxiv:1907.11692",
            "arxiv:1806.02847",
            "arxiv:1804.07461",
            "arxiv:1704.05426",
            "arxiv:1508.05326",
            "arxiv:1809.05053",
            "arxiv:1910.09700",
            "license:mit",
            "autotrain_compatible",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 738650,
          "likes": 199
        }
      ],
      "basic_fields": [
        "model",
        "inputs",
        "candidate_labels",
        "multi_label"
      ]
    },
    {
      "title": "Chunks To SRT",
      "description": "Convert audio chunks to SRT (SubRip Subtitle) format\n    subtitle, srt, whisper, transcription\n\n    **Use Cases:**\n    - Generate subtitles for videos\n    - Create closed captions from audio transcriptions\n    - Convert speech-to-text output to a standardized subtitle format\n\n    **Features:**\n    - Converts Whisper audio chunks to SRT format\n    - Supports customizable time offset\n    - Generates properly formatted SRT file content",
      "namespace": "huggingface.automatic_speech_recognition",
      "node_type": "huggingface.automatic_speech_recognition.ChunksToSRT",
      "properties": [
        {
          "name": "chunks",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "audio_chunk"
              }
            ]
          },
          "default": [],
          "title": "Audio Chunks",
          "description": "List of audio chunks from Whisper transcription"
        },
        {
          "name": "time_offset",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Time Offset",
          "description": "Time offset in seconds to apply to all timestamps"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "chunks",
        "time_offset"
      ]
    },
    {
      "title": "Whisper",
      "description": "Convert speech to text\n    asr, automatic-speech-recognition, speech-to-text, translate, transcribe, audio, huggingface\n\n    **Use Cases:**\n    - Voice input for a chatbot\n    - Transcribe or translate audio files\n    - Create subtitles for videos\n\n    **Features:**\n    - Multilingual speech recognition\n    - Speech translation\n    - Language identification\n\n    **Note**\n    - Language selection is sorted by word error rate in the FLEURS benchmark\n    - There are many variants of Whisper that are optimized for different use cases.\n\n    **Links:**\n    - https://github.com/openai/whisper\n    - https://platform.openai.com/docs/guides/speech-to-text/supported-languages",
      "namespace": "huggingface.automatic_speech_recognition",
      "node_type": "huggingface.automatic_speech_recognition.Whisper",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.automatic_speech_recognition"
          },
          "default": {
            "type": "hf.automatic_speech_recognition",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for the speech recognition."
        },
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Audio Input",
          "description": "The input audio to transcribe."
        },
        {
          "name": "task",
          "type": {
            "type": "enum",
            "values": [
              "transcribe",
              "translate"
            ],
            "type_name": "nodetool.nodes.huggingface.automatic_speech_recognition.Task"
          },
          "default": "transcribe",
          "title": "Task",
          "description": "The task to perform: 'transcribe' for speech-to-text or 'translate' for speech translation."
        },
        {
          "name": "language",
          "type": {
            "type": "enum",
            "values": [
              "auto_detect",
              "spanish",
              "italian",
              "korean",
              "portuguese",
              "english",
              "japanese",
              "german",
              "russian",
              "dutch",
              "polish",
              "catalan",
              "french",
              "indonesian",
              "ukrainian",
              "turkish",
              "malay",
              "swedish",
              "mandarin",
              "finnish",
              "norwegian",
              "romanian",
              "thai",
              "vietnamese",
              "slovak",
              "arabic",
              "czech",
              "croatian",
              "greek",
              "serbian",
              "danish",
              "bulgarian",
              "hungarian",
              "filipino",
              "bosnian",
              "galician",
              "macedonian",
              "hindi",
              "estonian",
              "slovenian",
              "tamil",
              "latvian",
              "azerbaijani",
              "urdu",
              "lithuanian",
              "hebrew",
              "welsh",
              "persian",
              "icelandic",
              "kazakh",
              "afrikaans",
              "kannada",
              "marathi",
              "swahili",
              "telugu",
              "maori",
              "nepali",
              "armenian",
              "belarusian",
              "gujarati",
              "punjabi",
              "bengali"
            ],
            "type_name": "nodetool.nodes.huggingface.automatic_speech_recognition.WhisperLanguage"
          },
          "default": "auto_detect",
          "title": "Language",
          "description": "The language of the input audio. If not specified, the model will attempt to detect it automatically."
        },
        {
          "name": "timestamps",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "word",
              "sentence"
            ],
            "type_name": "nodetool.nodes.huggingface.automatic_speech_recognition.Timestamps"
          },
          "default": "none",
          "title": "Timestamps",
          "description": "The type of timestamps to return for the generated text."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "text"
        },
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "audio_chunk"
              }
            ]
          },
          "name": "chunks"
        }
      ],
      "recommended_models": [
        {
          "id": "openai/whisper-large-v3",
          "type": "hf.automatic_speech_recognition",
          "name": "openai/whisper-large-v3",
          "repo_id": "openai/whisper-large-v3",
          "allow_patterns": [
            "model.safetensors",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 3091755614,
          "pipeline_tag": "automatic-speech-recognition",
          "tags": [
            "transformers",
            "pytorch",
            "jax",
            "safetensors",
            "whisper",
            "automatic-speech-recognition",
            "audio",
            "hf-asr-leaderboard",
            "en",
            "zh",
            "de",
            "es",
            "ru",
            "ko",
            "fr",
            "ja",
            "pt",
            "tr",
            "pl",
            "ca",
            "nl",
            "ar",
            "sv",
            "it",
            "id",
            "hi",
            "fi",
            "vi",
            "he",
            "uk",
            "el",
            "ms",
            "cs",
            "ro",
            "da",
            "hu",
            "ta",
            "no",
            "th",
            "ur",
            "hr",
            "bg",
            "lt",
            "la",
            "mi",
            "ml",
            "cy",
            "sk",
            "te",
            "fa",
            "lv",
            "bn",
            "sr",
            "az",
            "sl",
            "kn",
            "et",
            "mk",
            "br",
            "eu",
            "is",
            "hy",
            "ne",
            "mn",
            "bs",
            "kk",
            "sq",
            "sw",
            "gl",
            "mr",
            "pa",
            "si",
            "km",
            "sn",
            "yo",
            "so",
            "af",
            "oc",
            "ka",
            "be",
            "tg",
            "sd",
            "gu",
            "am",
            "yi",
            "lo",
            "uz",
            "fo",
            "ht",
            "ps",
            "tk",
            "nn",
            "mt",
            "sa",
            "lb",
            "my",
            "bo",
            "tl",
            "mg",
            "as",
            "tt",
            "haw",
            "ln",
            "ha",
            "ba",
            "jw",
            "su",
            "arxiv:2212.04356",
            "license:apache-2.0",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 4466952,
          "likes": 5125
        },
        {
          "id": "openai/whisper-large-v3-turbo",
          "type": "hf.automatic_speech_recognition",
          "name": "openai/whisper-large-v3-turbo",
          "repo_id": "openai/whisper-large-v3-turbo",
          "allow_patterns": [
            "model.safetensors",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 1622443339,
          "pipeline_tag": "automatic-speech-recognition",
          "tags": [
            "transformers",
            "safetensors",
            "whisper",
            "automatic-speech-recognition",
            "audio",
            "en",
            "zh",
            "de",
            "es",
            "ru",
            "ko",
            "fr",
            "ja",
            "pt",
            "tr",
            "pl",
            "ca",
            "nl",
            "ar",
            "sv",
            "it",
            "id",
            "hi",
            "fi",
            "vi",
            "he",
            "uk",
            "el",
            "ms",
            "cs",
            "ro",
            "da",
            "hu",
            "ta",
            "no",
            "th",
            "ur",
            "hr",
            "bg",
            "lt",
            "la",
            "mi",
            "ml",
            "cy",
            "sk",
            "te",
            "fa",
            "lv",
            "bn",
            "sr",
            "az",
            "sl",
            "kn",
            "et",
            "mk",
            "br",
            "eu",
            "is",
            "hy",
            "ne",
            "mn",
            "bs",
            "kk",
            "sq",
            "sw",
            "gl",
            "mr",
            "pa",
            "si",
            "km",
            "sn",
            "yo",
            "so",
            "af",
            "oc",
            "ka",
            "be",
            "tg",
            "sd",
            "gu",
            "am",
            "yi",
            "lo",
            "uz",
            "fo",
            "ht",
            "ps",
            "tk",
            "nn",
            "mt",
            "sa",
            "lb",
            "my",
            "bo",
            "tl",
            "mg",
            "as",
            "tt",
            "haw",
            "ln",
            "ha",
            "ba",
            "jw",
            "su",
            "arxiv:2212.04356",
            "base_model:openai/whisper-large-v3",
            "base_model:finetune:openai/whisper-large-v3",
            "license:mit",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 4318046,
          "likes": 2700
        },
        {
          "id": "openai/whisper-large-v2",
          "type": "hf.automatic_speech_recognition",
          "name": "openai/whisper-large-v2",
          "repo_id": "openai/whisper-large-v2",
          "allow_patterns": [
            "model.safetensors",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 6177743461,
          "pipeline_tag": "automatic-speech-recognition",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "jax",
            "safetensors",
            "whisper",
            "automatic-speech-recognition",
            "audio",
            "hf-asr-leaderboard",
            "en",
            "zh",
            "de",
            "es",
            "ru",
            "ko",
            "fr",
            "ja",
            "pt",
            "tr",
            "pl",
            "ca",
            "nl",
            "ar",
            "sv",
            "it",
            "id",
            "hi",
            "fi",
            "vi",
            "he",
            "uk",
            "el",
            "ms",
            "cs",
            "ro",
            "da",
            "hu",
            "ta",
            "no",
            "th",
            "ur",
            "hr",
            "bg",
            "lt",
            "la",
            "mi",
            "ml",
            "cy",
            "sk",
            "te",
            "fa",
            "lv",
            "bn",
            "sr",
            "az",
            "sl",
            "kn",
            "et",
            "mk",
            "br",
            "eu",
            "is",
            "hy",
            "ne",
            "mn",
            "bs",
            "kk",
            "sq",
            "sw",
            "gl",
            "mr",
            "pa",
            "si",
            "km",
            "sn",
            "yo",
            "so",
            "af",
            "oc",
            "ka",
            "be",
            "tg",
            "sd",
            "gu",
            "am",
            "yi",
            "lo",
            "uz",
            "fo",
            "ht",
            "ps",
            "tk",
            "nn",
            "mt",
            "sa",
            "lb",
            "my",
            "bo",
            "tl",
            "mg",
            "as",
            "tt",
            "haw",
            "ln",
            "ha",
            "ba",
            "jw",
            "su",
            "arxiv:2212.04356",
            "license:apache-2.0",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 358090,
          "likes": 1774
        },
        {
          "id": "openai/whisper-medium",
          "type": "hf.automatic_speech_recognition",
          "name": "openai/whisper-medium",
          "repo_id": "openai/whisper-medium",
          "allow_patterns": [
            "model.safetensors",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 3059917072,
          "pipeline_tag": "automatic-speech-recognition",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "jax",
            "safetensors",
            "whisper",
            "automatic-speech-recognition",
            "audio",
            "hf-asr-leaderboard",
            "en",
            "zh",
            "de",
            "es",
            "ru",
            "ko",
            "fr",
            "ja",
            "pt",
            "tr",
            "pl",
            "ca",
            "nl",
            "ar",
            "sv",
            "it",
            "id",
            "hi",
            "fi",
            "vi",
            "he",
            "uk",
            "el",
            "ms",
            "cs",
            "ro",
            "da",
            "hu",
            "ta",
            "no",
            "th",
            "ur",
            "hr",
            "bg",
            "lt",
            "la",
            "mi",
            "ml",
            "cy",
            "sk",
            "te",
            "fa",
            "lv",
            "bn",
            "sr",
            "az",
            "sl",
            "kn",
            "et",
            "mk",
            "br",
            "eu",
            "is",
            "hy",
            "ne",
            "mn",
            "bs",
            "kk",
            "sq",
            "sw",
            "gl",
            "mr",
            "pa",
            "si",
            "km",
            "sn",
            "yo",
            "so",
            "af",
            "oc",
            "ka",
            "be",
            "tg",
            "sd",
            "gu",
            "am",
            "yi",
            "lo",
            "uz",
            "fo",
            "ht",
            "ps",
            "tk",
            "nn",
            "mt",
            "sa",
            "lb",
            "my",
            "bo",
            "tl",
            "mg",
            "as",
            "tt",
            "haw",
            "ln",
            "ha",
            "ba",
            "jw",
            "su",
            "arxiv:2212.04356",
            "license:apache-2.0",
            "model-index",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 933954,
          "likes": 268
        },
        {
          "id": "openai/whisper-small",
          "type": "hf.automatic_speech_recognition",
          "name": "openai/whisper-small",
          "repo_id": "openai/whisper-small",
          "allow_patterns": [
            "model.safetensors",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 971367937,
          "pipeline_tag": "automatic-speech-recognition",
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "jax",
            "safetensors",
            "whisper",
            "automatic-speech-recognition",
            "audio",
            "hf-asr-leaderboard",
            "en",
            "zh",
            "de",
            "es",
            "ru",
            "ko",
            "fr",
            "ja",
            "pt",
            "tr",
            "pl",
            "ca",
            "nl",
            "ar",
            "sv",
            "it",
            "id",
            "hi",
            "fi",
            "vi",
            "he",
            "uk",
            "el",
            "ms",
            "cs",
            "ro",
            "da",
            "hu",
            "ta",
            "no",
            "th",
            "ur",
            "hr",
            "bg",
            "lt",
            "la",
            "mi",
            "ml",
            "cy",
            "sk",
            "te",
            "fa",
            "lv",
            "bn",
            "sr",
            "az",
            "sl",
            "kn",
            "et",
            "mk",
            "br",
            "eu",
            "is",
            "hy",
            "ne",
            "mn",
            "bs",
            "kk",
            "sq",
            "sw",
            "gl",
            "mr",
            "pa",
            "si",
            "km",
            "sn",
            "yo",
            "so",
            "af",
            "oc",
            "ka",
            "be",
            "tg",
            "sd",
            "gu",
            "am",
            "yi",
            "lo",
            "uz",
            "fo",
            "ht",
            "ps",
            "tk",
            "nn",
            "mt",
            "sa",
            "lb",
            "my",
            "bo",
            "tl",
            "mg",
            "as",
            "tt",
            "haw",
            "ln",
            "ha",
            "ba",
            "jw",
            "su",
            "arxiv:2212.04356",
            "license:apache-2.0",
            "model-index",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 2839192,
          "likes": 483
        },
        {
          "id": "Systran/faster-whisper-large-v3",
          "type": "hf.automatic_speech_recognition",
          "name": "Systran/faster-whisper-large-v3",
          "repo_id": "Systran/faster-whisper-large-v3",
          "allow_patterns": [
            "model.bin",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 3090835702,
          "pipeline_tag": "automatic-speech-recognition",
          "tags": [
            "ctranslate2",
            "audio",
            "automatic-speech-recognition",
            "en",
            "zh",
            "de",
            "es",
            "ru",
            "ko",
            "fr",
            "ja",
            "pt",
            "tr",
            "pl",
            "ca",
            "nl",
            "ar",
            "sv",
            "it",
            "id",
            "hi",
            "fi",
            "vi",
            "he",
            "uk",
            "el",
            "ms",
            "cs",
            "ro",
            "da",
            "hu",
            "ta",
            "no",
            "th",
            "ur",
            "hr",
            "bg",
            "lt",
            "la",
            "mi",
            "ml",
            "cy",
            "sk",
            "te",
            "fa",
            "lv",
            "bn",
            "sr",
            "az",
            "sl",
            "kn",
            "et",
            "mk",
            "br",
            "eu",
            "is",
            "hy",
            "ne",
            "mn",
            "bs",
            "kk",
            "sq",
            "sw",
            "gl",
            "mr",
            "pa",
            "si",
            "km",
            "sn",
            "yo",
            "so",
            "af",
            "oc",
            "ka",
            "be",
            "tg",
            "sd",
            "gu",
            "am",
            "yi",
            "lo",
            "uz",
            "fo",
            "ht",
            "ps",
            "tk",
            "nn",
            "mt",
            "sa",
            "lb",
            "my",
            "bo",
            "tl",
            "mg",
            "as",
            "tt",
            "haw",
            "ln",
            "ha",
            "ba",
            "jw",
            "su",
            "yue",
            "license:mit",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 402596,
          "likes": 473
        }
      ],
      "basic_fields": [
        "model",
        "audio",
        "task"
      ]
    },
    {
      "title": "Bark",
      "description": "Bark is a text-to-audio model created by Suno. Bark can generate highly realistic, multilingual speech as well as other audio - including music, background noise and simple sound effects. The model can also produce nonverbal communications like laughing, sighing and crying.\n    tts, audio, speech, huggingface\n\n    Use cases:\n    - Create voice content for apps and websites\n    - Develop voice assistants with natural-sounding speech\n    - Generate automated announcements for public spaces",
      "namespace": "huggingface.text_to_speech",
      "node_type": "huggingface.text_to_speech.Bark",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.text_to_speech"
          },
          "default": {
            "type": "hf.text_to_speech",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for the image generation"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Inputs",
          "description": "The input text to the model"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "suno/bark",
          "type": "hf.text_to_speech",
          "name": "suno/bark",
          "repo_id": "suno/bark",
          "allow_patterns": [
            "*.bin",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 4490634036,
          "pipeline_tag": "text-to-speech",
          "tags": [
            "transformers",
            "pytorch",
            "bark",
            "text-to-audio",
            "audio",
            "text-to-speech",
            "en",
            "de",
            "es",
            "fr",
            "hi",
            "it",
            "ja",
            "ko",
            "pl",
            "pt",
            "ru",
            "tr",
            "zh",
            "license:mit",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 39231,
          "likes": 1462
        },
        {
          "id": "suno/bark-small",
          "type": "hf.text_to_speech",
          "name": "suno/bark-small",
          "repo_id": "suno/bark-small",
          "allow_patterns": [
            "*.bin",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 1680654085,
          "pipeline_tag": "text-to-speech",
          "tags": [
            "transformers",
            "pytorch",
            "bark",
            "text-to-audio",
            "audio",
            "text-to-speech",
            "en",
            "de",
            "es",
            "fr",
            "hi",
            "it",
            "ja",
            "ko",
            "pl",
            "pt",
            "ru",
            "tr",
            "zh",
            "license:mit",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 40017,
          "likes": 241
        }
      ],
      "basic_fields": [
        "model",
        "prompt"
      ]
    },
    {
      "title": "Kokoro TTS",
      "description": "Kokoro is an open-weight, fast, and lightweight TTS model (~82M params) with Apache-2.0 weights.\n    It supports multiple languages via `misaki` and provides high-quality speech with selectable voices.\n    tts, audio, speech, huggingface, kokoro\n\n    Reference: https://huggingface.co/hexgrad/Kokoro-82M\n\n    Use cases:\n    - Natural-sounding speech synthesis for apps, assistants, and narration\n    - Low-latency TTS in production or local projects\n    - Multi-language TTS with configurable voices and speed",
      "namespace": "huggingface.text_to_speech",
      "node_type": "huggingface.text_to_speech.KokoroTTS",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.text_to_speech"
          },
          "default": {
            "type": "hf.text_to_speech",
            "repo_id": "hexgrad/Kokoro-82M",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Hugging Face",
          "description": "The Kokoro repo to use (e.g., hexgrad/Kokoro-82M)"
        },
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "Hello from Kokoro.",
          "title": "Text",
          "description": "Input text to synthesize"
        },
        {
          "name": "lang_code",
          "type": {
            "type": "enum",
            "values": [
              "a",
              "b",
              "e",
              "f",
              "h",
              "i",
              "p",
              "j",
              "z",
              "k",
              "r",
              "t",
              "v",
              "a",
              "g",
              "p",
              "r",
              "u"
            ],
            "type_name": "nodetool.nodes.huggingface.text_to_speech.KokoroTTS.LanguageCode"
          },
          "default": "a",
          "title": "Language Code",
          "description": "Language code for G2P. Examples: 'a' (American English), 'b' (British English), 'e' (es), 'f' (fr-fr), 'h' (hi), 'i' (it), 'p' (pt-br), 'j' (ja), 'z' (zh)."
        },
        {
          "name": "voice",
          "type": {
            "type": "enum",
            "values": [
              "af_alloy",
              "af_aoede",
              "af_bella",
              "af_heart",
              "af_jessica",
              "af_kore",
              "af_nicole",
              "af_nova",
              "af_river",
              "af_sarah",
              "af_sky",
              "am_adam",
              "am_echo",
              "am_eric",
              "am_fenrir",
              "am_liam",
              "am_michael",
              "am_onyx",
              "am_puck",
              "am_santa",
              "bf_alice",
              "bf_emma",
              "bf_isabella",
              "bf_lily",
              "bm_daniel",
              "bm_fable",
              "bm_george",
              "bm_lewis",
              "ef_dora",
              "em_alex",
              "em_santa",
              "ff_siwis",
              "hf_alpha",
              "hf_beta",
              "hm_omega",
              "hm_psi",
              "if_sara",
              "im_nicola",
              "jf_alpha",
              "jf_gongitsune",
              "jf_nezumi",
              "jf_tebukuro",
              "jm_kumo",
              "pf_dora",
              "pm_alex",
              "pm_santa",
              "zf_xiaobei",
              "zf_xiaoni",
              "zf_xiaoxiao",
              "zf_xiaoyi"
            ],
            "type_name": "nodetool.nodes.huggingface.text_to_speech.KokoroTTS.Voice"
          },
          "default": "af_heart",
          "title": "Voice",
          "description": "Voice name (see VOICES.md on the model page). Examples: af_heart, af_bella, af_jessica."
        },
        {
          "name": "speed",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Speed",
          "description": "Speech speed multiplier (0.5\u20132.0)",
          "min": 0.5,
          "max": 2.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "audio"
        },
        {
          "type": {
            "type": "chunk"
          },
          "name": "chunk"
        }
      ],
      "recommended_models": [
        {
          "id": "hexgrad/Kokoro-82M",
          "type": "hf.text_to_speech",
          "name": "hexgrad/Kokoro-82M",
          "repo_id": "hexgrad/Kokoro-82M",
          "allow_patterns": [
            "*.json",
            "*.pth",
            "voices/*.pt"
          ],
          "size_on_disk": 355479286,
          "pipeline_tag": "text-to-speech",
          "tags": [
            "text-to-speech",
            "en",
            "arxiv:2306.07691",
            "arxiv:2203.02395",
            "base_model:yl4579/StyleTTS2-LJSpeech",
            "base_model:finetune:yl4579/StyleTTS2-LJSpeech",
            "doi:10.57967/hf/4329",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 4181673,
          "likes": 5299
        }
      ],
      "basic_fields": [
        "model",
        "text",
        "lang_code",
        "voice",
        "speed"
      ],
      "is_streaming_output": true
    },
    {
      "title": "Text To Speech",
      "description": "A generic Text-to-Speech node that can work with various Hugging Face TTS models.\n    tts, audio, speech, huggingface, speak, voice\n\n    Use cases:\n    - Generate speech from text for various applications\n    - Create voice content for apps, websites, or virtual assistants\n    - Produce audio narrations for videos, presentations, or e-learning content",
      "namespace": "huggingface.text_to_speech",
      "node_type": "huggingface.text_to_speech.TextToSpeech",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.text_to_speech"
          },
          "default": {
            "type": "hf.text_to_speech",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for text-to-speech generation"
        },
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "Hello, this is a test of the text-to-speech system.",
          "title": "Input Text",
          "description": "The text to convert to speech"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "facebook/mms-tts-eng",
          "type": "hf.text_to_speech",
          "name": "facebook/mms-tts-eng",
          "repo_id": "facebook/mms-tts-eng",
          "allow_patterns": [
            "*.bin",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 145391110,
          "pipeline_tag": "text-to-speech",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "vits",
            "text-to-audio",
            "mms",
            "text-to-speech",
            "arxiv:2305.13516",
            "license:cc-by-nc-4.0",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 27592,
          "likes": 160
        },
        {
          "id": "facebook/mms-tts-kor",
          "type": "hf.text_to_speech",
          "name": "facebook/mms-tts-kor",
          "repo_id": "facebook/mms-tts-kor",
          "allow_patterns": [
            "*.bin",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 145380980,
          "pipeline_tag": "text-to-speech",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "vits",
            "text-to-audio",
            "mms",
            "text-to-speech",
            "arxiv:2305.13516",
            "license:cc-by-nc-4.0",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 1862,
          "likes": 14
        },
        {
          "id": "facebook/mms-tts-fra",
          "type": "hf.text_to_speech",
          "name": "facebook/mms-tts-fra",
          "repo_id": "facebook/mms-tts-fra",
          "allow_patterns": [
            "*.bin",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 145395800,
          "pipeline_tag": "text-to-speech",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "vits",
            "text-to-audio",
            "mms",
            "text-to-speech",
            "arxiv:2305.13516",
            "license:cc-by-nc-4.0",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 2489,
          "likes": 14
        },
        {
          "id": "facebook/mms-tts-deu",
          "type": "hf.text_to_speech",
          "name": "facebook/mms-tts-deu",
          "repo_id": "facebook/mms-tts-deu",
          "allow_patterns": [
            "*.bin",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 145396569,
          "pipeline_tag": "text-to-speech",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "vits",
            "text-to-audio",
            "mms",
            "text-to-speech",
            "arxiv:2305.13516",
            "license:cc-by-nc-4.0",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 1018,
          "likes": 14
        }
      ],
      "basic_fields": [
        "model",
        "text"
      ]
    },
    {
      "title": "Object Detection",
      "description": "Detects and localizes objects in images.\n    image, object detection, bounding boxes, huggingface\n\n    Use cases:\n    - Identify and count objects in images\n    - Locate specific items in complex scenes\n    - Assist in autonomous vehicle vision systems\n    - Enhance security camera footage analysis",
      "namespace": "huggingface.object_detection",
      "node_type": "huggingface.object_detection.ObjectDetection",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.object_detection"
          },
          "default": {
            "type": "hf.object_detection",
            "repo_id": "facebook/detr-resnet-50",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for object detection"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Inputs",
          "description": "The input image for object detection"
        },
        {
          "name": "threshold",
          "type": {
            "type": "float"
          },
          "default": 0.9,
          "title": "Confidence Threshold",
          "description": "Minimum confidence score for detected objects"
        },
        {
          "name": "top_k",
          "type": {
            "type": "int"
          },
          "default": 5,
          "title": "Top K",
          "description": "The number of top predictions to return"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "object_detection_result"
              }
            ]
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "facebook/detr-resnet-50",
          "type": "hf.object_detection",
          "name": "facebook/detr-resnet-50",
          "repo_id": "facebook/detr-resnet-50",
          "allow_patterns": [
            "README.md",
            "*.bin",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 166742644,
          "pipeline_tag": "object-detection",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "detr",
            "object-detection",
            "vision",
            "dataset:coco",
            "arxiv:2005.12872",
            "license:apache-2.0",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 955823,
          "likes": 909
        },
        {
          "id": "facebook/detr-resnet-101",
          "type": "hf.object_detection",
          "name": "facebook/detr-resnet-101",
          "repo_id": "facebook/detr-resnet-101",
          "allow_patterns": [
            "README.md",
            "*.safetensors",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 242808179,
          "pipeline_tag": "object-detection",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "detr",
            "object-detection",
            "vision",
            "dataset:coco",
            "arxiv:2005.12872",
            "license:apache-2.0",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 45359,
          "likes": 124
        },
        {
          "id": "hustvl/yolos-tiny",
          "type": "hf.object_detection",
          "name": "hustvl/yolos-tiny",
          "repo_id": "hustvl/yolos-tiny",
          "allow_patterns": [
            "README.md",
            "*.safetensors",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 25987930,
          "pipeline_tag": "object-detection",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "yolos",
            "object-detection",
            "vision",
            "dataset:coco",
            "arxiv:2106.00666",
            "license:apache-2.0",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 138875,
          "likes": 271
        },
        {
          "id": "hustvl/yolos-small",
          "type": "hf.object_detection",
          "name": "hustvl/yolos-small",
          "repo_id": "hustvl/yolos-small",
          "allow_patterns": [
            "README.md",
            "*.safetensors",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 122771871,
          "pipeline_tag": "object-detection",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "yolos",
            "object-detection",
            "vision",
            "dataset:coco",
            "arxiv:2106.00666",
            "license:apache-2.0",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 762542,
          "likes": 71
        },
        {
          "id": "microsoft/table-transformer-detection",
          "type": "hf.object_detection",
          "name": "microsoft/table-transformer-detection",
          "repo_id": "microsoft/table-transformer-detection",
          "allow_patterns": [
            "README.md",
            "*.bin",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 115395920,
          "pipeline_tag": "object-detection",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "table-transformer",
            "object-detection",
            "arxiv:2110.00061",
            "license:mit",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 1553933,
          "likes": 380
        },
        {
          "id": "microsoft/table-transformer-structure-recognition-v1.1-all",
          "type": "hf.object_detection",
          "name": "microsoft/table-transformer-structure-recognition-v1.1-all",
          "repo_id": "microsoft/table-transformer-structure-recognition-v1.1-all",
          "allow_patterns": [
            "README.md",
            "*.bin",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 78191,
          "pipeline_tag": "object-detection",
          "tags": [
            "transformers",
            "safetensors",
            "table-transformer",
            "object-detection",
            "arxiv:2303.00716",
            "license:mit",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 247418,
          "likes": 76
        },
        {
          "id": "valentinafeve/yolos-fashionpedia",
          "type": "hf.object_detection",
          "name": "valentinafeve/yolos-fashionpedia",
          "repo_id": "valentinafeve/yolos-fashionpedia",
          "allow_patterns": [
            "README.md",
            "*.bin",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 122742861,
          "pipeline_tag": "object-detection",
          "tags": [
            "transformers",
            "pytorch",
            "yolos",
            "object-detection",
            "YOLOS",
            "Object detection",
            "en",
            "dataset:detection-datasets/fashionpedia",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 3686,
          "likes": 139
        }
      ],
      "basic_fields": [
        "model",
        "image"
      ]
    },
    {
      "title": "Visualize Object Detection",
      "description": "Visualizes object detection results on images.\n    image, object detection, bounding boxes, visualization, mask",
      "namespace": "huggingface.object_detection",
      "node_type": "huggingface.object_detection.VisualizeObjectDetection",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The input image to visualize"
        },
        {
          "name": "objects",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "object_detection_result"
              }
            ]
          },
          "default": {},
          "title": "Detected Objects",
          "description": "The detected objects to visualize"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "objects"
      ]
    },
    {
      "title": "Zero-Shot Object Detection",
      "description": "Detects objects in images without the need for training data.\n    image, object detection, bounding boxes, zero-shot, mask\n\n    Use cases:\n    - Quickly detect objects in images without training data\n    - Identify objects in images without predefined labels\n    - Automate object detection for large datasets",
      "namespace": "huggingface.object_detection",
      "node_type": "huggingface.object_detection.ZeroShotObjectDetection",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.zero_shot_object_detection"
          },
          "default": {
            "type": "hf.zero_shot_object_detection",
            "repo_id": "google/owlv2-base-patch16",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for object detection"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Inputs",
          "description": "The input image for object detection"
        },
        {
          "name": "threshold",
          "type": {
            "type": "float"
          },
          "default": 0.1,
          "title": "Confidence Threshold",
          "description": "Minimum confidence score for detected objects"
        },
        {
          "name": "top_k",
          "type": {
            "type": "int"
          },
          "default": 5,
          "title": "Top K",
          "description": "The number of top predictions to return"
        },
        {
          "name": "candidate_labels",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Candidate Labels",
          "description": "The candidate labels to detect in the image, separated by commas"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "object_detection_result"
              }
            ]
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "google/owlvit-base-patch32",
          "type": "hf.zero_shot_object_detection",
          "name": "google/owlvit-base-patch32",
          "repo_id": "google/owlvit-base-patch32",
          "allow_patterns": [
            "README.md",
            "*.bin",
            "*.json",
            "**/*.json",
            "txt"
          ],
          "size_on_disk": 614120310,
          "pipeline_tag": "zero-shot-object-detection",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "owlvit",
            "zero-shot-object-detection",
            "vision",
            "arxiv:2205.06230",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 206038,
          "likes": 143
        },
        {
          "id": "google/owlvit-large-patch14",
          "type": "hf.zero_shot_object_detection",
          "name": "google/owlvit-large-patch14",
          "repo_id": "google/owlvit-large-patch14",
          "allow_patterns": [
            "README.md",
            "*.bin",
            "*.json",
            "**/*.json",
            "txt"
          ],
          "size_on_disk": 1736825755,
          "pipeline_tag": "zero-shot-object-detection",
          "tags": [
            "transformers",
            "pytorch",
            "owlvit",
            "zero-shot-object-detection",
            "vision",
            "arxiv:2205.06230",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 28149,
          "likes": 28
        },
        {
          "id": "google/owlvit-base-patch16",
          "type": "hf.zero_shot_object_detection",
          "name": "google/owlvit-base-patch16",
          "repo_id": "google/owlvit-base-patch16",
          "allow_patterns": [
            "README.md",
            "*.bin",
            "*.json",
            "**/*.json",
            "txt"
          ],
          "size_on_disk": 612364662,
          "pipeline_tag": "zero-shot-object-detection",
          "tags": [
            "transformers",
            "pytorch",
            "owlvit",
            "zero-shot-object-detection",
            "vision",
            "arxiv:2205.06230",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 21222,
          "likes": 12
        },
        {
          "id": "google/owlv2-base-patch16",
          "type": "hf.zero_shot_object_detection",
          "name": "google/owlv2-base-patch16",
          "repo_id": "google/owlv2-base-patch16",
          "allow_patterns": [
            "README.md",
            "*.bin",
            "*.json",
            "**/*.json",
            "txt"
          ],
          "size_on_disk": 621074340,
          "pipeline_tag": "zero-shot-object-detection",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "owlv2",
            "zero-shot-object-detection",
            "vision",
            "arxiv:2306.09683",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 25535,
          "likes": 28
        },
        {
          "id": "google/owlv2-base-patch16-ensemble",
          "type": "hf.zero_shot_object_detection",
          "name": "google/owlv2-base-patch16-ensemble",
          "repo_id": "google/owlv2-base-patch16-ensemble",
          "allow_patterns": [
            "README.md",
            "*.bin",
            "*.json",
            "**/*.json",
            "txt"
          ],
          "size_on_disk": 621073668,
          "pipeline_tag": "zero-shot-object-detection",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "owlv2",
            "zero-shot-object-detection",
            "vision",
            "arxiv:2306.09683",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 731461,
          "likes": 113
        },
        {
          "id": "IDEA-Research/grounding-dino-tiny",
          "type": "hf.zero_shot_object_detection",
          "name": "IDEA-Research/grounding-dino-tiny",
          "repo_id": "IDEA-Research/grounding-dino-tiny",
          "allow_patterns": [
            "README.md",
            "*.bin",
            "*.json",
            "**/*.json",
            "txt"
          ],
          "size_on_disk": 692632123,
          "pipeline_tag": "zero-shot-object-detection",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "grounding-dino",
            "zero-shot-object-detection",
            "vision",
            "arxiv:2303.05499",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 613875,
          "likes": 88
        }
      ],
      "basic_fields": [
        "model",
        "image",
        "threshold",
        "top_k",
        "candidate_labels"
      ]
    },
    {
      "title": "Audio Classifier",
      "description": "Classifies audio into predefined categories.\n    audio, classification, labeling, categorization\n\n    Use cases:\n    - Classify music genres\n    - Detect speech vs. non-speech audio\n    - Identify environmental sounds\n    - Emotion recognition in speech\n\n    Recommended models\n    - MIT/ast-finetuned-audioset-10-10-0.4593\n    - ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
      "namespace": "huggingface.audio_classification",
      "node_type": "huggingface.audio_classification.AudioClassifier",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.audio_classification"
          },
          "default": {
            "type": "hf.audio_classification",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for audio classification"
        },
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Audio",
          "description": "The input audio to classify"
        },
        {
          "name": "top_k",
          "type": {
            "type": "int"
          },
          "default": 10,
          "title": "Top K",
          "description": "The number of top results to return"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "dict",
            "type_args": [
              {
                "type": "str"
              },
              {
                "type": "float"
              }
            ]
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "MIT/ast-finetuned-audioset-10-10-0.4593",
          "type": "hf.audio_classification",
          "name": "MIT/ast-finetuned-audioset-10-10-0.4593",
          "repo_id": "MIT/ast-finetuned-audioset-10-10-0.4593",
          "allow_patterns": [
            "*.safetensors",
            "*.json"
          ],
          "size_on_disk": 346432008,
          "pipeline_tag": "audio-classification",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "audio-spectrogram-transformer",
            "audio-classification",
            "arxiv:2104.01778",
            "license:bsd-3-clause",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 474065,
          "likes": 331
        },
        {
          "id": "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
          "type": "hf.audio_classification",
          "name": "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
          "repo_id": "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
          "allow_patterns": [
            "pytorch_model.bin",
            "*.json"
          ],
          "size_on_disk": 1266158125,
          "pipeline_tag": "audio-classification",
          "tags": [
            "transformers",
            "pytorch",
            "tensorboard",
            "safetensors",
            "wav2vec2",
            "audio-classification",
            "generated_from_trainer",
            "doi:10.57967/hf/2045",
            "license:apache-2.0",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 30034,
          "likes": 236
        }
      ],
      "basic_fields": [
        "model",
        "audio",
        "top_k"
      ]
    },
    {
      "title": "Zero Shot Audio Classifier",
      "description": "Classifies audio into categories without the need for training data.\n    audio, classification, labeling, categorization, zero-shot\n\n    Use cases:\n    - Quickly categorize audio without training data\n    - Identify sounds or music genres without predefined labels\n    - Automate audio tagging for large datasets",
      "namespace": "huggingface.audio_classification",
      "node_type": "huggingface.audio_classification.ZeroShotAudioClassifier",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.zero_shot_audio_classification"
          },
          "default": {
            "type": "hf.zero_shot_audio_classification",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for the classification"
        },
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Audio",
          "description": "The input audio to classify"
        },
        {
          "name": "candidate_labels",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Candidate Labels",
          "description": "The candidate labels to classify the audio against, separated by commas"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "dict",
            "type_args": [
              {
                "type": "str"
              },
              {
                "type": "float"
              }
            ]
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "laion/clap-htsat-unfused",
          "type": "hf.zero_shot_audio_classification",
          "name": "laion/clap-htsat-unfused",
          "repo_id": "laion/clap-htsat-unfused",
          "allow_patterns": [
            "model.safetensors",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 3369990,
          "pipeline_tag": "feature-extraction",
          "tags": [
            "transformers",
            "pytorch",
            "clap",
            "feature-extraction",
            "arxiv:2211.06687",
            "license:apache-2.0",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 200744,
          "likes": 61
        }
      ],
      "basic_fields": [
        "model",
        "audio",
        "candidate_labels"
      ]
    },
    {
      "title": "Text To Text",
      "description": "Performs text-to-text generation tasks.\n    text, generation, translation, question-answering, summarization, nlp, natural-language-processing\n\n    Use cases:\n    - Text translation\n    - Text summarization\n    - Paraphrasing\n    - Text style transfer\n\n    Usage:\n    Start with a command like Translate, Summarize, or Q (for question)\n    Follow with the text you want to translate, summarize, or answer a question about.\n    Examples:\n    - Translate to German: Hello\n    - Summarize: The quick brown fox jumps over the lazy dog.\n    - Q: Who ate the cookie? followed by the text of the cookie monster.",
      "namespace": "huggingface.text_to_text",
      "node_type": "huggingface.text_to_text.TextToText",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.text2text_generation"
          },
          "default": {
            "type": "hf.text2text_generation",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for the text-to-text generation"
        },
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Input Text",
          "description": "The input text for the text-to-text task"
        },
        {
          "name": "max_length",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Max Length",
          "description": "The maximum length of the generated text"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "google/flan-t5-small",
          "type": "hf.text2text_generation",
          "name": "google/flan-t5-small",
          "repo_id": "google/flan-t5-small",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 310297400,
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "jax",
            "safetensors",
            "t5",
            "text2text-generation",
            "en",
            "fr",
            "ro",
            "de",
            "multilingual",
            "dataset:svakulenk0/qrecc",
            "dataset:taskmaster2",
            "dataset:djaym7/wiki_dialog",
            "dataset:deepmind/code_contests",
            "dataset:lambada",
            "dataset:gsm8k",
            "dataset:aqua_rat",
            "dataset:esnli",
            "dataset:quasc",
            "dataset:qed",
            "arxiv:2210.11416",
            "arxiv:1910.09700",
            "license:apache-2.0",
            "text-generation-inference",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 479848,
          "likes": 445
        },
        {
          "id": "google/flan-t5-base",
          "type": "hf.text2text_generation",
          "name": "google/flan-t5-base",
          "repo_id": "google/flan-t5-base",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 992775414,
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "jax",
            "safetensors",
            "t5",
            "text2text-generation",
            "en",
            "fr",
            "ro",
            "de",
            "multilingual",
            "dataset:svakulenk0/qrecc",
            "dataset:taskmaster2",
            "dataset:djaym7/wiki_dialog",
            "dataset:deepmind/code_contests",
            "dataset:lambada",
            "dataset:gsm8k",
            "dataset:aqua_rat",
            "dataset:esnli",
            "dataset:quasc",
            "dataset:qed",
            "arxiv:2210.11416",
            "arxiv:1910.09700",
            "license:apache-2.0",
            "text-generation-inference",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 1167625,
          "likes": 1020
        },
        {
          "id": "google/flan-t5-large",
          "type": "hf.text2text_generation",
          "name": "google/flan-t5-large",
          "repo_id": "google/flan-t5-large",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 3135098417,
          "tags": [
            "transformers",
            "pytorch",
            "tf",
            "jax",
            "safetensors",
            "t5",
            "text2text-generation",
            "en",
            "fr",
            "ro",
            "de",
            "multilingual",
            "dataset:svakulenk0/qrecc",
            "dataset:taskmaster2",
            "dataset:djaym7/wiki_dialog",
            "dataset:deepmind/code_contests",
            "dataset:lambada",
            "dataset:gsm8k",
            "dataset:aqua_rat",
            "dataset:esnli",
            "dataset:quasc",
            "dataset:qed",
            "arxiv:2210.11416",
            "arxiv:1910.09700",
            "license:apache-2.0",
            "text-generation-inference",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 599920,
          "likes": 849
        },
        {
          "id": "gokaygokay/Flux-Prompt-Enhance",
          "type": "hf.text2text_generation",
          "name": "gokaygokay/Flux-Prompt-Enhance",
          "repo_id": "gokaygokay/Flux-Prompt-Enhance",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "*.safetensors"
          ],
          "size_on_disk": 894091472,
          "pipeline_tag": "text-generation",
          "tags": [
            "transformers",
            "safetensors",
            "t5",
            "text2text-generation",
            "en",
            "dataset:gokaygokay/prompt-enhancer-dataset",
            "base_model:google-t5/t5-base",
            "base_model:finetune:google-t5/t5-base",
            "license:apache-2.0",
            "text-generation-inference",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 4071,
          "likes": 62
        }
      ],
      "basic_fields": [
        "model",
        "text"
      ]
    },
    {
      "title": "Audio LDM",
      "description": "Generates audio using the AudioLDM model based on text prompts.\n    audio, generation, AI, text-to-audio\n\n    Use cases:\n    - Create custom music or sound effects from text descriptions\n    - Generate background audio for videos, games, or other media\n    - Produce audio content for creative projects\n    - Explore AI-generated audio for music production or sound design",
      "namespace": "huggingface.text_to_audio",
      "node_type": "huggingface.text_to_audio.AudioLDM",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "Techno music with a strong, upbeat tempo and high melodic riffs",
          "title": "Prompt",
          "description": "A text prompt describing the desired audio."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 10,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps. More steps generally improve quality but increase generation time.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "audio_length_in_s",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Audio Length In S",
          "description": "The desired duration of the generated audio in seconds.",
          "min": 1.0,
          "max": 30.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "cvssp/audioldm-s-full-v2",
          "type": "hf.text_to_audio",
          "name": "cvssp/audioldm-s-full-v2",
          "repo_id": "cvssp/audioldm-s-full-v2",
          "allow_patterns": [
            "*.safetensors",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 1687448107,
          "tags": [
            "diffusers",
            "safetensors",
            "arxiv:2301.12503",
            "license:cc-by-nc-sa-4.0",
            "diffusers:AudioLDMPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 1369,
          "likes": 20
        }
      ],
      "basic_fields": [
        "model",
        "prompt"
      ]
    },
    {
      "title": "Audio LDM 2",
      "description": "Generates audio using the AudioLDM2 model based on text prompts.\n    audio, generation, AI, text-to-audio\n\n    Use cases:\n    - Create custom sound effects based on textual descriptions\n    - Generate background audio for videos or games\n    - Produce audio content for multimedia projects\n    - Explore AI-generated audio for creative sound design",
      "namespace": "huggingface.text_to_audio",
      "node_type": "huggingface.text_to_audio.AudioLDM2",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "The sound of a hammer hitting a wooden surface.",
          "title": "Prompt",
          "description": "A text prompt describing the desired audio."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "Low quality.",
          "title": "Negative Prompt",
          "description": "A text prompt describing what you don't want in the audio."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 200,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps. More steps generally improve quality but increase generation time.",
          "min": 50.0,
          "max": 500.0
        },
        {
          "name": "audio_length_in_s",
          "type": {
            "type": "float"
          },
          "default": 10.0,
          "title": "Audio Length In S",
          "description": "The desired duration of the generated audio in seconds.",
          "min": 1.0,
          "max": 30.0
        },
        {
          "name": "num_waveforms_per_prompt",
          "type": {
            "type": "int"
          },
          "default": 3,
          "title": "Num Waveforms Per Prompt",
          "description": "Number of audio samples to generate per prompt.",
          "min": 1.0,
          "max": 5.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "cvssp/audioldm2",
          "type": "hf.text_to_audio",
          "name": "cvssp/audioldm2",
          "repo_id": "cvssp/audioldm2",
          "allow_patterns": [
            "*.safetensors",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 4480160895,
          "tags": [
            "diffusers",
            "safetensors",
            "arxiv:2308.05734",
            "license:cc-by-nc-sa-4.0",
            "diffusers:AudioLDM2Pipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 22210,
          "likes": 55
        }
      ],
      "basic_fields": [
        "model",
        "prompt"
      ]
    },
    {
      "title": "Dance Diffusion",
      "description": "Generates audio using the DanceDiffusion model.\n    audio, generation, AI, music, text-to-audio\n\n    Use cases:\n    - Create AI-generated music samples\n    - Produce background music for videos or games\n    - Generate audio content for creative projects\n    - Explore AI-composed musical ideas",
      "namespace": "huggingface.text_to_audio",
      "node_type": "huggingface.text_to_audio.DanceDiffusion",
      "properties": [
        {
          "name": "audio_length_in_s",
          "type": {
            "type": "float"
          },
          "default": 4.0,
          "title": "Audio Length In S",
          "description": "The desired duration of the generated audio in seconds.",
          "min": 1.0,
          "max": 30.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps. More steps generally improve quality but increase generation time.",
          "min": 1.0,
          "max": 1000.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "harmonai/maestro-150k",
          "type": "hf.text_to_audio",
          "name": "harmonai/maestro-150k",
          "repo_id": "harmonai/maestro-150k",
          "allow_patterns": [
            "*.bin",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 885946620,
          "tags": [
            "diffusers",
            "audio-generation",
            "license:mit",
            "diffusers:DanceDiffusionPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 59,
          "likes": 17
        }
      ],
      "basic_fields": [
        "model",
        "prompt"
      ]
    },
    {
      "title": "Music Gen",
      "description": "Generates audio (music or sound effects) from text descriptions.\n    audio, music, generation, huggingface, text-to-audio\n\n    Use cases:\n    - Create custom background music for videos or games\n    - Generate sound effects based on textual descriptions\n    - Prototype musical ideas quickly",
      "namespace": "huggingface.text_to_audio",
      "node_type": "huggingface.text_to_audio.MusicGen",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.text_to_audio"
          },
          "default": {
            "type": "hf.text_to_audio",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for the audio generation"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Inputs",
          "description": "The input text to the model"
        },
        {
          "name": "max_new_tokens",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Max New Tokens",
          "description": "The maximum number of tokens to generate"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "facebook/musicgen-small",
          "type": "hf.text_to_audio",
          "name": "facebook/musicgen-small",
          "repo_id": "facebook/musicgen-small",
          "allow_patterns": [
            "*.safetensors",
            "*.json",
            "*.model"
          ],
          "size_on_disk": 2367653971,
          "pipeline_tag": "text-to-audio",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "musicgen",
            "text-to-audio",
            "arxiv:2306.05284",
            "license:cc-by-nc-4.0",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 78880,
          "likes": 463
        },
        {
          "id": "facebook/musicgen-medium",
          "type": "hf.text_to_audio",
          "name": "facebook/musicgen-medium",
          "repo_id": "facebook/musicgen-medium",
          "allow_patterns": [
            "*.safetensors",
            "*.json",
            "*.model"
          ],
          "size_on_disk": 3226683,
          "pipeline_tag": "text-to-audio",
          "tags": [
            "transformers",
            "pytorch",
            "musicgen",
            "text-to-audio",
            "arxiv:2306.05284",
            "license:cc-by-nc-4.0",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 1348111,
          "likes": 144
        },
        {
          "id": "facebook/musicgen-large",
          "type": "hf.text_to_audio",
          "name": "facebook/musicgen-large",
          "repo_id": "facebook/musicgen-large",
          "allow_patterns": [
            "*.safetensors",
            "*.json",
            "*.model"
          ],
          "size_on_disk": 3324787,
          "pipeline_tag": "text-to-audio",
          "tags": [
            "transformers",
            "pytorch",
            "musicgen",
            "text-to-audio",
            "arxiv:2306.05284",
            "license:cc-by-nc-4.0",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 5822,
          "likes": 490
        },
        {
          "id": "facebook/musicgen-melody",
          "type": "hf.text_to_audio",
          "name": "facebook/musicgen-melody",
          "repo_id": "facebook/musicgen-melody",
          "allow_patterns": [
            "*.safetensors",
            "*.json",
            "*.model"
          ],
          "size_on_disk": 6232963744,
          "pipeline_tag": "text-to-audio",
          "tags": [
            "transformers",
            "safetensors",
            "musicgen_melody",
            "text-to-audio",
            "musicgen",
            "arxiv:2306.05284",
            "license:cc-by-nc-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 2940,
          "likes": 247
        },
        {
          "id": "facebook/musicgen-stereo-small",
          "type": "hf.text_to_audio",
          "name": "facebook/musicgen-stereo-small",
          "repo_id": "facebook/musicgen-stereo-small",
          "allow_patterns": [
            "*.safetensors",
            "*.json",
            "*.model"
          ],
          "size_on_disk": 3650614378,
          "pipeline_tag": "text-to-audio",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "musicgen",
            "text-to-audio",
            "audiocraft",
            "arxiv:2306.05284",
            "license:cc-by-nc-4.0",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 1565,
          "likes": 37
        },
        {
          "id": "facebook/musicgen-stereo-large",
          "type": "hf.text_to_audio",
          "name": "facebook/musicgen-stereo-large",
          "repo_id": "facebook/musicgen-stereo-large",
          "allow_patterns": [
            "*.safetensors",
            "*.json",
            "*.model"
          ],
          "size_on_disk": 6930444453,
          "pipeline_tag": "text-to-audio",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "musicgen",
            "text-to-audio",
            "audiocraft",
            "arxiv:2306.05284",
            "license:cc-by-nc-4.0",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 344,
          "likes": 83
        }
      ],
      "basic_fields": [
        "model",
        "prompt"
      ]
    },
    {
      "title": "Music LDM",
      "description": "Generates audio (music or sound effects) from text descriptions.\n    audio, music, generation, huggingface, text-to-audio\n\n    Use cases:\n    - Create custom background music for videos or games\n    - Generate sound effects based on textual descriptions\n    - Prototype musical ideas quickly",
      "namespace": "huggingface.text_to_audio",
      "node_type": "huggingface.text_to_audio.MusicLDM",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.text_to_audio"
          },
          "default": {
            "type": "hf.text_to_audio",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for the audio generation"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Inputs",
          "description": "The input text to the model"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 10,
          "title": "Number of Inference Steps",
          "description": "The number of inference steps to use for the generation"
        },
        {
          "name": "audio_length_in_s",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Audio Length",
          "description": "The length of the generated audio in seconds"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "ucsd-reach/musicldm",
          "type": "hf.text_to_audio",
          "name": "ucsd-reach/musicldm",
          "repo_id": "ucsd-reach/musicldm",
          "allow_patterns": [
            "*.safetensors",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 1962535221,
          "tags": [
            "diffusers",
            "safetensors",
            "arxiv:2308.01546",
            "license:cc-by-nc-sa-4.0",
            "diffusers:MusicLDMPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 76,
          "likes": 6
        }
      ],
      "basic_fields": [
        "model",
        "prompt"
      ]
    },
    {
      "title": "Stable Audio",
      "description": "Generate audio using Stable Audio model based on text prompts. Features high-quality audio synthesis with configurable parameters.\n    audio, generation, synthesis, text-to-audio, text-to-audio\n\n    Use cases:\n    - Create custom audio content from text\n    - Generate background music and sounds\n    - Produce audio for multimedia projects\n    - Create sound effects and ambience\n    - Generate experimental audio content",
      "namespace": "huggingface.text_to_audio",
      "node_type": "huggingface.text_to_audio.StableAudio",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "A peaceful piano melody.",
          "title": "Prompt",
          "description": "A text prompt describing the desired audio."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "Low quality.",
          "title": "Negative Prompt",
          "description": "A text prompt describing what you don't want in the audio."
        },
        {
          "name": "duration",
          "type": {
            "type": "float"
          },
          "default": 10.0,
          "title": "Duration",
          "description": "The desired duration of the generated audio in seconds.",
          "min": 1.0,
          "max": 300.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 200,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps. More steps generally improve quality but increase generation time.",
          "min": 50.0,
          "max": 500.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "stabilityai/stable-audio-open-1.0",
          "type": "hf.text_to_audio",
          "name": "stabilityai/stable-audio-open-1.0",
          "repo_id": "stabilityai/stable-audio-open-1.0",
          "allow_patterns": [
            "*.safetensors",
            "*.json",
            "*.txt"
          ],
          "size_on_disk": 10148754510,
          "pipeline_tag": "text-to-audio",
          "tags": [
            "stable-audio-tools",
            "diffusers",
            "safetensors",
            "text-to-audio",
            "en",
            "arxiv:2407.14358",
            "license:other",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 58195,
          "likes": 1340
        }
      ],
      "basic_fields": [
        "model",
        "prompt"
      ]
    },
    {
      "title": "Sentence Similarity",
      "description": "Compares the similarity between two sentences.\n    text, sentence similarity, embeddings, natural language processing\n\n    Use cases:\n    - Duplicate detection in text data\n    - Semantic search\n    - Sentiment analysis",
      "namespace": "huggingface.sentence_similarity",
      "node_type": "huggingface.sentence_similarity.SentenceSimilarity",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.sentence_similarity"
          },
          "default": {
            "type": "hf.sentence_similarity",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for sentence similarity"
        },
        {
          "name": "inputs",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Input Text",
          "description": "The text to compare"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "np_array"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "sentence-transformers/all-mpnet-base-v2",
          "type": "hf.sentence_similarity",
          "name": "sentence-transformers/all-mpnet-base-v2",
          "repo_id": "sentence-transformers/all-mpnet-base-v2",
          "allow_patterns": [
            "*.safetensors",
            "*.txt",
            "*,json"
          ],
          "size_on_disk": 438203408,
          "pipeline_tag": "sentence-similarity",
          "tags": [
            "sentence-transformers",
            "pytorch",
            "onnx",
            "safetensors",
            "openvino",
            "mpnet",
            "fill-mask",
            "feature-extraction",
            "sentence-similarity",
            "transformers",
            "text-embeddings-inference",
            "en",
            "dataset:s2orc",
            "dataset:flax-sentence-embeddings/stackexchange_xml",
            "dataset:ms_marco",
            "dataset:gooaq",
            "dataset:yahoo_answers_topics",
            "dataset:code_search_net",
            "dataset:search_qa",
            "dataset:eli5",
            "dataset:snli",
            "dataset:multi_nli",
            "dataset:wikihow",
            "dataset:natural_questions",
            "dataset:trivia_qa",
            "dataset:embedding-data/sentence-compression",
            "dataset:embedding-data/flickr30k-captions",
            "dataset:embedding-data/altlex",
            "dataset:embedding-data/simple-wiki",
            "dataset:embedding-data/QQP",
            "dataset:embedding-data/SPECTER",
            "dataset:embedding-data/PAQ_pairs",
            "dataset:embedding-data/WikiAnswers",
            "arxiv:1904.06472",
            "arxiv:2102.07033",
            "arxiv:2104.08727",
            "arxiv:1704.05179",
            "arxiv:1810.09305",
            "license:apache-2.0",
            "autotrain_compatible",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 19927588,
          "likes": 1190
        },
        {
          "id": "sentence-transformers/all-MiniLM-L6-v2",
          "type": "hf.sentence_similarity",
          "name": "sentence-transformers/all-MiniLM-L6-v2",
          "repo_id": "sentence-transformers/all-MiniLM-L6-v2",
          "allow_patterns": [
            "*.safetensors",
            "*.txt",
            "*,json"
          ],
          "size_on_disk": 91099884,
          "pipeline_tag": "sentence-similarity",
          "tags": [
            "sentence-transformers",
            "pytorch",
            "tf",
            "rust",
            "onnx",
            "safetensors",
            "openvino",
            "bert",
            "feature-extraction",
            "sentence-similarity",
            "transformers",
            "en",
            "dataset:s2orc",
            "dataset:flax-sentence-embeddings/stackexchange_xml",
            "dataset:ms_marco",
            "dataset:gooaq",
            "dataset:yahoo_answers_topics",
            "dataset:code_search_net",
            "dataset:search_qa",
            "dataset:eli5",
            "dataset:snli",
            "dataset:multi_nli",
            "dataset:wikihow",
            "dataset:natural_questions",
            "dataset:trivia_qa",
            "dataset:embedding-data/sentence-compression",
            "dataset:embedding-data/flickr30k-captions",
            "dataset:embedding-data/altlex",
            "dataset:embedding-data/simple-wiki",
            "dataset:embedding-data/QQP",
            "dataset:embedding-data/SPECTER",
            "dataset:embedding-data/PAQ_pairs",
            "dataset:embedding-data/WikiAnswers",
            "arxiv:1904.06472",
            "arxiv:2102.07033",
            "arxiv:2104.08727",
            "arxiv:1704.05179",
            "arxiv:1810.09305",
            "license:apache-2.0",
            "autotrain_compatible",
            "text-embeddings-inference",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 145767733,
          "likes": 4133
        },
        {
          "id": "BAAI/bge-m3",
          "type": "hf.sentence_similarity",
          "name": "BAAI/bge-m3",
          "repo_id": "BAAI/bge-m3",
          "allow_patterns": [
            "*.safetensors",
            "*.txt",
            "*,json"
          ],
          "size_on_disk": 0,
          "pipeline_tag": "sentence-similarity",
          "tags": [
            "sentence-transformers",
            "pytorch",
            "onnx",
            "xlm-roberta",
            "feature-extraction",
            "sentence-similarity",
            "arxiv:2402.03216",
            "arxiv:2004.04906",
            "arxiv:2106.14807",
            "arxiv:2107.05720",
            "arxiv:2004.12832",
            "license:mit",
            "autotrain_compatible",
            "text-embeddings-inference",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 6872418,
          "likes": 2510
        },
        {
          "id": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
          "type": "hf.sentence_similarity",
          "name": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
          "repo_id": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
          "allow_patterns": [
            "*.safetensors",
            "*.txt",
            "*,json"
          ],
          "size_on_disk": 470641600,
          "pipeline_tag": "sentence-similarity",
          "tags": [
            "sentence-transformers",
            "pytorch",
            "tf",
            "onnx",
            "safetensors",
            "openvino",
            "bert",
            "feature-extraction",
            "sentence-similarity",
            "transformers",
            "multilingual",
            "ar",
            "bg",
            "ca",
            "cs",
            "da",
            "de",
            "el",
            "en",
            "es",
            "et",
            "fa",
            "fi",
            "fr",
            "gl",
            "gu",
            "he",
            "hi",
            "hr",
            "hu",
            "hy",
            "id",
            "it",
            "ja",
            "ka",
            "ko",
            "ku",
            "lt",
            "lv",
            "mk",
            "mn",
            "mr",
            "ms",
            "my",
            "nb",
            "nl",
            "pl",
            "pt",
            "ro",
            "ru",
            "sk",
            "sl",
            "sq",
            "sr",
            "sv",
            "th",
            "tr",
            "uk",
            "ur",
            "vi",
            "arxiv:1908.10084",
            "license:apache-2.0",
            "autotrain_compatible",
            "text-embeddings-inference",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 14145374,
          "likes": 1059
        }
      ],
      "basic_fields": [
        "model",
        "inputs"
      ]
    },
    {
      "title": "Flux Fill",
      "description": "Performs image inpainting/filling using FLUX Fill models with support for GGUF quantization.\n    image, inpainting, fill, flux, quantization, mask\n\n    Use cases:\n    - Fill masked regions in images with high-quality content\n    - Remove unwanted objects from images\n    - Complete missing parts of images\n    - Memory-efficient inpainting using GGUF quantization\n    - High-quality image editing with FLUX models",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.FluxFill",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.inpainting"
          },
          "default": {
            "type": "hf.inpainting",
            "repo_id": "black-forest-labs/FLUX.1-Fill-dev",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model",
          "description": "The FLUX Fill model to use for image inpainting."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "a white paper cup",
          "title": "Prompt",
          "description": "A text prompt describing what should fill the masked area."
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Input Image",
          "description": "The input image to fill/inpaint"
        },
        {
          "name": "mask_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Mask Image",
          "description": "The mask image indicating areas to be filled (white areas will be filled)"
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Height",
          "description": "The height of the generated image.",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Width",
          "description": "The width of the generated image.",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 30.0,
          "title": "Guidance Scale",
          "description": "Guidance scale for generation. Higher values follow the prompt more closely",
          "min": 0.0,
          "max": 50.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "max_sequence_length",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Max Sequence Length",
          "description": "Maximum sequence length for the prompt.",
          "min": 1.0,
          "max": 512.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload to reduce VRAM usage."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "black-forest-labs/FLUX.1-Fill-dev",
          "type": "hf.inpainting",
          "name": "black-forest-labs/FLUX.1-Fill-dev",
          "repo_id": "black-forest-labs/FLUX.1-Fill-dev",
          "size_on_disk": 58056239932,
          "tags": [
            "diffusers",
            "safetensors",
            "image-generation",
            "flux",
            "diffusion-single-file",
            "en",
            "license:other",
            "diffusers:FluxFillPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 218428,
          "likes": 958
        }
      ],
      "basic_fields": [
        "model",
        "image",
        "mask_image",
        "prompt",
        "height",
        "width",
        "guidance_scale",
        "num_inference_steps",
        "seed"
      ]
    },
    {
      "title": "Flux Kontext",
      "description": "Performs image editing using FLUX Kontext models for context-aware image generation.\n    image, editing, flux, kontext, context-aware, generation\n\n    Use cases:\n    - Edit images based on reference context\n    - Add elements to images guided by prompts\n    - Context-aware image modifications\n    - High-quality image editing with FLUX models",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.FluxKontext",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.flux_kontext"
          },
          "default": {
            "type": "hf.flux_kontext",
            "repo_id": "black-forest-labs/FLUX.1-Kontext-dev",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model",
          "description": "The FLUX Kontext model to use for image editing."
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Input Image",
          "description": "The input image to edit"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "Add a hat to the cat",
          "title": "Prompt",
          "description": "Text description of the desired edit to apply to the image"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 2.5,
          "title": "Guidance Scale",
          "description": "Guidance scale for editing. Higher values follow the prompt more closely",
          "min": 0.0,
          "max": 30.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed",
          "min": -1.0
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload to reduce VRAM usage."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "black-forest-labs/FLUX.1-Kontext-dev",
          "type": "hf.flux_kontext",
          "name": "black-forest-labs/FLUX.1-Kontext-dev",
          "repo_id": "black-forest-labs/FLUX.1-Kontext-dev",
          "size_on_disk": 57890836779,
          "pipeline_tag": "image-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "image-generation",
            "flux",
            "diffusion-single-file",
            "image-to-image",
            "en",
            "arxiv:2506.15742",
            "license:other",
            "diffusers:FluxKontextPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 315384,
          "likes": 2438
        },
        {
          "id": "nunchaku-tech/nunchaku-flux.1-kontext-dev:svdq-int4_r32-flux.1-kontext-dev.safetensors",
          "type": "hf.flux_kontext",
          "name": "nunchaku-tech/nunchaku-flux.1-kontext-dev",
          "repo_id": "nunchaku-tech/nunchaku-flux.1-kontext-dev",
          "path": "svdq-int4_r32-flux.1-kontext-dev.safetensors",
          "size_on_disk": 6768310048,
          "pipeline_tag": "image-to-image",
          "tags": [
            "diffusers",
            "image-to-image",
            "SVDQuant",
            "FLUX.1-Kontext-dev",
            "FLUX.1",
            "Diffusion",
            "Quantization",
            "ICLR2025",
            "en",
            "dataset:mit-han-lab/svdquant-datasets",
            "arxiv:2411.05007",
            "base_model:black-forest-labs/FLUX.1-Kontext-dev",
            "base_model:quantized:black-forest-labs/FLUX.1-Kontext-dev",
            "license:other",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 44675,
          "likes": 54
        },
        {
          "id": "nunchaku-tech/nunchaku-flux.1-kontext-dev:svdq-fp4_r32-flux.1-kontext-dev.safetensors",
          "type": "hf.flux_kontext",
          "name": "nunchaku-tech/nunchaku-flux.1-kontext-dev",
          "repo_id": "nunchaku-tech/nunchaku-flux.1-kontext-dev",
          "path": "svdq-fp4_r32-flux.1-kontext-dev.safetensors",
          "size_on_disk": 7038707104,
          "pipeline_tag": "image-to-image",
          "tags": [
            "diffusers",
            "image-to-image",
            "SVDQuant",
            "FLUX.1-Kontext-dev",
            "FLUX.1",
            "Diffusion",
            "Quantization",
            "ICLR2025",
            "en",
            "dataset:mit-han-lab/svdquant-datasets",
            "arxiv:2411.05007",
            "base_model:black-forest-labs/FLUX.1-Kontext-dev",
            "base_model:quantized:black-forest-labs/FLUX.1-Kontext-dev",
            "license:other",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 44675,
          "likes": 54
        },
        {
          "id": "mit-han-lab/nunchaku-t5:awq-int4-flux.1-t5xxl.safetensors",
          "type": "hf.model",
          "name": "mit-han-lab/nunchaku-t5",
          "repo_id": "mit-han-lab/nunchaku-t5",
          "path": "awq-int4-flux.1-t5xxl.safetensors",
          "size_on_disk": 2986819952,
          "pipeline_tag": "text-generation",
          "tags": [
            "transformers",
            "text-generation",
            "AWQ",
            "Quantization",
            "en",
            "dataset:mit-han-lab/svdquant-datasets",
            "arxiv:2411.05007",
            "base_model:google/t5-v1_1-xxl",
            "base_model:quantized:google/t5-v1_1-xxl",
            "license:apache-2.0",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 2,
          "likes": 19
        }
      ],
      "basic_fields": [
        "model",
        "image",
        "prompt",
        "guidance_scale"
      ]
    },
    {
      "title": "Flux Prior Redux",
      "description": "Performs image transformation using FLUX Prior Redux pipeline for image-conditioned generation.\n    image, transformation, flux, redux, prior, image-conditioned, generation\n\n    Use cases:\n    - Transform images using FLUX Prior Redux for style transfer and image variations\n    - Generate images conditioned on reference images without text prompts\n    - High-quality image-to-image transformation with FLUX models\n    - Create variations of existing images with FLUX Prior Redux guidance",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.FluxPriorRedux",
      "properties": [
        {
          "name": "prior_redux_model",
          "type": {
            "type": "hf.flux_redux"
          },
          "default": {
            "type": "hf.flux_redux",
            "repo_id": "black-forest-labs/FLUX.1-Redux-dev",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Prior Redux Model",
          "description": "The FLUX Prior Redux model to use for image conditioning."
        },
        {
          "name": "flux_model",
          "type": {
            "type": "hf.flux"
          },
          "default": {
            "type": "hf.flux",
            "repo_id": "black-forest-labs/FLUX.1-dev",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Flux Model",
          "description": "The FLUX base model to use for generation."
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Input Image",
          "description": "The input image to transform"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 2.5,
          "title": "Guidance Scale",
          "description": "Guidance scale for generation. Higher values follow the prior more closely",
          "min": 0.0,
          "max": 30.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed",
          "min": -1.0
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload to reduce VRAM usage."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prior_redux_model",
        "flux_model",
        "image",
        "guidance_scale",
        "num_inference_steps",
        "seed"
      ]
    },
    {
      "title": "Image to Image",
      "description": "Transforms existing images based on text prompts using AutoPipeline for Image-to-Image.\n    This node automatically detects the appropriate pipeline class based on the model used.\n    image, generation, image-to-image, autopipeline\n\n    Use cases:\n    - Transform existing images with any compatible model (Stable Diffusion, SDXL, Kandinsky, etc.)\n    - Apply specific styles or concepts to photographs or artwork\n    - Modify existing images based on text descriptions\n    - Create variations of existing visual content with automatic pipeline selection",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.ImageToImage",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.image_to_image"
          },
          "default": {
            "type": "hf.image_to_image",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model",
          "description": "The HuggingFace model to use for image-to-image generation."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "A beautiful landscape with mountains and a lake at sunset",
          "title": "Prompt",
          "description": "Text prompt describing the desired image transformation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Text prompt describing what should not appear in the generated image."
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Input Image",
          "description": "The input image to transform"
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 0.8,
          "title": "Strength",
          "description": "Strength of the transformation. Higher values allow for more deviation from the original image.",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "Guidance scale for generation. Higher values follow the prompt more closely.",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "model",
        "image",
        "prompt",
        "negative_prompt",
        "strength"
      ]
    },
    {
      "title": "AutoPipeline Inpainting",
      "description": "Performs inpainting on images using AutoPipeline for Inpainting.\n    This node automatically detects the appropriate pipeline class based on the model used.\n    image, inpainting, autopipeline, stable-diffusion, SDXL, kandinsky\n\n    Use cases:\n    - Remove unwanted objects from images with any compatible model\n    - Fill in missing parts of images using various diffusion models\n    - Modify specific areas of images while preserving the rest\n    - Automatic pipeline selection for different model architectures",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.Inpaint",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.image_to_image"
          },
          "default": {
            "type": "hf.image_to_image",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model",
          "description": "The HuggingFace model to use for inpainting."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text prompt describing what should be generated in the masked area."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Text prompt describing what should not appear in the generated content."
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Input Image",
          "description": "The input image to inpaint"
        },
        {
          "name": "mask_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Mask Image",
          "description": "The mask image indicating areas to be inpainted (white areas will be inpainted)"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "Guidance scale for generation. Higher values follow the prompt more closely.",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "model",
        "image",
        "mask_image",
        "prompt",
        "negative_prompt"
      ]
    },
    {
      "title": "Load Image To Image Model",
      "description": "Load HuggingFace model for image-to-image generation from a repo_id.\n\n    Use cases:\n    - Loads a pipeline directly from a repo_id\n    - Used for ImageToImage node",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.LoadImageToImageModel",
      "properties": [
        {
          "name": "repo_id",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Repo Id",
          "description": "The repository ID of the model to use for image-to-image generation."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "hf.image_to_image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "repo_id"
      ]
    },
    {
      "title": "OmniGen",
      "description": "Generates and edits images using the OmniGen model, supporting multimodal inputs.\n    image, generation, text-to-image, image-editing, multimodal, omnigen\n\n    Use cases:\n    - Generate images from text prompts\n    - Edit existing images with text instructions\n    - Controllable image generation with reference images\n    - Visual reasoning and image manipulation\n    - ID and object preserving generation",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.OmniGen",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "A realistic photo of a young woman sitting on a sofa, holding a book and facing the camera.",
          "title": "Prompt",
          "description": "The text prompt for image generation. Use <img><|image_1|></img> placeholders to reference input images."
        },
        {
          "name": "input_images",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "image"
              }
            ]
          },
          "default": [],
          "title": "Input Images",
          "description": "List of input images to use for editing or as reference. Referenced in prompt using <img><|image_1|></img>, <img><|image_2|></img>, etc."
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Height",
          "description": "Height of the generated image.",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Width",
          "description": "Width of the generated image.",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 2.5,
          "title": "Guidance Scale",
          "description": "Guidance scale for generation. Higher values follow the prompt more closely.",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "img_guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 1.6,
          "title": "Img Guidance Scale",
          "description": "Image guidance scale when using input images.",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0
        },
        {
          "name": "use_input_image_size_as_output",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Use Input Image Size As Output",
          "description": "If True, use the input image size as output size. Recommended for image editing."
        },
        {
          "name": "max_input_image_size",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Max Input Image Size",
          "description": "Maximum input image size. Smaller values reduce memory usage but may affect quality.",
          "min": 256.0,
          "max": 2048.0
        },
        {
          "name": "enable_model_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Model Cpu Offload",
          "description": "Enable CPU offload to reduce memory usage when using multiple images."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "Shitao/OmniGen-v1-diffusers",
          "type": "hf.model",
          "name": "Shitao/OmniGen-v1-diffusers",
          "repo_id": "Shitao/OmniGen-v1-diffusers",
          "allow_patterns": [
            "README.md",
            "*.safetensors",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 8088954905,
          "tags": [
            "diffusers",
            "safetensors",
            "license:mit",
            "diffusers:OmniGenPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 1093,
          "likes": 4
        }
      ],
      "basic_fields": [
        "prompt",
        "input_images",
        "height",
        "width",
        "guidance_scale"
      ]
    },
    {
      "title": "Qwen Image Edit",
      "description": "Performs image editing using the Qwen Image Edit model with support for Nunchaku quantization.\n    image, editing, semantic, appearance, qwen, multimodal, quantization\n\n    Use cases:\n    - Semantic editing (object rotation, style transfer)\n    - Appearance editing (adding/removing elements)\n    - Precise text modifications in images\n    - Background and clothing changes\n    - Complex image transformations guided by text\n    - Memory-efficient editing using Nunchaku quantization",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.QwenImageEdit",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.qwen_image_edit"
          },
          "default": {
            "type": "hf.qwen_image_edit",
            "repo_id": "mit-han-lab/nunchaku-qwen-image-edit",
            "path": "awq-int4-qwen-image-edit.safetensors",
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model",
          "description": "The Qwen-Image-Edit model to use for image editing."
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Input Image",
          "description": "The input image to edit"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "Change the object's color to blue",
          "title": "Prompt",
          "description": "Text description of the desired edit to apply to the image"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Text describing what should not appear in the edited image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps for the editing process",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "true_cfg_scale",
          "type": {
            "type": "float"
          },
          "default": 4.0,
          "title": "True Cfg Scale",
          "description": "Guidance scale for editing. Higher values follow the prompt more closely",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed",
          "min": -1.0
        },
        {
          "name": "enable_memory_efficient_attention",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Memory Efficient Attention",
          "description": "Enable memory efficient attention to reduce VRAM usage."
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload to reduce VRAM usage."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "mit-han-lab/nunchaku-qwen-image-edit:awq-int4-qwen-image-edit.safetensors",
          "type": "hf.qwen_image_edit",
          "name": "mit-han-lab/nunchaku-qwen-image-edit",
          "repo_id": "mit-han-lab/nunchaku-qwen-image-edit",
          "path": "awq-int4-qwen-image-edit.safetensors"
        }
      ],
      "basic_fields": [
        "model",
        "image",
        "prompt",
        "negative_prompt",
        "true_cfg_scale"
      ]
    },
    {
      "title": "Real ESRGAN",
      "description": "Performs image super-resolution using the RealESRGAN model.\n    image, super-resolution, enhancement, huggingface\n\n    Use cases:\n    - Enhance low-resolution images\n    - Improve image quality for printing or display\n    - Upscale images for better detail",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.RealESRGAN",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Input Image",
          "description": "The input image to transform"
        },
        {
          "name": "model",
          "type": {
            "type": "hf.real_esrgan"
          },
          "default": {
            "type": "hf.real_esrgan",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "RealESRGAN Model",
          "description": "The RealESRGAN model to use for image super-resolution"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "ai-forever/Real-ESRGAN:RealESRGAN_x2.pth",
          "type": "hf.real_esrgan",
          "name": "ai-forever/Real-ESRGAN",
          "repo_id": "ai-forever/Real-ESRGAN",
          "path": "RealESRGAN_x2.pth",
          "size_on_disk": 67061725,
          "tags": [
            "PyTorch",
            "ru",
            "en",
            "arxiv:2107.10833",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 209
        },
        {
          "id": "ai-forever/Real-ESRGAN:RealESRGAN_x4.pth",
          "type": "hf.real_esrgan",
          "name": "ai-forever/Real-ESRGAN",
          "repo_id": "ai-forever/Real-ESRGAN",
          "path": "RealESRGAN_x4.pth",
          "size_on_disk": 67040989,
          "tags": [
            "PyTorch",
            "ru",
            "en",
            "arxiv:2107.10833",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 209
        },
        {
          "id": "ai-forever/Real-ESRGAN:RealESRGAN_x8.pth",
          "type": "hf.real_esrgan",
          "name": "ai-forever/Real-ESRGAN",
          "repo_id": "ai-forever/Real-ESRGAN",
          "path": "RealESRGAN_x8.pth",
          "size_on_disk": 67189359,
          "tags": [
            "PyTorch",
            "ru",
            "en",
            "arxiv:2107.10833",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 209
        },
        {
          "id": "ximso/RealESRGAN_x4plus_anime_6B:RealESRGAN_x4plus_anime_6B.pth",
          "type": "hf.real_esrgan",
          "name": "ximso/RealESRGAN_x4plus_anime_6B",
          "repo_id": "ximso/RealESRGAN_x4plus_anime_6B",
          "path": "RealESRGAN_x4plus_anime_6B.pth",
          "size_on_disk": 17938799,
          "tags": [
            "license:openrail",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 5
        }
      ],
      "basic_fields": [
        "image",
        "model"
      ]
    },
    {
      "title": "Stable Diffusion ControlNet",
      "description": "Generates images using Stable Diffusion with ControlNet guidance.\n    image, generation, text-to-image, controlnet, SD\n\n    Use cases:\n    - Generate images with precise control over composition and structure\n    - Create variations of existing images while maintaining specific features\n    - Artistic image generation with guided outputs",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.StableDiffusionControlNet",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.stable_diffusion"
          },
          "default": {
            "type": "hf.stable_diffusion",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model",
          "description": "The model to use for image generation."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt for image generation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to guide what should not appear in the generated image."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0,
          "max": 4294967295.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "Guidance scale for generation.",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "DPMSolverSDEScheduler",
              "EulerDiscreteScheduler",
              "LMSDiscreteScheduler",
              "DDIMScheduler",
              "DDPMScheduler",
              "HeunDiscreteScheduler",
              "DPMSolverMultistepScheduler",
              "DEISMultistepScheduler",
              "PNDMScheduler",
              "EulerAncestralDiscreteScheduler",
              "UniPCMultistepScheduler",
              "KDPM2DiscreteScheduler",
              "DPMSolverSinglestepScheduler",
              "KDPM2AncestralDiscreteScheduler"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionBaseNode.StableDiffusionScheduler"
          },
          "default": "EulerDiscreteScheduler",
          "title": "Scheduler",
          "description": "The scheduler to use for the diffusion process."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "hf.lora_sd_config"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "The LoRA models to use for image processing"
        },
        {
          "name": "ip_adapter_model",
          "type": {
            "type": "hf.ip_adapter"
          },
          "default": {
            "type": "hf.ip_adapter",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Ip Adapter Model",
          "description": "The IP adapter model to use for image processing"
        },
        {
          "name": "ip_adapter_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Ip Adapter Image",
          "description": "When provided the image will be fed into the IP adapter"
        },
        {
          "name": "ip_adapter_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Ip Adapter Scale",
          "description": "The strength of the IP adapter",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "latents",
          "type": {
            "type": "torch_tensor"
          },
          "default": {
            "type": "torch_tensor",
            "value": null,
            "dtype": "<i8",
            "shape": [
              1
            ]
          },
          "title": "Latents",
          "description": "Optional initial latents to start generation from."
        },
        {
          "name": "enable_attention_slicing",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Attention Slicing",
          "description": "Enable attention slicing for the pipeline. This can reduce VRAM usage."
        },
        {
          "name": "enable_tiling",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Tiling",
          "description": "Legacy VAE tiling flag (disabled in favor of PyTorch 2 attention optimizations)."
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage."
        },
        {
          "name": "output_type",
          "type": {
            "type": "enum",
            "values": [
              "Image",
              "Latent"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionBaseNode.StableDiffusionOutputType"
          },
          "default": "Image",
          "title": "Output Type",
          "description": "The type of output to generate."
        },
        {
          "name": "controlnet",
          "type": {
            "type": "hf.controlnet"
          },
          "default": {
            "type": "hf.controlnet",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Controlnet",
          "description": "The ControlNet model to use for guidance."
        },
        {
          "name": "control_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Control Image",
          "description": "The control image to guide the generation process."
        },
        {
          "name": "controlnet_conditioning_scale",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Controlnet Conditioning Scale",
          "description": "The scale for ControlNet conditioning.",
          "min": 0.0,
          "max": 2.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "torch_tensor"
          },
          "name": "latent"
        }
      ],
      "recommended_models": [
        {
          "id": "lllyasviel/control_v11p_sd15_canny:diffusion_pytorch_model.fp16.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/control_v11p_sd15_canny",
          "repo_id": "lllyasviel/control_v11p_sd15_canny",
          "path": "diffusion_pytorch_model.fp16.safetensors",
          "size_on_disk": 722598642,
          "pipeline_tag": "image-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "art",
            "controlnet",
            "stable-diffusion",
            "controlnet-v1-1",
            "image-to-image",
            "arxiv:2302.05543",
            "base_model:runwayml/stable-diffusion-v1-5",
            "base_model:adapter:runwayml/stable-diffusion-v1-5",
            "license:openrail",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 13929,
          "likes": 52
        },
        {
          "id": "lllyasviel/control_v11p_sd15_inpaint:diffusion_pytorch_model.fp16.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/control_v11p_sd15_inpaint",
          "repo_id": "lllyasviel/control_v11p_sd15_inpaint",
          "path": "diffusion_pytorch_model.fp16.safetensors",
          "size_on_disk": 722598642,
          "pipeline_tag": "image-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "art",
            "controlnet",
            "stable-diffusion",
            "controlnet-v1-1",
            "image-to-image",
            "arxiv:2302.05543",
            "base_model:runwayml/stable-diffusion-v1-5",
            "base_model:adapter:runwayml/stable-diffusion-v1-5",
            "license:openrail",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 30848,
          "likes": 130
        },
        {
          "id": "lllyasviel/control_v11p_sd15_mlsd:diffusion_pytorch_model.fp16.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/control_v11p_sd15_mlsd",
          "repo_id": "lllyasviel/control_v11p_sd15_mlsd",
          "path": "diffusion_pytorch_model.fp16.safetensors",
          "size_on_disk": 722598642,
          "pipeline_tag": "image-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "art",
            "controlnet",
            "stable-diffusion",
            "controlnet-v1-1",
            "image-to-image",
            "arxiv:2302.05543",
            "base_model:runwayml/stable-diffusion-v1-5",
            "base_model:adapter:runwayml/stable-diffusion-v1-5",
            "license:openrail",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 10574,
          "likes": 17
        },
        {
          "id": "lllyasviel/control_v11p_sd15_lineart:diffusion_pytorch_model.fp16.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/control_v11p_sd15_lineart",
          "repo_id": "lllyasviel/control_v11p_sd15_lineart",
          "path": "diffusion_pytorch_model.fp16.safetensors",
          "size_on_disk": 722598642,
          "pipeline_tag": "image-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "art",
            "controlnet",
            "stable-diffusion",
            "controlnet-v1-1",
            "image-to-image",
            "arxiv:2302.05543",
            "base_model:runwayml/stable-diffusion-v1-5",
            "base_model:adapter:runwayml/stable-diffusion-v1-5",
            "license:openrail",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 9073,
          "likes": 72
        },
        {
          "id": "lllyasviel/control_v11p_sd15_scribble:diffusion_pytorch_model.fp16.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/control_v11p_sd15_scribble",
          "repo_id": "lllyasviel/control_v11p_sd15_scribble",
          "path": "diffusion_pytorch_model.fp16.safetensors",
          "size_on_disk": 722598642,
          "pipeline_tag": "image-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "art",
            "controlnet",
            "stable-diffusion",
            "controlnet-v1-1",
            "image-to-image",
            "arxiv:2302.05543",
            "base_model:runwayml/stable-diffusion-v1-5",
            "base_model:adapter:runwayml/stable-diffusion-v1-5",
            "license:openrail",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 7187,
          "likes": 29
        },
        {
          "id": "lllyasviel/control_v11p_sd15_openpose:diffusion_pytorch_model.fp16.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/control_v11p_sd15_openpose",
          "repo_id": "lllyasviel/control_v11p_sd15_openpose",
          "path": "diffusion_pytorch_model.fp16.safetensors",
          "size_on_disk": 722598642,
          "pipeline_tag": "image-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "art",
            "controlnet",
            "stable-diffusion",
            "controlnet-v1-1",
            "image-to-image",
            "arxiv:2302.05543",
            "base_model:runwayml/stable-diffusion-v1-5",
            "base_model:adapter:runwayml/stable-diffusion-v1-5",
            "license:openrail",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12837,
          "likes": 127
        },
        {
          "id": "lllyasviel/sd_control_collection:ip-adapter_sd15_plus.pth",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "ip-adapter_sd15_plus.pth",
          "size_on_disk": 158030471,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:ip-adapter_sd15.pth",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "ip-adapter_sd15.pth",
          "size_on_disk": 44642819,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:ioclab_sd15_recolor.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "ioclab_sd15_recolor.safetensors",
          "size_on_disk": 722598616,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "h94/IP-Adapter:models/ip-adapter_sd15.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "models/ip-adapter_sd15.bin",
          "size_on_disk": 44642825,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "h94/IP-Adapter:models/ip-adapter_sd15_light.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "models/ip-adapter_sd15_light.bin",
          "size_on_disk": 44642819,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "h94/IP-Adapter:models/ip-adapter_sd15_vit-G.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "models/ip-adapter_sd15_vit-G.bin",
          "size_on_disk": 46215689,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "Lykon/DreamShaper:DreamShaper_6.2_BakedVae_pruned.safetensors",
          "type": "hf.stable_diffusion",
          "name": "Lykon/DreamShaper",
          "repo_id": "Lykon/DreamShaper",
          "path": "DreamShaper_6.2_BakedVae_pruned.safetensors",
          "size_on_disk": 2132625894,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "stable-diffusion",
            "stable-diffusion-diffusers",
            "text-to-image",
            "art",
            "artistic",
            "anime",
            "en",
            "doi:10.57967/hf/0453",
            "license:other",
            "autotrain_compatible",
            "diffusers:StableDiffusionPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 201878,
          "likes": 992
        }
      ],
      "basic_fields": [
        "model",
        "prompt",
        "controlnet",
        "control_image",
        "controlnet_conditioning_scale"
      ]
    },
    {
      "title": "Stable Diffusion ControlNet (Img2Img)",
      "description": "Transforms existing images using Stable Diffusion with ControlNet guidance.\n    image, generation, image-to-image, controlnet, SD, style-transfer\n\n    Use cases:\n    - Modify existing images with precise control over composition and structure\n    - Apply specific styles or concepts to photographs or artwork with guided transformations\n    - Create variations of existing visual content while maintaining certain features\n    - Enhance image editing capabilities with AI-guided transformations",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.StableDiffusionControlNetImg2Img",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.stable_diffusion"
          },
          "default": {
            "type": "hf.stable_diffusion",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model",
          "description": "The model to use for image generation."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt for image generation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to guide what should not appear in the generated image."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0,
          "max": 4294967295.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "Guidance scale for generation.",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "DPMSolverSDEScheduler",
              "EulerDiscreteScheduler",
              "LMSDiscreteScheduler",
              "DDIMScheduler",
              "DDPMScheduler",
              "HeunDiscreteScheduler",
              "DPMSolverMultistepScheduler",
              "DEISMultistepScheduler",
              "PNDMScheduler",
              "EulerAncestralDiscreteScheduler",
              "UniPCMultistepScheduler",
              "KDPM2DiscreteScheduler",
              "DPMSolverSinglestepScheduler",
              "KDPM2AncestralDiscreteScheduler"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionBaseNode.StableDiffusionScheduler"
          },
          "default": "EulerDiscreteScheduler",
          "title": "Scheduler",
          "description": "The scheduler to use for the diffusion process."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "hf.lora_sd_config"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "The LoRA models to use for image processing"
        },
        {
          "name": "ip_adapter_model",
          "type": {
            "type": "hf.ip_adapter"
          },
          "default": {
            "type": "hf.ip_adapter",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Ip Adapter Model",
          "description": "The IP adapter model to use for image processing"
        },
        {
          "name": "ip_adapter_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Ip Adapter Image",
          "description": "When provided the image will be fed into the IP adapter"
        },
        {
          "name": "ip_adapter_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Ip Adapter Scale",
          "description": "The strength of the IP adapter",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "latents",
          "type": {
            "type": "torch_tensor"
          },
          "default": {
            "type": "torch_tensor",
            "value": null,
            "dtype": "<i8",
            "shape": [
              1
            ]
          },
          "title": "Latents",
          "description": "Optional initial latents to start generation from."
        },
        {
          "name": "enable_attention_slicing",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Attention Slicing",
          "description": "Enable attention slicing for the pipeline. This can reduce VRAM usage."
        },
        {
          "name": "enable_tiling",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Tiling",
          "description": "Legacy VAE tiling flag (disabled in favor of PyTorch 2 attention optimizations)."
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage."
        },
        {
          "name": "output_type",
          "type": {
            "type": "enum",
            "values": [
              "Image",
              "Latent"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionBaseNode.StableDiffusionOutputType"
          },
          "default": "Image",
          "title": "Output Type",
          "description": "The type of output to generate."
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The input image to be transformed."
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Strength",
          "description": "Similarity to the input image",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "controlnet",
          "type": {
            "type": "hf.controlnet"
          },
          "default": {
            "type": "hf.controlnet",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Controlnet",
          "description": "The ControlNet model to use for guidance."
        },
        {
          "name": "control_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Control Image",
          "description": "The control image to guide the transformation."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "torch_tensor"
          },
          "name": "latent"
        }
      ],
      "recommended_models": [
        {
          "id": "lllyasviel/control_v11p_sd15_canny:diffusion_pytorch_model.fp16.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/control_v11p_sd15_canny",
          "repo_id": "lllyasviel/control_v11p_sd15_canny",
          "path": "diffusion_pytorch_model.fp16.safetensors",
          "size_on_disk": 722598642,
          "pipeline_tag": "image-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "art",
            "controlnet",
            "stable-diffusion",
            "controlnet-v1-1",
            "image-to-image",
            "arxiv:2302.05543",
            "base_model:runwayml/stable-diffusion-v1-5",
            "base_model:adapter:runwayml/stable-diffusion-v1-5",
            "license:openrail",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 13929,
          "likes": 52
        },
        {
          "id": "lllyasviel/control_v11p_sd15_inpaint:diffusion_pytorch_model.fp16.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/control_v11p_sd15_inpaint",
          "repo_id": "lllyasviel/control_v11p_sd15_inpaint",
          "path": "diffusion_pytorch_model.fp16.safetensors",
          "size_on_disk": 722598642,
          "pipeline_tag": "image-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "art",
            "controlnet",
            "stable-diffusion",
            "controlnet-v1-1",
            "image-to-image",
            "arxiv:2302.05543",
            "base_model:runwayml/stable-diffusion-v1-5",
            "base_model:adapter:runwayml/stable-diffusion-v1-5",
            "license:openrail",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 30848,
          "likes": 130
        },
        {
          "id": "lllyasviel/control_v11p_sd15_mlsd:diffusion_pytorch_model.fp16.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/control_v11p_sd15_mlsd",
          "repo_id": "lllyasviel/control_v11p_sd15_mlsd",
          "path": "diffusion_pytorch_model.fp16.safetensors",
          "size_on_disk": 722598642,
          "pipeline_tag": "image-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "art",
            "controlnet",
            "stable-diffusion",
            "controlnet-v1-1",
            "image-to-image",
            "arxiv:2302.05543",
            "base_model:runwayml/stable-diffusion-v1-5",
            "base_model:adapter:runwayml/stable-diffusion-v1-5",
            "license:openrail",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 10574,
          "likes": 17
        },
        {
          "id": "lllyasviel/control_v11p_sd15_lineart:diffusion_pytorch_model.fp16.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/control_v11p_sd15_lineart",
          "repo_id": "lllyasviel/control_v11p_sd15_lineart",
          "path": "diffusion_pytorch_model.fp16.safetensors",
          "size_on_disk": 722598642,
          "pipeline_tag": "image-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "art",
            "controlnet",
            "stable-diffusion",
            "controlnet-v1-1",
            "image-to-image",
            "arxiv:2302.05543",
            "base_model:runwayml/stable-diffusion-v1-5",
            "base_model:adapter:runwayml/stable-diffusion-v1-5",
            "license:openrail",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 9073,
          "likes": 72
        },
        {
          "id": "lllyasviel/control_v11p_sd15_scribble:diffusion_pytorch_model.fp16.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/control_v11p_sd15_scribble",
          "repo_id": "lllyasviel/control_v11p_sd15_scribble",
          "path": "diffusion_pytorch_model.fp16.safetensors",
          "size_on_disk": 722598642,
          "pipeline_tag": "image-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "art",
            "controlnet",
            "stable-diffusion",
            "controlnet-v1-1",
            "image-to-image",
            "arxiv:2302.05543",
            "base_model:runwayml/stable-diffusion-v1-5",
            "base_model:adapter:runwayml/stable-diffusion-v1-5",
            "license:openrail",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 7187,
          "likes": 29
        },
        {
          "id": "lllyasviel/control_v11p_sd15_openpose:diffusion_pytorch_model.fp16.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/control_v11p_sd15_openpose",
          "repo_id": "lllyasviel/control_v11p_sd15_openpose",
          "path": "diffusion_pytorch_model.fp16.safetensors",
          "size_on_disk": 722598642,
          "pipeline_tag": "image-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "art",
            "controlnet",
            "stable-diffusion",
            "controlnet-v1-1",
            "image-to-image",
            "arxiv:2302.05543",
            "base_model:runwayml/stable-diffusion-v1-5",
            "base_model:adapter:runwayml/stable-diffusion-v1-5",
            "license:openrail",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12837,
          "likes": 127
        },
        {
          "id": "lllyasviel/sd_control_collection:ip-adapter_sd15_plus.pth",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "ip-adapter_sd15_plus.pth",
          "size_on_disk": 158030471,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:ip-adapter_sd15.pth",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "ip-adapter_sd15.pth",
          "size_on_disk": 44642819,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:ioclab_sd15_recolor.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "ioclab_sd15_recolor.safetensors",
          "size_on_disk": 722598616,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "h94/IP-Adapter:models/ip-adapter_sd15.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "models/ip-adapter_sd15.bin",
          "size_on_disk": 44642825,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "h94/IP-Adapter:models/ip-adapter_sd15_light.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "models/ip-adapter_sd15_light.bin",
          "size_on_disk": 44642819,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "h94/IP-Adapter:models/ip-adapter_sd15_vit-G.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "models/ip-adapter_sd15_vit-G.bin",
          "size_on_disk": 46215689,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "Lykon/DreamShaper:DreamShaper_6.2_BakedVae_pruned.safetensors",
          "type": "hf.stable_diffusion",
          "name": "Lykon/DreamShaper",
          "repo_id": "Lykon/DreamShaper",
          "path": "DreamShaper_6.2_BakedVae_pruned.safetensors",
          "size_on_disk": 2132625894,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "stable-diffusion",
            "stable-diffusion-diffusers",
            "text-to-image",
            "art",
            "artistic",
            "anime",
            "en",
            "doi:10.57967/hf/0453",
            "license:other",
            "autotrain_compatible",
            "diffusers:StableDiffusionPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 201878,
          "likes": 992
        }
      ],
      "basic_fields": [
        "model",
        "prompt",
        "image",
        "controlnet",
        "control_image"
      ]
    },
    {
      "title": "Stable Diffusion ControlNet Inpaint",
      "description": "Performs inpainting on images using Stable Diffusion with ControlNet guidance.\n    image, inpainting, controlnet, SD, style-transfer\n\n    Use cases:\n    - Remove unwanted objects from images with precise control\n    - Fill in missing parts of images guided by control images\n    - Modify specific areas of images while preserving the rest and maintaining structure",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.StableDiffusionControlNetInpaint",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.stable_diffusion"
          },
          "default": {
            "type": "hf.stable_diffusion",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model",
          "description": "The model to use for image generation."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt for image generation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to guide what should not appear in the generated image."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0,
          "max": 4294967295.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "Guidance scale for generation.",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "DPMSolverSDEScheduler",
              "EulerDiscreteScheduler",
              "LMSDiscreteScheduler",
              "DDIMScheduler",
              "DDPMScheduler",
              "HeunDiscreteScheduler",
              "DPMSolverMultistepScheduler",
              "DEISMultistepScheduler",
              "PNDMScheduler",
              "EulerAncestralDiscreteScheduler",
              "UniPCMultistepScheduler",
              "KDPM2DiscreteScheduler",
              "DPMSolverSinglestepScheduler",
              "KDPM2AncestralDiscreteScheduler"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionBaseNode.StableDiffusionScheduler"
          },
          "default": "EulerDiscreteScheduler",
          "title": "Scheduler",
          "description": "The scheduler to use for the diffusion process."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "hf.lora_sd_config"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "The LoRA models to use for image processing"
        },
        {
          "name": "ip_adapter_model",
          "type": {
            "type": "hf.ip_adapter"
          },
          "default": {
            "type": "hf.ip_adapter",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Ip Adapter Model",
          "description": "The IP adapter model to use for image processing"
        },
        {
          "name": "ip_adapter_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Ip Adapter Image",
          "description": "When provided the image will be fed into the IP adapter"
        },
        {
          "name": "ip_adapter_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Ip Adapter Scale",
          "description": "The strength of the IP adapter",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "latents",
          "type": {
            "type": "torch_tensor"
          },
          "default": {
            "type": "torch_tensor",
            "value": null,
            "dtype": "<i8",
            "shape": [
              1
            ]
          },
          "title": "Latents",
          "description": "Optional initial latents to start generation from."
        },
        {
          "name": "enable_attention_slicing",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Attention Slicing",
          "description": "Enable attention slicing for the pipeline. This can reduce VRAM usage."
        },
        {
          "name": "enable_tiling",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Tiling",
          "description": "Legacy VAE tiling flag (disabled in favor of PyTorch 2 attention optimizations)."
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage."
        },
        {
          "name": "output_type",
          "type": {
            "type": "enum",
            "values": [
              "Image",
              "Latent"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionBaseNode.StableDiffusionOutputType"
          },
          "default": "Image",
          "title": "Output Type",
          "description": "The type of output to generate."
        },
        {
          "name": "controlnet",
          "type": {
            "type": "enum",
            "values": [
              "lllyasviel/control_v11p_sd15_inpaint"
            ],
            "type_name": "nodetool.nodes.huggingface.image_to_image.StableDiffusionControlNetModel"
          },
          "default": "lllyasviel/control_v11p_sd15_inpaint",
          "title": "Controlnet",
          "description": "The ControlNet model to use for guidance."
        },
        {
          "name": "init_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Init Image",
          "description": "The initial image to be inpainted."
        },
        {
          "name": "mask_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Mask Image",
          "description": "The mask image indicating areas to be inpainted."
        },
        {
          "name": "control_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Control Image",
          "description": "The control image to guide the inpainting process."
        },
        {
          "name": "controlnet_conditioning_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Controlnet Conditioning Scale",
          "description": "The scale for ControlNet conditioning.",
          "min": 0.0,
          "max": 2.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "torch_tensor"
          },
          "name": "latent"
        }
      ],
      "recommended_models": [
        {
          "id": "h94/IP-Adapter:models/ip-adapter_sd15.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "models/ip-adapter_sd15.bin",
          "size_on_disk": 44642825,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "h94/IP-Adapter:models/ip-adapter_sd15_light.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "models/ip-adapter_sd15_light.bin",
          "size_on_disk": 44642819,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "h94/IP-Adapter:models/ip-adapter_sd15_vit-G.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "models/ip-adapter_sd15_vit-G.bin",
          "size_on_disk": 46215689,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "Lykon/DreamShaper:DreamShaper_6.2_BakedVae_pruned.safetensors",
          "type": "hf.stable_diffusion",
          "name": "Lykon/DreamShaper",
          "repo_id": "Lykon/DreamShaper",
          "path": "DreamShaper_6.2_BakedVae_pruned.safetensors",
          "size_on_disk": 2132625894,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "stable-diffusion",
            "stable-diffusion-diffusers",
            "text-to-image",
            "art",
            "artistic",
            "anime",
            "en",
            "doi:10.57967/hf/0453",
            "license:other",
            "autotrain_compatible",
            "diffusers:StableDiffusionPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 201878,
          "likes": 992
        }
      ],
      "basic_fields": [
        "model",
        "prompt",
        "init_image",
        "mask_image",
        "control_image",
        "controlnet_conditioning_scale"
      ]
    },
    {
      "title": "Stable Diffusion (Img2Img)",
      "description": "Transforms existing images based on text prompts using Stable Diffusion.\n    image, generation, image-to-image, SD, img2img, style-transfer\n\n    Use cases:\n    - Modifying existing images to fit a specific style or theme\n    - Enhancing or altering photographs\n    - Creating variations of existing artwork\n    - Applying text-guided edits to images",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.StableDiffusionImg2Img",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.stable_diffusion"
          },
          "default": {
            "type": "hf.stable_diffusion",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model",
          "description": "The model to use for image generation."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt for image generation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to guide what should not appear in the generated image."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0,
          "max": 4294967295.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "Guidance scale for generation.",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "DPMSolverSDEScheduler",
              "EulerDiscreteScheduler",
              "LMSDiscreteScheduler",
              "DDIMScheduler",
              "DDPMScheduler",
              "HeunDiscreteScheduler",
              "DPMSolverMultistepScheduler",
              "DEISMultistepScheduler",
              "PNDMScheduler",
              "EulerAncestralDiscreteScheduler",
              "UniPCMultistepScheduler",
              "KDPM2DiscreteScheduler",
              "DPMSolverSinglestepScheduler",
              "KDPM2AncestralDiscreteScheduler"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionBaseNode.StableDiffusionScheduler"
          },
          "default": "EulerDiscreteScheduler",
          "title": "Scheduler",
          "description": "The scheduler to use for the diffusion process."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "hf.lora_sd_config"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "The LoRA models to use for image processing"
        },
        {
          "name": "ip_adapter_model",
          "type": {
            "type": "hf.ip_adapter"
          },
          "default": {
            "type": "hf.ip_adapter",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Ip Adapter Model",
          "description": "The IP adapter model to use for image processing"
        },
        {
          "name": "ip_adapter_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Ip Adapter Image",
          "description": "When provided the image will be fed into the IP adapter"
        },
        {
          "name": "ip_adapter_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Ip Adapter Scale",
          "description": "The strength of the IP adapter",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "latents",
          "type": {
            "type": "torch_tensor"
          },
          "default": {
            "type": "torch_tensor",
            "value": null,
            "dtype": "<i8",
            "shape": [
              1
            ]
          },
          "title": "Latents",
          "description": "Optional initial latents to start generation from."
        },
        {
          "name": "enable_attention_slicing",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Attention Slicing",
          "description": "Enable attention slicing for the pipeline. This can reduce VRAM usage."
        },
        {
          "name": "enable_tiling",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Tiling",
          "description": "Legacy VAE tiling flag (disabled in favor of PyTorch 2 attention optimizations)."
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage."
        },
        {
          "name": "output_type",
          "type": {
            "type": "enum",
            "values": [
              "Image",
              "Latent"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionBaseNode.StableDiffusionOutputType"
          },
          "default": "Image",
          "title": "Output Type",
          "description": "The type of output to generate."
        },
        {
          "name": "init_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Init Image",
          "description": "The initial image for Image-to-Image generation."
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 0.8,
          "title": "Strength",
          "description": "Strength for Image-to-Image generation. Higher values allow for more deviation from the original image.",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "torch_tensor"
          },
          "name": "latent"
        }
      ],
      "recommended_models": [
        {
          "id": "h94/IP-Adapter:models/ip-adapter_sd15.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "models/ip-adapter_sd15.bin",
          "size_on_disk": 44642825,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "h94/IP-Adapter:models/ip-adapter_sd15_light.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "models/ip-adapter_sd15_light.bin",
          "size_on_disk": 44642819,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "h94/IP-Adapter:models/ip-adapter_sd15_vit-G.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "models/ip-adapter_sd15_vit-G.bin",
          "size_on_disk": 46215689,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "Lykon/DreamShaper:DreamShaper_6.2_BakedVae_pruned.safetensors",
          "type": "hf.stable_diffusion",
          "name": "Lykon/DreamShaper",
          "repo_id": "Lykon/DreamShaper",
          "path": "DreamShaper_6.2_BakedVae_pruned.safetensors",
          "size_on_disk": 2132625894,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "stable-diffusion",
            "stable-diffusion-diffusers",
            "text-to-image",
            "art",
            "artistic",
            "anime",
            "en",
            "doi:10.57967/hf/0453",
            "license:other",
            "autotrain_compatible",
            "diffusers:StableDiffusionPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 201878,
          "likes": 992
        }
      ],
      "basic_fields": [
        "model",
        "prompt",
        "init_image",
        "strength"
      ]
    },
    {
      "title": "Stable Diffusion (Inpaint)",
      "description": "Performs inpainting on images using Stable Diffusion.\n    image, inpainting, SD\n\n    Use cases:\n    - Remove unwanted objects from images\n    - Fill in missing parts of images\n    - Modify specific areas of images while preserving the rest",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.StableDiffusionInpaint",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.stable_diffusion"
          },
          "default": {
            "type": "hf.stable_diffusion",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model",
          "description": "The model to use for image generation."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt for image generation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to guide what should not appear in the generated image."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0,
          "max": 4294967295.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "Guidance scale for generation.",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "DPMSolverSDEScheduler",
              "EulerDiscreteScheduler",
              "LMSDiscreteScheduler",
              "DDIMScheduler",
              "DDPMScheduler",
              "HeunDiscreteScheduler",
              "DPMSolverMultistepScheduler",
              "DEISMultistepScheduler",
              "PNDMScheduler",
              "EulerAncestralDiscreteScheduler",
              "UniPCMultistepScheduler",
              "KDPM2DiscreteScheduler",
              "DPMSolverSinglestepScheduler",
              "KDPM2AncestralDiscreteScheduler"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionBaseNode.StableDiffusionScheduler"
          },
          "default": "EulerDiscreteScheduler",
          "title": "Scheduler",
          "description": "The scheduler to use for the diffusion process."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "hf.lora_sd_config"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "The LoRA models to use for image processing"
        },
        {
          "name": "ip_adapter_model",
          "type": {
            "type": "hf.ip_adapter"
          },
          "default": {
            "type": "hf.ip_adapter",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Ip Adapter Model",
          "description": "The IP adapter model to use for image processing"
        },
        {
          "name": "ip_adapter_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Ip Adapter Image",
          "description": "When provided the image will be fed into the IP adapter"
        },
        {
          "name": "ip_adapter_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Ip Adapter Scale",
          "description": "The strength of the IP adapter",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "latents",
          "type": {
            "type": "torch_tensor"
          },
          "default": {
            "type": "torch_tensor",
            "value": null,
            "dtype": "<i8",
            "shape": [
              1
            ]
          },
          "title": "Latents",
          "description": "Optional initial latents to start generation from."
        },
        {
          "name": "enable_attention_slicing",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Attention Slicing",
          "description": "Enable attention slicing for the pipeline. This can reduce VRAM usage."
        },
        {
          "name": "enable_tiling",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Tiling",
          "description": "Legacy VAE tiling flag (disabled in favor of PyTorch 2 attention optimizations)."
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage."
        },
        {
          "name": "output_type",
          "type": {
            "type": "enum",
            "values": [
              "Image",
              "Latent"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionBaseNode.StableDiffusionOutputType"
          },
          "default": "Image",
          "title": "Output Type",
          "description": "The type of output to generate."
        },
        {
          "name": "init_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Init Image",
          "description": "The initial image to be inpainted."
        },
        {
          "name": "mask_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Mask Image",
          "description": "The mask image indicating areas to be inpainted."
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 0.8,
          "title": "Strength",
          "description": "Strength for inpainting. Higher values allow for more deviation from the original image.",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "torch_tensor"
          },
          "name": "latent"
        }
      ],
      "recommended_models": [
        {
          "id": "h94/IP-Adapter:models/ip-adapter_sd15.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "models/ip-adapter_sd15.bin",
          "size_on_disk": 44642825,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "h94/IP-Adapter:models/ip-adapter_sd15_light.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "models/ip-adapter_sd15_light.bin",
          "size_on_disk": 44642819,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "h94/IP-Adapter:models/ip-adapter_sd15_vit-G.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "models/ip-adapter_sd15_vit-G.bin",
          "size_on_disk": 46215689,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "Lykon/DreamShaper:DreamShaper_6.2_BakedVae_pruned.safetensors",
          "type": "hf.stable_diffusion",
          "name": "Lykon/DreamShaper",
          "repo_id": "Lykon/DreamShaper",
          "path": "DreamShaper_6.2_BakedVae_pruned.safetensors",
          "size_on_disk": 2132625894,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "stable-diffusion",
            "stable-diffusion-diffusers",
            "text-to-image",
            "art",
            "artistic",
            "anime",
            "en",
            "doi:10.57967/hf/0453",
            "license:other",
            "autotrain_compatible",
            "diffusers:StableDiffusionPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 201878,
          "likes": 992
        }
      ],
      "basic_fields": [
        "model",
        "prompt",
        "init_image",
        "mask_image",
        "strength"
      ]
    },
    {
      "title": "Stable Diffusion Latent Upscaler",
      "description": "Upscales Stable Diffusion latents (x2) using the SD Latent Upscaler pipeline.\n    tensor, upscaling, stable-diffusion, latent, SD\n\n    Input and output are tensors for chaining with latent-based workflows.",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.StableDiffusionLatentUpscaler",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt for upscaling guidance."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to guide what should not appear in the result."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 10,
          "title": "Num Inference Steps",
          "description": "Number of upscaling denoising steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Guidance Scale",
          "description": "Guidance scale for upscaling. 0 preserves content strongly.",
          "min": 0.0,
          "max": 20.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0
        },
        {
          "name": "latents",
          "type": {
            "type": "torch_tensor"
          },
          "default": {
            "type": "torch_tensor",
            "value": null,
            "dtype": "<i8",
            "shape": [
              1
            ]
          },
          "title": "Latents",
          "description": "Low-resolution latents tensor to upscale."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "torch_tensor"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "latents",
        "prompt",
        "negative_prompt",
        "num_inference_steps",
        "guidance_scale"
      ]
    },
    {
      "title": "Stable Diffusion 4x Upscale",
      "description": "Upscales an image using Stable Diffusion 4x upscaler.\n    image, upscaling, stable-diffusion, SD\n\n    Use cases:\n    - Enhance low-resolution images\n    - Improve image quality for printing or display\n    - Create high-resolution versions of small images",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.StableDiffusionUpscale",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt for image generation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to guide what should not appear in the generated image."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Inference Steps",
          "description": "Number of upscaling steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "Guidance scale for generation.",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The initial image for Image-to-Image generation."
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "DPMSolverSDEScheduler",
              "EulerDiscreteScheduler",
              "LMSDiscreteScheduler",
              "DDIMScheduler",
              "DDPMScheduler",
              "HeunDiscreteScheduler",
              "DPMSolverMultistepScheduler",
              "DEISMultistepScheduler",
              "PNDMScheduler",
              "EulerAncestralDiscreteScheduler",
              "UniPCMultistepScheduler",
              "KDPM2DiscreteScheduler",
              "DPMSolverSinglestepScheduler",
              "KDPM2AncestralDiscreteScheduler"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionBaseNode.StableDiffusionScheduler"
          },
          "default": "HeunDiscreteScheduler",
          "title": "Scheduler",
          "description": "The scheduler to use for the diffusion process."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0,
          "max": 4294967295.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "stabilityai/stable-diffusion-x4-upscaler",
          "type": "hf.image_to_image",
          "name": "stabilityai/stable-diffusion-x4-upscaler",
          "repo_id": "stabilityai/stable-diffusion-x4-upscaler",
          "allow_patterns": [
            "README.md",
            "**/*.fp16.safetensors",
            "**/*.json",
            "**/*.txt",
            "*.json"
          ],
          "size_on_disk": 1739977012,
          "tags": [
            "diffusers",
            "safetensors",
            "stable-diffusion",
            "arxiv:2112.10752",
            "arxiv:2202.00512",
            "arxiv:1910.09700",
            "license:openrail++",
            "diffusers:StableDiffusionUpscalePipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 30322,
          "likes": 712
        }
      ],
      "basic_fields": [
        "prompt",
        "negative_prompt",
        "image"
      ]
    },
    {
      "title": "Stable Diffusion XL ControlNet",
      "description": "Generates images using Stable Diffusion XL with ControlNet guidance.\n    image, generation, text-to-image, controlnet, SDXL\n\n    Use cases:\n    - Generate images with precise control over composition and structure\n    - Create variations of existing images while maintaining specific features\n    - Artistic image generation with guided outputs",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.StableDiffusionXLControlNet",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.stable_diffusion_xl"
          },
          "default": {
            "type": "hf.stable_diffusion_xl",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model",
          "description": "The Stable Diffusion XL model to use for generation."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt for image generation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to guide what should not appear in the generated image."
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Width",
          "description": "Width of the generated image.",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Height",
          "description": "Height of the generated image",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator.",
          "min": -1.0,
          "max": 1000000.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Inference Steps",
          "description": "Number of inference steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.0,
          "title": "Guidance Scale",
          "description": "Guidance scale for generation.",
          "min": 0.0,
          "max": 20.0
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "DPMSolverSDEScheduler",
              "EulerDiscreteScheduler",
              "LMSDiscreteScheduler",
              "DDIMScheduler",
              "DDPMScheduler",
              "HeunDiscreteScheduler",
              "DPMSolverMultistepScheduler",
              "DEISMultistepScheduler",
              "PNDMScheduler",
              "EulerAncestralDiscreteScheduler",
              "UniPCMultistepScheduler",
              "KDPM2DiscreteScheduler",
              "DPMSolverSinglestepScheduler",
              "KDPM2AncestralDiscreteScheduler"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionXLBase.StableDiffusionScheduler"
          },
          "default": "EulerDiscreteScheduler",
          "title": "Scheduler",
          "description": "The scheduler to use for the diffusion process."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "hf.lora_sdxl_config"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "The LoRA models to use for image processing"
        },
        {
          "name": "lora_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Lora Scale",
          "description": "Strength of the LoRAs",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "ip_adapter_model",
          "type": {
            "type": "hf.ip_adapter"
          },
          "default": {
            "type": "hf.ip_adapter",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Ip Adapter Model",
          "description": "The IP adapter model to use for image processing"
        },
        {
          "name": "ip_adapter_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Ip Adapter Image",
          "description": "When provided the image will be fed into the IP adapter"
        },
        {
          "name": "ip_adapter_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Ip Adapter Scale",
          "description": "Strength of the IP adapter image",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "enable_attention_slicing",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Attention Slicing",
          "description": "Enable attention slicing for the pipeline. This can reduce VRAM usage but may slow down generation."
        },
        {
          "name": "enable_tiling",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Tiling",
          "description": "Legacy VAE tiling flag (disabled in favor of PyTorch 2 attention optimizations)."
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage."
        },
        {
          "name": "output_type",
          "type": {
            "type": "enum",
            "values": [
              "Image",
              "Latent"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionXLBase.StableDiffusionOutputType"
          },
          "default": "Image",
          "title": "Output Type",
          "description": "The type of output to generate."
        },
        {
          "name": "controlnet",
          "type": {
            "type": "hf.controlnet"
          },
          "default": {
            "type": "hf.controlnet",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Controlnet",
          "description": "The ControlNet model to use for guidance."
        },
        {
          "name": "control_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Control Image",
          "description": "The control image to guide the generation process."
        },
        {
          "name": "controlnet_conditioning_scale",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Controlnet Conditioning Scale",
          "description": "The scale for ControlNet conditioning.",
          "min": 0.0,
          "max": 2.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "torch_tensor"
          },
          "name": "latent"
        }
      ],
      "recommended_models": [
        {
          "id": "diffusers/controlnet-canny-sdxl-1.0:diffusion_pytorch_model.fp16.safetensors",
          "type": "hf.controlnet",
          "name": "diffusers/controlnet-canny-sdxl-1.0",
          "repo_id": "diffusers/controlnet-canny-sdxl-1.0",
          "path": "diffusion_pytorch_model.fp16.safetensors",
          "size_on_disk": 2502139136,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "stable-diffusion-xl",
            "stable-diffusion-xl-diffusers",
            "text-to-image",
            "base_model:runwayml/stable-diffusion-v1-5",
            "base_model:finetune:runwayml/stable-diffusion-v1-5",
            "license:openrail++",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 9966,
          "likes": 518
        },
        {
          "id": "diffusers/controlnet-depth-sdxl-1.0:diffusion_pytorch_model.fp16.safetensors",
          "type": "hf.controlnet",
          "name": "diffusers/controlnet-depth-sdxl-1.0",
          "repo_id": "diffusers/controlnet-depth-sdxl-1.0",
          "path": "diffusion_pytorch_model.fp16.safetensors",
          "size_on_disk": 2502139134,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "stable-diffusion-xl",
            "stable-diffusion-xl-diffusers",
            "text-to-image",
            "controlnet",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:adapter:stabilityai/stable-diffusion-xl-base-1.0",
            "license:openrail++",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 16846,
          "likes": 190
        },
        {
          "id": "diffusers/controlnet-zoe-depth-sdxl-1.0:diffusion_pytorch_model.fp16.safetensors",
          "type": "hf.controlnet",
          "name": "diffusers/controlnet-zoe-depth-sdxl-1.0",
          "repo_id": "diffusers/controlnet-zoe-depth-sdxl-1.0",
          "path": "diffusion_pytorch_model.fp16.safetensors",
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "stable-diffusion-xl",
            "stable-diffusion-xl-diffusers",
            "text-to-image",
            "controlnet",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:adapter:stabilityai/stable-diffusion-xl-base-1.0",
            "license:openrail++",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 833,
          "likes": 39
        },
        {
          "id": "lllyasviel/sd_control_collection:diffusers_xl_canny_full.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "diffusers_xl_canny_full.safetensors",
          "size_on_disk": 2502139104,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:diffusers_xl_canny_mid.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "diffusers_xl_canny_mid.safetensors",
          "size_on_disk": 545197704,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:diffusers_xl_canny_small.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "diffusers_xl_canny_small.safetensors",
          "size_on_disk": 320237152,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:diffusers_xl_depth_full.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "diffusers_xl_depth_full.safetensors",
          "size_on_disk": 2502139104,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:diffusers_xl_depth_mid.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "diffusers_xl_depth_mid.safetensors",
          "size_on_disk": 545197704,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:diffusers_xl_depth_small.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "diffusers_xl_depth_small.safetensors",
          "size_on_disk": 320237152,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:t2i-adapter_diffusers_xl_canny.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "t2i-adapter_diffusers_xl_canny.safetensors",
          "size_on_disk": 158060416,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:t2i-adapter_diffusers_xl_depth_midas.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "t2i-adapter_diffusers_xl_depth_midas.safetensors",
          "size_on_disk": 158060416,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:t2i-adapter_diffusers_xl_depth_zoe.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "t2i-adapter_diffusers_xl_depth_zoe.safetensors",
          "size_on_disk": 158060416,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:t2i-adapter_diffusers_xl_lineart.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "t2i-adapter_diffusers_xl_lineart.safetensors",
          "size_on_disk": 158060416,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:t2i-adapter_diffusers_xl_openpose.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "t2i-adapter_diffusers_xl_openpose.safetensors",
          "size_on_disk": 158060416,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:t2i-adapter_diffusers_xl_sketch.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "t2i-adapter_diffusers_xl_sketch.safetensors",
          "size_on_disk": 158060416,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:t2i-adapter_xl_canny.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "t2i-adapter_xl_canny.safetensors",
          "size_on_disk": 155110672,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:t2i-adapter_xl_openpose.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "t2i-adapter_xl_openpose.safetensors",
          "size_on_disk": 158059792,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:t2i-adapter_xl_sketch.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "t2i-adapter_xl_sketch.safetensors",
          "size_on_disk": 155110672,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:thibaud_xl_openpose.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "thibaud_xl_openpose.safetensors",
          "size_on_disk": 2502139104,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:thibaud_xl_openpose_256lora.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "thibaud_xl_openpose_256lora.safetensors",
          "size_on_disk": 774423040,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:sargezt_xl_depth_faid_vidit.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "sargezt_xl_depth_faid_vidit.safetensors",
          "size_on_disk": 2502139104,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:sargezt_xl_depth_zeed.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "sargezt_xl_depth_zeed.safetensors",
          "size_on_disk": 2502139104,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:sargezt_xl_depth.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "sargezt_xl_depth.safetensors",
          "size_on_disk": 2502139104,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:sargezt_xl_softedge.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "sargezt_xl_softedge.safetensors",
          "size_on_disk": 2502139104,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:ip-adapter_xl.pth",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "ip-adapter_xl.pth",
          "size_on_disk": 702585021,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:kohya_controllllite_xl_depth_anime.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "kohya_controllllite_xl_depth_anime.safetensors",
          "size_on_disk": 11321048,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:kohya_controllllite_xl_canny_anime.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "kohya_controllllite_xl_canny_anime.safetensors",
          "size_on_disk": 46172168,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:kohya_controllllite_xl_scribble_anime.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "kohya_controllllite_xl_scribble_anime.safetensors",
          "size_on_disk": 46172168,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:kohya_controllllite_xl_openpose_anime.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "kohya_controllllite_xl_openpose_anime.safetensors",
          "size_on_disk": 46172168,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:kohya_controllllite_xl_openpose_anime_v2.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "kohya_controllllite_xl_openpose_anime_v2.safetensors",
          "size_on_disk": 46172168,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:kohya_controllllite_xl_blur_anime_beta.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "kohya_controllllite_xl_blur_anime_beta.safetensors",
          "size_on_disk": 22512816,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:kohya_controllllite_xl_blur.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "kohya_controllllite_xl_blur.safetensors",
          "size_on_disk": 46172168,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:kohya_controllllite_xl_blur_anime.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "kohya_controllllite_xl_blur_anime.safetensors",
          "size_on_disk": 46172168,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:kohya_controllllite_xl_canny.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "kohya_controllllite_xl_canny.safetensors",
          "size_on_disk": 46172168,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:kohya_controllllite_xl_depth.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "kohya_controllllite_xl_depth.safetensors",
          "size_on_disk": 46172168,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_canny.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_canny.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_depth.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_depth.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_depth_V2.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_depth_V2.safetensors",
          "size_on_disk": 223905112,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_dw_openpose.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_dw_openpose.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_lineart_anime_denoise.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_lineart_anime_denoise.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_mlsd_V2.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_mlsd_V2.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_normal.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_normal.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_normal_dsine.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_normal_dsine.safetensors",
          "size_on_disk": 223905104,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_recolor_luminance.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_recolor_luminance.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_segment_animeface.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_segment_animeface.safetensors",
          "size_on_disk": 223906696,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_segment_animeface_V2.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_segment_animeface_V2.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_sketch.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_sketch.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_softedge.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_softedge.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_t2i-adapter_color_shuffle.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_t2i-adapter_color_shuffle.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_tile_anime_alpha.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_tile_anime_alpha.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_tile_anime_beta.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_tile_anime_beta.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_tile_realistic.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_tile_realistic.safetensors",
          "size_on_disk": 317085856,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        }
      ],
      "basic_fields": [
        "model",
        "prompt",
        "width",
        "height",
        "controlnet",
        "control_image",
        "controlnet_conditioning_scale"
      ]
    },
    {
      "title": "Stable Diffusion XL ControlNet (Img2Img)",
      "description": "Transforms existing images using Stable Diffusion XL with ControlNet guidance.\n    image, generation, image-to-image, controlnet, SDXL\n\n    Use cases:\n    - Modify existing images with precise control over composition and structure\n    - Apply specific styles or concepts to photographs or artwork with guided transformations\n    - Create variations of existing visual content while maintaining certain features\n    - Enhance image editing capabilities with AI-guided transformations",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.StableDiffusionXLControlNetImg2Img",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.stable_diffusion_xl"
          },
          "default": {
            "type": "hf.stable_diffusion_xl",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model",
          "description": "The Stable Diffusion XL model to use for generation."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt for image generation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to guide what should not appear in the generated image."
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Width",
          "description": "Width of the generated image.",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Height",
          "description": "Height of the generated image",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator.",
          "min": -1.0,
          "max": 1000000.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Inference Steps",
          "description": "Number of inference steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.0,
          "title": "Guidance Scale",
          "description": "Guidance scale for generation.",
          "min": 0.0,
          "max": 20.0
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "DPMSolverSDEScheduler",
              "EulerDiscreteScheduler",
              "LMSDiscreteScheduler",
              "DDIMScheduler",
              "DDPMScheduler",
              "HeunDiscreteScheduler",
              "DPMSolverMultistepScheduler",
              "DEISMultistepScheduler",
              "PNDMScheduler",
              "EulerAncestralDiscreteScheduler",
              "UniPCMultistepScheduler",
              "KDPM2DiscreteScheduler",
              "DPMSolverSinglestepScheduler",
              "KDPM2AncestralDiscreteScheduler"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionXLBase.StableDiffusionScheduler"
          },
          "default": "EulerDiscreteScheduler",
          "title": "Scheduler",
          "description": "The scheduler to use for the diffusion process."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "hf.lora_sdxl_config"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "The LoRA models to use for image processing"
        },
        {
          "name": "lora_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Lora Scale",
          "description": "Strength of the LoRAs",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "ip_adapter_model",
          "type": {
            "type": "hf.ip_adapter"
          },
          "default": {
            "type": "hf.ip_adapter",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Ip Adapter Model",
          "description": "The IP adapter model to use for image processing"
        },
        {
          "name": "ip_adapter_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Ip Adapter Image",
          "description": "When provided the image will be fed into the IP adapter"
        },
        {
          "name": "ip_adapter_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Ip Adapter Scale",
          "description": "Strength of the IP adapter image",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "enable_attention_slicing",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Attention Slicing",
          "description": "Enable attention slicing for the pipeline. This can reduce VRAM usage but may slow down generation."
        },
        {
          "name": "enable_tiling",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Tiling",
          "description": "Legacy VAE tiling flag (disabled in favor of PyTorch 2 attention optimizations)."
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage."
        },
        {
          "name": "output_type",
          "type": {
            "type": "enum",
            "values": [
              "Image",
              "Latent"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionXLBase.StableDiffusionOutputType"
          },
          "default": "Image",
          "title": "Output Type",
          "description": "The type of output to generate."
        },
        {
          "name": "init_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Init Image",
          "description": "The initial image for Image-to-Image generation."
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 0.8,
          "title": "Strength",
          "description": "Strength for Image-to-Image generation. Higher values allow for more deviation from the original image.",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "controlnet",
          "type": {
            "type": "hf.controlnet"
          },
          "default": {
            "type": "hf.controlnet",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Controlnet",
          "description": "The ControlNet model to use for guidance."
        },
        {
          "name": "control_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Control Image",
          "description": "The control image to guide the transformation."
        },
        {
          "name": "controlnet_conditioning_scale",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Controlnet Conditioning Scale",
          "description": "The scale for ControlNet conditioning.",
          "min": 0.0,
          "max": 2.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "torch_tensor"
          },
          "name": "latent"
        }
      ],
      "recommended_models": [
        {
          "id": "diffusers/controlnet-canny-sdxl-1.0:diffusion_pytorch_model.fp16.safetensors",
          "type": "hf.controlnet",
          "name": "diffusers/controlnet-canny-sdxl-1.0",
          "repo_id": "diffusers/controlnet-canny-sdxl-1.0",
          "path": "diffusion_pytorch_model.fp16.safetensors",
          "size_on_disk": 2502139136,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "stable-diffusion-xl",
            "stable-diffusion-xl-diffusers",
            "text-to-image",
            "base_model:runwayml/stable-diffusion-v1-5",
            "base_model:finetune:runwayml/stable-diffusion-v1-5",
            "license:openrail++",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 9966,
          "likes": 518
        },
        {
          "id": "diffusers/controlnet-depth-sdxl-1.0:diffusion_pytorch_model.fp16.safetensors",
          "type": "hf.controlnet",
          "name": "diffusers/controlnet-depth-sdxl-1.0",
          "repo_id": "diffusers/controlnet-depth-sdxl-1.0",
          "path": "diffusion_pytorch_model.fp16.safetensors",
          "size_on_disk": 2502139134,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "stable-diffusion-xl",
            "stable-diffusion-xl-diffusers",
            "text-to-image",
            "controlnet",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:adapter:stabilityai/stable-diffusion-xl-base-1.0",
            "license:openrail++",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 16846,
          "likes": 190
        },
        {
          "id": "diffusers/controlnet-zoe-depth-sdxl-1.0:diffusion_pytorch_model.fp16.safetensors",
          "type": "hf.controlnet",
          "name": "diffusers/controlnet-zoe-depth-sdxl-1.0",
          "repo_id": "diffusers/controlnet-zoe-depth-sdxl-1.0",
          "path": "diffusion_pytorch_model.fp16.safetensors",
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "stable-diffusion-xl",
            "stable-diffusion-xl-diffusers",
            "text-to-image",
            "controlnet",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:adapter:stabilityai/stable-diffusion-xl-base-1.0",
            "license:openrail++",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 833,
          "likes": 39
        },
        {
          "id": "lllyasviel/sd_control_collection:diffusers_xl_canny_full.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "diffusers_xl_canny_full.safetensors",
          "size_on_disk": 2502139104,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:diffusers_xl_canny_mid.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "diffusers_xl_canny_mid.safetensors",
          "size_on_disk": 545197704,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:diffusers_xl_canny_small.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "diffusers_xl_canny_small.safetensors",
          "size_on_disk": 320237152,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:diffusers_xl_depth_full.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "diffusers_xl_depth_full.safetensors",
          "size_on_disk": 2502139104,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:diffusers_xl_depth_mid.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "diffusers_xl_depth_mid.safetensors",
          "size_on_disk": 545197704,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:diffusers_xl_depth_small.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "diffusers_xl_depth_small.safetensors",
          "size_on_disk": 320237152,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:t2i-adapter_diffusers_xl_canny.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "t2i-adapter_diffusers_xl_canny.safetensors",
          "size_on_disk": 158060416,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:t2i-adapter_diffusers_xl_depth_midas.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "t2i-adapter_diffusers_xl_depth_midas.safetensors",
          "size_on_disk": 158060416,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:t2i-adapter_diffusers_xl_depth_zoe.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "t2i-adapter_diffusers_xl_depth_zoe.safetensors",
          "size_on_disk": 158060416,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:t2i-adapter_diffusers_xl_lineart.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "t2i-adapter_diffusers_xl_lineart.safetensors",
          "size_on_disk": 158060416,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:t2i-adapter_diffusers_xl_openpose.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "t2i-adapter_diffusers_xl_openpose.safetensors",
          "size_on_disk": 158060416,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:t2i-adapter_diffusers_xl_sketch.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "t2i-adapter_diffusers_xl_sketch.safetensors",
          "size_on_disk": 158060416,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:t2i-adapter_xl_canny.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "t2i-adapter_xl_canny.safetensors",
          "size_on_disk": 155110672,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:t2i-adapter_xl_openpose.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "t2i-adapter_xl_openpose.safetensors",
          "size_on_disk": 158059792,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:t2i-adapter_xl_sketch.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "t2i-adapter_xl_sketch.safetensors",
          "size_on_disk": 155110672,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:thibaud_xl_openpose.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "thibaud_xl_openpose.safetensors",
          "size_on_disk": 2502139104,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:thibaud_xl_openpose_256lora.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "thibaud_xl_openpose_256lora.safetensors",
          "size_on_disk": 774423040,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:sargezt_xl_depth_faid_vidit.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "sargezt_xl_depth_faid_vidit.safetensors",
          "size_on_disk": 2502139104,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:sargezt_xl_depth_zeed.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "sargezt_xl_depth_zeed.safetensors",
          "size_on_disk": 2502139104,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:sargezt_xl_depth.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "sargezt_xl_depth.safetensors",
          "size_on_disk": 2502139104,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:sargezt_xl_softedge.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "sargezt_xl_softedge.safetensors",
          "size_on_disk": 2502139104,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:ip-adapter_xl.pth",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "ip-adapter_xl.pth",
          "size_on_disk": 702585021,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:kohya_controllllite_xl_depth_anime.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "kohya_controllllite_xl_depth_anime.safetensors",
          "size_on_disk": 11321048,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:kohya_controllllite_xl_canny_anime.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "kohya_controllllite_xl_canny_anime.safetensors",
          "size_on_disk": 46172168,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:kohya_controllllite_xl_scribble_anime.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "kohya_controllllite_xl_scribble_anime.safetensors",
          "size_on_disk": 46172168,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:kohya_controllllite_xl_openpose_anime.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "kohya_controllllite_xl_openpose_anime.safetensors",
          "size_on_disk": 46172168,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:kohya_controllllite_xl_openpose_anime_v2.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "kohya_controllllite_xl_openpose_anime_v2.safetensors",
          "size_on_disk": 46172168,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:kohya_controllllite_xl_blur_anime_beta.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "kohya_controllllite_xl_blur_anime_beta.safetensors",
          "size_on_disk": 22512816,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:kohya_controllllite_xl_blur.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "kohya_controllllite_xl_blur.safetensors",
          "size_on_disk": 46172168,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:kohya_controllllite_xl_blur_anime.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "kohya_controllllite_xl_blur_anime.safetensors",
          "size_on_disk": 46172168,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:kohya_controllllite_xl_canny.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "kohya_controllllite_xl_canny.safetensors",
          "size_on_disk": 46172168,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "lllyasviel/sd_control_collection:kohya_controllllite_xl_depth.safetensors",
          "type": "hf.controlnet",
          "name": "lllyasviel/sd_control_collection",
          "repo_id": "lllyasviel/sd_control_collection",
          "path": "kohya_controllllite_xl_depth.safetensors",
          "size_on_disk": 46172168,
          "tags": [
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 2069
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_canny.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_canny.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_depth.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_depth.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_depth_V2.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_depth_V2.safetensors",
          "size_on_disk": 223905112,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_dw_openpose.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_dw_openpose.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_lineart_anime_denoise.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_lineart_anime_denoise.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_mlsd_V2.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_mlsd_V2.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_normal.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_normal.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_normal_dsine.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_normal_dsine.safetensors",
          "size_on_disk": 223905104,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_recolor_luminance.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_recolor_luminance.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_segment_animeface.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_segment_animeface.safetensors",
          "size_on_disk": 223906696,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_segment_animeface_V2.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_segment_animeface_V2.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_sketch.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_sketch.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_softedge.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_softedge.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_t2i-adapter_color_shuffle.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_t2i-adapter_color_shuffle.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_tile_anime_alpha.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_tile_anime_alpha.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_tile_anime_beta.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_tile_anime_beta.safetensors",
          "size_on_disk": 223906688,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        },
        {
          "id": "bdsqlsz/qinglong_controlnet-lllite:bdsqlsz_controlllite_xl_tile_realistic.safetensors",
          "type": "hf.controlnet",
          "name": "bdsqlsz/qinglong_controlnet-lllite",
          "repo_id": "bdsqlsz/qinglong_controlnet-lllite",
          "path": "bdsqlsz_controlllite_xl_tile_realistic.safetensors",
          "size_on_disk": 317085856,
          "tags": [
            "diffusers",
            "onnx",
            "license:cc-by-nc-sa-4.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 12179,
          "likes": 336
        }
      ],
      "basic_fields": [
        "model",
        "prompt",
        "width",
        "height",
        "init_image",
        "strength",
        "controlnet",
        "control_image",
        "controlnet_conditioning_scale"
      ]
    },
    {
      "title": "Stable Diffusion XL (Img2Img)",
      "description": "Transforms existing images based on text prompts using Stable Diffusion XL.\n    image, generation, image-to-image, SDXL, style-transfer\n\n    Use cases:\n    - Modifying existing images to fit a specific style or theme\n    - Enhancing or altering photographs\n    - Creating variations of existing artwork\n    - Applying text-guided edits to images",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.StableDiffusionXLImg2Img",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.stable_diffusion_xl"
          },
          "default": {
            "type": "hf.stable_diffusion_xl",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model",
          "description": "The Stable Diffusion XL model to use for generation."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt for image generation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to guide what should not appear in the generated image."
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Width",
          "description": "Width of the generated image.",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Height",
          "description": "Height of the generated image",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator.",
          "min": -1.0,
          "max": 1000000.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Inference Steps",
          "description": "Number of inference steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.0,
          "title": "Guidance Scale",
          "description": "Guidance scale for generation.",
          "min": 0.0,
          "max": 20.0
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "DPMSolverSDEScheduler",
              "EulerDiscreteScheduler",
              "LMSDiscreteScheduler",
              "DDIMScheduler",
              "DDPMScheduler",
              "HeunDiscreteScheduler",
              "DPMSolverMultistepScheduler",
              "DEISMultistepScheduler",
              "PNDMScheduler",
              "EulerAncestralDiscreteScheduler",
              "UniPCMultistepScheduler",
              "KDPM2DiscreteScheduler",
              "DPMSolverSinglestepScheduler",
              "KDPM2AncestralDiscreteScheduler"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionXLBase.StableDiffusionScheduler"
          },
          "default": "EulerDiscreteScheduler",
          "title": "Scheduler",
          "description": "The scheduler to use for the diffusion process."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "hf.lora_sdxl_config"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "The LoRA models to use for image processing"
        },
        {
          "name": "lora_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Lora Scale",
          "description": "Strength of the LoRAs",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "ip_adapter_model",
          "type": {
            "type": "hf.ip_adapter"
          },
          "default": {
            "type": "hf.ip_adapter",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Ip Adapter Model",
          "description": "The IP adapter model to use for image processing"
        },
        {
          "name": "ip_adapter_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Ip Adapter Image",
          "description": "When provided the image will be fed into the IP adapter"
        },
        {
          "name": "ip_adapter_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Ip Adapter Scale",
          "description": "Strength of the IP adapter image",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "enable_attention_slicing",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Attention Slicing",
          "description": "Enable attention slicing for the pipeline. This can reduce VRAM usage."
        },
        {
          "name": "enable_tiling",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Tiling",
          "description": "Legacy VAE tiling flag (disabled in favor of PyTorch 2 attention optimizations)."
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage."
        },
        {
          "name": "output_type",
          "type": {
            "type": "enum",
            "values": [
              "Image",
              "Latent"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionXLBase.StableDiffusionOutputType"
          },
          "default": "Image",
          "title": "Output Type",
          "description": "The type of output to generate."
        },
        {
          "name": "init_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Init Image",
          "description": "The initial image for Image-to-Image generation."
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 0.8,
          "title": "Strength",
          "description": "Strength for Image-to-Image generation. Higher values allow for more deviation from the original image.",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "torch_tensor"
          },
          "name": "latent"
        }
      ],
      "recommended_models": [
        {
          "id": "h94/IP-Adapter:sdxl_models/ip-adapter_sdxl.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "sdxl_models/ip-adapter_sdxl.bin",
          "size_on_disk": 702585097,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "h94/IP-Adapter:sdxl_models/ip-adapter_sdxl_vit-h.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "sdxl_models/ip-adapter_sdxl_vit-h.bin",
          "size_on_disk": 698390793,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "h94/IP-Adapter:sdxl_models/ip-adapter-plus_sdxl_vit-h.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "sdxl_models/ip-adapter-plus_sdxl_vit-h.bin",
          "size_on_disk": 1013454427,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "stabilityai/stable-diffusion-xl-base-1.0:sd_xl_base_1.0.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "stabilityai/stable-diffusion-xl-base-1.0",
          "repo_id": "stabilityai/stable-diffusion-xl-base-1.0",
          "path": "sd_xl_base_1.0.safetensors",
          "size_on_disk": 6938078334,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "onnx",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "arxiv:2307.01952",
            "arxiv:2211.01324",
            "arxiv:2108.01073",
            "arxiv:2112.10752",
            "license:openrail++",
            "autotrain_compatible",
            "endpoints_compatible",
            "diffusers:StableDiffusionXLPipeline",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 2760051,
          "likes": 7146
        },
        {
          "id": "Lykon/dreamshaper-xl-v2-turbo:DreamShaperXL_Turbo_v2_1.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "Lykon/dreamshaper-xl-v2-turbo",
          "repo_id": "Lykon/dreamshaper-xl-v2-turbo",
          "path": "DreamShaperXL_Turbo_v2_1.safetensors",
          "size_on_disk": 6939220250,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "stable-diffusion",
            "stable-diffusion-diffusers",
            "stable-diffusion-xl",
            "stable-diffusion-xl-turbo",
            "text-to-image",
            "art",
            "artistic",
            "anime",
            "dreamshaper",
            "turbo",
            "lcm",
            "en",
            "license:openrail++",
            "autotrain_compatible",
            "endpoints_compatible",
            "diffusers:StableDiffusionXLPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 56786,
          "likes": 69
        },
        {
          "id": "RunDiffusion/Juggernaut-XL-v9:Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "RunDiffusion/Juggernaut-XL-v9",
          "repo_id": "RunDiffusion/Juggernaut-XL-v9",
          "path": "Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors",
          "size_on_disk": 7105348188,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "art",
            "people",
            "diffusion",
            "Cinematic",
            "Photography",
            "Landscape",
            "Interior",
            "Food",
            "Car",
            "Wildlife",
            "Architecture",
            "text-to-image",
            "en",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:finetune:stabilityai/stable-diffusion-xl-base-1.0",
            "license:creativeml-openrail-m",
            "autotrain_compatible",
            "endpoints_compatible",
            "diffusers:StableDiffusionXLPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 304515,
          "likes": 272
        },
        {
          "id": "dataautogpt3/ProteusV0.3:ProteusV0.3.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "dataautogpt3/ProteusV0.3",
          "repo_id": "dataautogpt3/ProteusV0.3",
          "path": "ProteusV0.3.safetensors",
          "size_on_disk": 6938040736,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "license:gpl-3.0",
            "autotrain_compatible",
            "endpoints_compatible",
            "diffusers:StableDiffusionXLPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 286459,
          "likes": 94
        },
        {
          "id": "John6666/prefect-illustrious-xl-v3-sdxl",
          "type": "hf.stable_diffusion_xl",
          "name": "John6666/prefect-illustrious-xl-v3-sdxl",
          "repo_id": "John6666/prefect-illustrious-xl-v3-sdxl",
          "size_on_disk": 6941387072,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "stable-diffusion-xl",
            "anime",
            "girls",
            "styles",
            "lighting",
            "texture",
            "clean",
            "color balance",
            "prompt understanding",
            "merge",
            "noobai",
            "Illustrious XL v1.0",
            "illustrious",
            "en",
            "base_model:Laxhar/noobai-XL-1.1",
            "base_model:merge:Laxhar/noobai-XL-1.1",
            "base_model:OnomaAIResearch/Illustrious-XL-v1.0",
            "base_model:merge:OnomaAIResearch/Illustrious-XL-v1.0",
            "license:other",
            "autotrain_compatible",
            "endpoints_compatible",
            "diffusers:StableDiffusionXLPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 314267,
          "likes": 0
        },
        {
          "id": "cagliostrolab/animagine-xl-4.0:animagine-xl-4.0-opt.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "cagliostrolab/animagine-xl-4.0",
          "repo_id": "cagliostrolab/animagine-xl-4.0",
          "path": "animagine-xl-4.0-opt.safetensors",
          "size_on_disk": 6938350040,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "stable-diffusion-xl",
            "en",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:finetune:stabilityai/stable-diffusion-xl-base-1.0",
            "license:openrail++",
            "autotrain_compatible",
            "endpoints_compatible",
            "diffusers:StableDiffusionXLPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 216454,
          "likes": 354
        },
        {
          "id": "SG161222/RealVisXL_V5.0:RealVisXL_V5.0_fp16.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "SG161222/RealVisXL_V5.0",
          "repo_id": "SG161222/RealVisXL_V5.0",
          "path": "RealVisXL_V5.0_fp16.safetensors",
          "size_on_disk": 6938065488,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "license:openrail++",
            "autotrain_compatible",
            "endpoints_compatible",
            "diffusers:StableDiffusionXLPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 49926,
          "likes": 115
        },
        {
          "id": "nunchaku-tech/nunchaku-sdxl:svdq-int4_r32-sdxl.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "nunchaku-tech/nunchaku-sdxl",
          "repo_id": "nunchaku-tech/nunchaku-sdxl",
          "path": "svdq-int4_r32-sdxl.safetensors",
          "size_on_disk": 2559021560,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "SVDQuant",
            "SDXL",
            "Diffusion",
            "Quantization",
            "stable-diffusion",
            "en",
            "dataset:mit-han-lab/svdquant-datasets",
            "arxiv:2411.05007",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:quantized:stabilityai/stable-diffusion-xl-base-1.0",
            "license:openrail++",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 952,
          "likes": 24
        },
        {
          "id": "nunchaku-tech/nunchaku-sdxl:svdq-fp4_r32-sdxl.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "nunchaku-tech/nunchaku-sdxl",
          "repo_id": "nunchaku-tech/nunchaku-sdxl",
          "path": "svdq-fp4_r32-sdxl.safetensors",
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "SVDQuant",
            "SDXL",
            "Diffusion",
            "Quantization",
            "stable-diffusion",
            "en",
            "dataset:mit-han-lab/svdquant-datasets",
            "arxiv:2411.05007",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:quantized:stabilityai/stable-diffusion-xl-base-1.0",
            "license:openrail++",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 952,
          "likes": 24
        }
      ],
      "basic_fields": [
        "model",
        "prompt",
        "width",
        "height",
        "init_image",
        "strength"
      ]
    },
    {
      "title": "Stable Diffusion XL (Inpaint)",
      "description": "Performs inpainting on images using Stable Diffusion XL.\n    image, inpainting, SDXL\n\n    Use cases:\n    - Remove unwanted objects from images\n    - Fill in missing parts of images\n    - Modify specific areas of images while preserving the rest",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.StableDiffusionXLInpainting",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.stable_diffusion_xl"
          },
          "default": {
            "type": "hf.stable_diffusion_xl",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model",
          "description": "The Stable Diffusion XL model to use for generation."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt for image generation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to guide what should not appear in the generated image."
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Width",
          "description": "Width of the generated image.",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Height",
          "description": "Height of the generated image",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator.",
          "min": -1.0,
          "max": 1000000.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Inference Steps",
          "description": "Number of inference steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.0,
          "title": "Guidance Scale",
          "description": "Guidance scale for generation.",
          "min": 0.0,
          "max": 20.0
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "DPMSolverSDEScheduler",
              "EulerDiscreteScheduler",
              "LMSDiscreteScheduler",
              "DDIMScheduler",
              "DDPMScheduler",
              "HeunDiscreteScheduler",
              "DPMSolverMultistepScheduler",
              "DEISMultistepScheduler",
              "PNDMScheduler",
              "EulerAncestralDiscreteScheduler",
              "UniPCMultistepScheduler",
              "KDPM2DiscreteScheduler",
              "DPMSolverSinglestepScheduler",
              "KDPM2AncestralDiscreteScheduler"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionXLBase.StableDiffusionScheduler"
          },
          "default": "EulerDiscreteScheduler",
          "title": "Scheduler",
          "description": "The scheduler to use for the diffusion process."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "hf.lora_sdxl_config"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "The LoRA models to use for image processing"
        },
        {
          "name": "lora_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Lora Scale",
          "description": "Strength of the LoRAs",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "ip_adapter_model",
          "type": {
            "type": "hf.ip_adapter"
          },
          "default": {
            "type": "hf.ip_adapter",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Ip Adapter Model",
          "description": "The IP adapter model to use for image processing"
        },
        {
          "name": "ip_adapter_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Ip Adapter Image",
          "description": "When provided the image will be fed into the IP adapter"
        },
        {
          "name": "ip_adapter_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Ip Adapter Scale",
          "description": "Strength of the IP adapter image",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "enable_attention_slicing",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Attention Slicing",
          "description": "Enable attention slicing for the pipeline. This can reduce VRAM usage."
        },
        {
          "name": "enable_tiling",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Tiling",
          "description": "Legacy VAE tiling flag (disabled in favor of PyTorch 2 attention optimizations)."
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage."
        },
        {
          "name": "output_type",
          "type": {
            "type": "enum",
            "values": [
              "Image",
              "Latent"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionXLBase.StableDiffusionOutputType"
          },
          "default": "Image",
          "title": "Output Type",
          "description": "The type of output to generate."
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The initial image to be inpainted."
        },
        {
          "name": "mask_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Mask Image",
          "description": "The mask image indicating areas to be inpainted."
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 0.8,
          "title": "Strength",
          "description": "Strength for inpainting. Higher values allow for more deviation from the original image.",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "torch_tensor"
          },
          "name": "latent"
        }
      ],
      "recommended_models": [
        {
          "id": "h94/IP-Adapter:sdxl_models/ip-adapter_sdxl.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "sdxl_models/ip-adapter_sdxl.bin",
          "size_on_disk": 702585097,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "h94/IP-Adapter:sdxl_models/ip-adapter_sdxl_vit-h.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "sdxl_models/ip-adapter_sdxl_vit-h.bin",
          "size_on_disk": 698390793,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "h94/IP-Adapter:sdxl_models/ip-adapter-plus_sdxl_vit-h.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "sdxl_models/ip-adapter-plus_sdxl_vit-h.bin",
          "size_on_disk": 1013454427,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "stabilityai/stable-diffusion-xl-base-1.0:sd_xl_base_1.0.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "stabilityai/stable-diffusion-xl-base-1.0",
          "repo_id": "stabilityai/stable-diffusion-xl-base-1.0",
          "path": "sd_xl_base_1.0.safetensors",
          "size_on_disk": 6938078334,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "onnx",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "arxiv:2307.01952",
            "arxiv:2211.01324",
            "arxiv:2108.01073",
            "arxiv:2112.10752",
            "license:openrail++",
            "autotrain_compatible",
            "endpoints_compatible",
            "diffusers:StableDiffusionXLPipeline",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 2760051,
          "likes": 7146
        },
        {
          "id": "Lykon/dreamshaper-xl-v2-turbo:DreamShaperXL_Turbo_v2_1.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "Lykon/dreamshaper-xl-v2-turbo",
          "repo_id": "Lykon/dreamshaper-xl-v2-turbo",
          "path": "DreamShaperXL_Turbo_v2_1.safetensors",
          "size_on_disk": 6939220250,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "stable-diffusion",
            "stable-diffusion-diffusers",
            "stable-diffusion-xl",
            "stable-diffusion-xl-turbo",
            "text-to-image",
            "art",
            "artistic",
            "anime",
            "dreamshaper",
            "turbo",
            "lcm",
            "en",
            "license:openrail++",
            "autotrain_compatible",
            "endpoints_compatible",
            "diffusers:StableDiffusionXLPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 56786,
          "likes": 69
        },
        {
          "id": "RunDiffusion/Juggernaut-XL-v9:Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "RunDiffusion/Juggernaut-XL-v9",
          "repo_id": "RunDiffusion/Juggernaut-XL-v9",
          "path": "Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors",
          "size_on_disk": 7105348188,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "art",
            "people",
            "diffusion",
            "Cinematic",
            "Photography",
            "Landscape",
            "Interior",
            "Food",
            "Car",
            "Wildlife",
            "Architecture",
            "text-to-image",
            "en",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:finetune:stabilityai/stable-diffusion-xl-base-1.0",
            "license:creativeml-openrail-m",
            "autotrain_compatible",
            "endpoints_compatible",
            "diffusers:StableDiffusionXLPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 304515,
          "likes": 272
        },
        {
          "id": "dataautogpt3/ProteusV0.3:ProteusV0.3.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "dataautogpt3/ProteusV0.3",
          "repo_id": "dataautogpt3/ProteusV0.3",
          "path": "ProteusV0.3.safetensors",
          "size_on_disk": 6938040736,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "license:gpl-3.0",
            "autotrain_compatible",
            "endpoints_compatible",
            "diffusers:StableDiffusionXLPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 286459,
          "likes": 94
        },
        {
          "id": "John6666/prefect-illustrious-xl-v3-sdxl",
          "type": "hf.stable_diffusion_xl",
          "name": "John6666/prefect-illustrious-xl-v3-sdxl",
          "repo_id": "John6666/prefect-illustrious-xl-v3-sdxl",
          "size_on_disk": 6941387072,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "stable-diffusion-xl",
            "anime",
            "girls",
            "styles",
            "lighting",
            "texture",
            "clean",
            "color balance",
            "prompt understanding",
            "merge",
            "noobai",
            "Illustrious XL v1.0",
            "illustrious",
            "en",
            "base_model:Laxhar/noobai-XL-1.1",
            "base_model:merge:Laxhar/noobai-XL-1.1",
            "base_model:OnomaAIResearch/Illustrious-XL-v1.0",
            "base_model:merge:OnomaAIResearch/Illustrious-XL-v1.0",
            "license:other",
            "autotrain_compatible",
            "endpoints_compatible",
            "diffusers:StableDiffusionXLPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 314267,
          "likes": 0
        },
        {
          "id": "cagliostrolab/animagine-xl-4.0:animagine-xl-4.0-opt.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "cagliostrolab/animagine-xl-4.0",
          "repo_id": "cagliostrolab/animagine-xl-4.0",
          "path": "animagine-xl-4.0-opt.safetensors",
          "size_on_disk": 6938350040,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "stable-diffusion-xl",
            "en",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:finetune:stabilityai/stable-diffusion-xl-base-1.0",
            "license:openrail++",
            "autotrain_compatible",
            "endpoints_compatible",
            "diffusers:StableDiffusionXLPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 216454,
          "likes": 354
        },
        {
          "id": "SG161222/RealVisXL_V5.0:RealVisXL_V5.0_fp16.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "SG161222/RealVisXL_V5.0",
          "repo_id": "SG161222/RealVisXL_V5.0",
          "path": "RealVisXL_V5.0_fp16.safetensors",
          "size_on_disk": 6938065488,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "license:openrail++",
            "autotrain_compatible",
            "endpoints_compatible",
            "diffusers:StableDiffusionXLPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 49926,
          "likes": 115
        },
        {
          "id": "nunchaku-tech/nunchaku-sdxl:svdq-int4_r32-sdxl.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "nunchaku-tech/nunchaku-sdxl",
          "repo_id": "nunchaku-tech/nunchaku-sdxl",
          "path": "svdq-int4_r32-sdxl.safetensors",
          "size_on_disk": 2559021560,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "SVDQuant",
            "SDXL",
            "Diffusion",
            "Quantization",
            "stable-diffusion",
            "en",
            "dataset:mit-han-lab/svdquant-datasets",
            "arxiv:2411.05007",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:quantized:stabilityai/stable-diffusion-xl-base-1.0",
            "license:openrail++",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 952,
          "likes": 24
        },
        {
          "id": "nunchaku-tech/nunchaku-sdxl:svdq-fp4_r32-sdxl.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "nunchaku-tech/nunchaku-sdxl",
          "repo_id": "nunchaku-tech/nunchaku-sdxl",
          "path": "svdq-fp4_r32-sdxl.safetensors",
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "SVDQuant",
            "SDXL",
            "Diffusion",
            "Quantization",
            "stable-diffusion",
            "en",
            "dataset:mit-han-lab/svdquant-datasets",
            "arxiv:2411.05007",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:quantized:stabilityai/stable-diffusion-xl-base-1.0",
            "license:openrail++",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 952,
          "likes": 24
        }
      ],
      "basic_fields": [
        "model",
        "prompt",
        "width",
        "height",
        "image",
        "mask_image",
        "strength"
      ]
    },
    {
      "title": "Swin2SR",
      "description": "Performs image super-resolution using the Swin2SR model.\n    image, super-resolution, enhancement, huggingface\n\n    Use cases:\n    - Enhance low-resolution images\n    - Improve image quality for printing or display\n    - Upscale images for better detail",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.Swin2SR",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Input Image",
          "description": "The input image to transform"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt to guide the image transformation (if applicable)"
        },
        {
          "name": "model",
          "type": {
            "type": "hf.image_to_image"
          },
          "default": {
            "type": "hf.image_to_image",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for image super-resolution"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "caidas/swin2SR-classical-sr-x2-64",
          "type": "hf.image_to_image",
          "name": "caidas/swin2SR-classical-sr-x2-64",
          "repo_id": "caidas/swin2SR-classical-sr-x2-64",
          "allow_patterns": [
            "README.md",
            "*.safetensors",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 48462226,
          "pipeline_tag": "image-to-image",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "swin2sr",
            "image-to-image",
            "vision",
            "arxiv:2209.11345",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 20634,
          "likes": 37
        },
        {
          "id": "caidas/swin2SR-classical-sr-x4-64",
          "type": "hf.image_to_image",
          "name": "caidas/swin2SR-classical-sr-x4-64",
          "repo_id": "caidas/swin2SR-classical-sr-x4-64",
          "allow_patterns": [
            "README.md",
            "*.safetensors",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 49053290,
          "pipeline_tag": "image-to-image",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "swin2sr",
            "image-to-image",
            "vision",
            "arxiv:2209.11345",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 4040,
          "likes": 3
        },
        {
          "id": "caidas/swin2SR-lightweight-x2-64",
          "type": "hf.image_to_image",
          "name": "caidas/swin2SR-lightweight-x2-64",
          "repo_id": "caidas/swin2SR-lightweight-x2-64",
          "allow_patterns": [
            "README.md",
            "*.safetensors",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 4084507,
          "pipeline_tag": "image-to-image",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "swin2sr",
            "image-to-image",
            "vision",
            "arxiv:2209.11345",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 890,
          "likes": 13
        },
        {
          "id": "caidas/swin2SR-compressed-sr-x4-48",
          "type": "hf.image_to_image",
          "name": "caidas/swin2SR-compressed-sr-x4-48",
          "repo_id": "caidas/swin2SR-compressed-sr-x4-48",
          "allow_patterns": [
            "README.md",
            "*.safetensors",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 49075149,
          "pipeline_tag": "image-to-image",
          "tags": [
            "transformers",
            "pytorch",
            "safetensors",
            "swin2sr",
            "image-to-image",
            "vision",
            "arxiv:2209.11345",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 744,
          "likes": 3
        },
        {
          "id": "caidas/swin2SR-realworld-sr-x4-64-bsrgan-psnr",
          "type": "hf.image_to_image",
          "name": "caidas/swin2SR-realworld-sr-x4-64-bsrgan-psnr",
          "repo_id": "caidas/swin2SR-realworld-sr-x4-64-bsrgan-psnr",
          "allow_patterns": [
            "README.md",
            "*.bin",
            "*.json",
            "**/*.json"
          ],
          "size_on_disk": 48461718,
          "pipeline_tag": "image-to-image",
          "tags": [
            "transformers",
            "pytorch",
            "swin2sr",
            "image-to-image",
            "vision",
            "arxiv:2209.11345",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 6737,
          "likes": 16
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "model"
      ]
    },
    {
      "title": "VAE Decode",
      "description": "Decodes latents into an image using a VAE.\n    tensor (TorchTensor) -> image",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.VAEDecode",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.vae"
          },
          "default": {
            "type": "hf.vae",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model",
          "description": "The VAE model to use."
        },
        {
          "name": "latents",
          "type": {
            "type": "torch_tensor"
          },
          "default": {
            "type": "torch_tensor",
            "value": null,
            "dtype": "<i8",
            "shape": [
              1
            ]
          },
          "title": "Latents",
          "description": "Latent tensor to decode."
        },
        {
          "name": "scale_factor",
          "type": {
            "type": "float"
          },
          "default": 0.18215,
          "title": "Scale Factor",
          "description": "Scaling factor used for encoding (inverse is applied before decode)",
          "min": 0.0,
          "max": 10.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "stabilityai/sd-vae-ft-mse",
          "type": "hf.vae",
          "name": "stabilityai/sd-vae-ft-mse",
          "repo_id": "stabilityai/sd-vae-ft-mse",
          "size_on_disk": 669359340,
          "tags": [
            "diffusers",
            "safetensors",
            "stable-diffusion",
            "stable-diffusion-diffusers",
            "license:mit",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 182346,
          "likes": 395
        },
        {
          "id": "stabilityai/sd-vae-ft-ema",
          "type": "hf.vae",
          "name": "stabilityai/sd-vae-ft-ema",
          "repo_id": "stabilityai/sd-vae-ft-ema",
          "size_on_disk": 669359341,
          "tags": [
            "diffusers",
            "safetensors",
            "stable-diffusion",
            "stable-diffusion-diffusers",
            "license:mit",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 24446,
          "likes": 131
        },
        {
          "id": "stabilityai/sdxl-vae",
          "type": "hf.vae",
          "name": "stabilityai/sdxl-vae",
          "repo_id": "stabilityai/sdxl-vae",
          "size_on_disk": 1004001843,
          "tags": [
            "diffusers",
            "safetensors",
            "stable-diffusion",
            "stable-diffusion-diffusers",
            "arxiv:2112.10752",
            "license:mit",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 375044,
          "likes": 714
        },
        {
          "id": "madebyollin/sdxl-vae-fp16-fix",
          "type": "hf.vae",
          "name": "madebyollin/sdxl-vae-fp16-fix",
          "repo_id": "madebyollin/sdxl-vae-fp16-fix",
          "size_on_disk": 1343646154,
          "tags": [
            "diffusers",
            "safetensors",
            "stable-diffusion",
            "stable-diffusion-diffusers",
            "license:mit",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 297322,
          "likes": 593
        }
      ],
      "basic_fields": [
        "model",
        "latents",
        "scale_factor"
      ]
    },
    {
      "title": "VAE Encode",
      "description": "Encodes an image into latents using a VAE.\n    image -> tensor (TorchTensor)",
      "namespace": "huggingface.image_to_image",
      "node_type": "huggingface.image_to_image.VAEEncode",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.vae"
          },
          "default": {
            "type": "hf.vae",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model",
          "description": "The VAE model to use."
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "Input image to encode."
        },
        {
          "name": "scale_factor",
          "type": {
            "type": "float"
          },
          "default": 0.18215,
          "title": "Scale Factor",
          "description": "Scaling factor applied to latents (e.g., 0.18215 for SD15)",
          "min": 0.0,
          "max": 10.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "torch_tensor"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "stabilityai/sd-vae-ft-mse",
          "type": "hf.vae",
          "name": "stabilityai/sd-vae-ft-mse",
          "repo_id": "stabilityai/sd-vae-ft-mse",
          "size_on_disk": 669359340,
          "tags": [
            "diffusers",
            "safetensors",
            "stable-diffusion",
            "stable-diffusion-diffusers",
            "license:mit",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 182346,
          "likes": 395
        },
        {
          "id": "stabilityai/sd-vae-ft-ema",
          "type": "hf.vae",
          "name": "stabilityai/sd-vae-ft-ema",
          "repo_id": "stabilityai/sd-vae-ft-ema",
          "size_on_disk": 669359341,
          "tags": [
            "diffusers",
            "safetensors",
            "stable-diffusion",
            "stable-diffusion-diffusers",
            "license:mit",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 24446,
          "likes": 131
        },
        {
          "id": "stabilityai/sdxl-vae",
          "type": "hf.vae",
          "name": "stabilityai/sdxl-vae",
          "repo_id": "stabilityai/sdxl-vae",
          "size_on_disk": 1004001843,
          "tags": [
            "diffusers",
            "safetensors",
            "stable-diffusion",
            "stable-diffusion-diffusers",
            "arxiv:2112.10752",
            "license:mit",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 375044,
          "likes": 714
        },
        {
          "id": "madebyollin/sdxl-vae-fp16-fix",
          "type": "hf.vae",
          "name": "madebyollin/sdxl-vae-fp16-fix",
          "repo_id": "madebyollin/sdxl-vae-fp16-fix",
          "size_on_disk": 1343646154,
          "tags": [
            "diffusers",
            "safetensors",
            "stable-diffusion",
            "stable-diffusion-diffusers",
            "license:mit",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 297322,
          "likes": 593
        }
      ],
      "basic_fields": [
        "model",
        "image",
        "scale_factor"
      ]
    },
    {
      "title": "Feature Extraction",
      "description": "Extracts features from text using pre-trained models.\n    text, feature extraction, embeddings, natural language processing\n\n    Use cases:\n    - Text similarity comparison\n    - Clustering text documents\n    - Input for machine learning models\n    - Semantic search applications",
      "namespace": "huggingface.feature_extraction",
      "node_type": "huggingface.feature_extraction.FeatureExtraction",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.feature_extraction"
          },
          "default": {
            "type": "hf.feature_extraction",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for feature extraction"
        },
        {
          "name": "inputs",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Input Text",
          "description": "The text to extract features from"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "np_array"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "mixedbread-ai/mxbai-embed-large-v1",
          "type": "hf.feature_extraction",
          "name": "mixedbread-ai/mxbai-embed-large-v1",
          "repo_id": "mixedbread-ai/mxbai-embed-large-v1",
          "allow_patterns": [
            "*.safetensors",
            "*.txt",
            "*,json"
          ],
          "size_on_disk": 670559900,
          "pipeline_tag": "feature-extraction",
          "tags": [
            "sentence-transformers",
            "onnx",
            "safetensors",
            "openvino",
            "gguf",
            "bert",
            "feature-extraction",
            "mteb",
            "transformers.js",
            "transformers",
            "en",
            "arxiv:2309.12871",
            "license:apache-2.0",
            "model-index",
            "autotrain_compatible",
            "text-embeddings-inference",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 2195994,
          "likes": 741
        },
        {
          "id": "BAAI/bge-base-en-v1.5",
          "type": "hf.feature_extraction",
          "name": "BAAI/bge-base-en-v1.5",
          "repo_id": "BAAI/bge-base-en-v1.5",
          "allow_patterns": [
            "*.safetensors",
            "*.txt",
            "*,json"
          ],
          "size_on_disk": 438187020,
          "pipeline_tag": "feature-extraction",
          "tags": [
            "sentence-transformers",
            "pytorch",
            "onnx",
            "safetensors",
            "bert",
            "feature-extraction",
            "sentence-similarity",
            "transformers",
            "mteb",
            "en",
            "arxiv:2401.03462",
            "arxiv:2312.15503",
            "arxiv:2311.13534",
            "arxiv:2310.07554",
            "arxiv:2309.07597",
            "license:mit",
            "model-index",
            "autotrain_compatible",
            "text-embeddings-inference",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 4089312,
          "likes": 375
        },
        {
          "id": "BAAI/bge-large-en-v1.5",
          "type": "hf.feature_extraction",
          "name": "BAAI/bge-large-en-v1.5",
          "repo_id": "BAAI/bge-large-en-v1.5",
          "allow_patterns": [
            "*.safetensors",
            "*.txt",
            "*,json"
          ],
          "size_on_disk": 1340848124,
          "pipeline_tag": "feature-extraction",
          "tags": [
            "sentence-transformers",
            "pytorch",
            "onnx",
            "safetensors",
            "bert",
            "feature-extraction",
            "sentence-similarity",
            "transformers",
            "mteb",
            "en",
            "arxiv:2401.03462",
            "arxiv:2312.15503",
            "arxiv:2311.13534",
            "arxiv:2310.07554",
            "arxiv:2309.07597",
            "license:mit",
            "model-index",
            "autotrain_compatible",
            "text-embeddings-inference",
            "endpoints_compatible",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 5025518,
          "likes": 598
        }
      ],
      "basic_fields": [
        "model",
        "inputs"
      ]
    },
    {
      "title": "Text Generation",
      "description": "Generates text based on a given prompt.\n    text, generation, natural language processing\n\n    Use cases:\n    - Creative writing assistance\n    - Automated content generation\n    - Chatbots and conversational AI\n    - Code generation and completion",
      "namespace": "huggingface.text_generation",
      "node_type": "huggingface.text_generation.TextGeneration",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.text_generation"
          },
          "default": {
            "type": "hf.text_generation",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model ID on Huggingface",
          "description": "The model ID to use for the text generation. Supports both regular models and GGUF quantized models (detected by .gguf file extension)."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The input text prompt for generation"
        },
        {
          "name": "max_new_tokens",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Max New Tokens",
          "description": "The maximum number of new tokens to generate"
        },
        {
          "name": "temperature",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Temperature",
          "description": "Controls randomness in generation. Lower values make it more deterministic.",
          "min": 0.0,
          "max": 2.0
        },
        {
          "name": "top_p",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Top P",
          "description": "Controls diversity of generated text. Lower values make it more focused.",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "do_sample",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Do Sample",
          "description": "Whether to use sampling or greedy decoding"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "text"
        },
        {
          "type": {
            "type": "chunk"
          },
          "name": "chunk"
        }
      ],
      "basic_fields": [
        "model",
        "prompt"
      ],
      "is_streaming_output": true
    },
    {
      "title": "Chroma",
      "description": "Generates images from text prompts using Chroma, a text-to-image model based on Flux.\n    image, generation, AI, text-to-image, flux, chroma, transformer\n\n    Use cases:\n    - Generate high-quality images with Flux-based architecture\n    - Create images with advanced attention masking for enhanced fidelity\n    - Generate images with optimized memory usage\n    - Create professional-quality images with precise color control",
      "namespace": "huggingface.text_to_image",
      "node_type": "huggingface.text_to_image.Chroma",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "A high-fashion close-up portrait of a blonde woman in clear sunglasses. The image uses a bold teal and red color split for dramatic lighting. The background is a simple teal-green. The photo is sharp and well-composed, and is designed for viewing with anaglyph 3D glasses for optimal effect. It looks professionally done.",
          "title": "Prompt",
          "description": "A text prompt describing the desired image."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "low quality, ugly, unfinished, out of focus, deformed, disfigure, blurry, smudged, restricted palette, flat colors",
          "title": "Negative Prompt",
          "description": "A text prompt describing what to avoid in the image."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.0,
          "title": "Guidance Scale",
          "description": "The scale for classifier-free guidance.",
          "min": 0.0,
          "max": 30.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 40,
          "title": "Num Inference Steps",
          "description": "The number of denoising steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Height",
          "description": "The height of the generated image.",
          "min": 256.0,
          "max": 2048.0
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Width",
          "description": "The width of the generated image.",
          "min": 256.0,
          "max": 2048.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0
        },
        {
          "name": "max_sequence_length",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Max Sequence Length",
          "description": "Maximum sequence length to use with the prompt.",
          "min": 1.0,
          "max": 512.0
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload to reduce VRAM usage."
        },
        {
          "name": "enable_attention_slicing",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Attention Slicing",
          "description": "Enable attention slicing to reduce memory usage."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "lodestones/Chroma",
          "type": "hf.text_to_image",
          "name": "lodestones/Chroma",
          "repo_id": "lodestones/Chroma",
          "allow_patterns": [
            "**/*.safetensors",
            "**/*.json",
            "**/*.txt",
            "*.json"
          ],
          "size_on_disk": 205492973495,
          "pipeline_tag": "text-to-image",
          "tags": [
            "pytorch",
            "diffusers",
            "safetensors",
            "text-to-image",
            "image-generation",
            "chroma",
            "not-for-all-audiences",
            "en",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 0,
          "likes": 1282
        }
      ],
      "basic_fields": [
        "prompt",
        "height",
        "width",
        "seed"
      ]
    },
    {
      "title": "Flux",
      "description": "Generates images using FLUX models with support for Nunchaku quantization.\n    image, generation, AI, text-to-image, flux, quantization\n\n    Use cases:\n    - High-quality image generation with FLUX models\n    - Memory-efficient generation using Nunchaku quantization\n    - Fast generation with FLUX.1-schnell\n    - High-fidelity generation with FLUX.1-dev\n    - Controlled generation with Fill, Canny, or Depth variants",
      "namespace": "huggingface.text_to_image",
      "node_type": "huggingface.text_to_image.Flux",
      "properties": [
        {
          "name": "variant",
          "type": {
            "type": "enum",
            "values": [
              "schnell",
              "dev",
              "fill-dev",
              "canny-dev",
              "depth-dev"
            ],
            "type_name": "nodetool.nodes.huggingface.text_to_image.FluxVariant"
          },
          "default": "dev",
          "title": "Variant",
          "description": "The FLUX variant to use."
        },
        {
          "name": "quantization",
          "type": {
            "type": "enum",
            "values": [
              "fp16",
              "fp4",
              "int4"
            ],
            "type_name": "nodetool.nodes.huggingface.text_to_image.FluxQuantization"
          },
          "default": "int4",
          "title": "Quantization",
          "description": "The quantization level to use."
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "A cat holding a sign that says hello world",
          "title": "Prompt",
          "description": "A text prompt describing the desired image."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "The scale for classifier-free guidance. Use 0.0 for schnell, 3.5 for dev.",
          "min": 0.0,
          "max": 20.0
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Width",
          "description": "The width of the generated image.",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Height",
          "description": "The height of the generated image.",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 20,
          "title": "Num Inference Steps",
          "description": "The number of denoising steps. 4 steps is forced for schnell models.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "max_sequence_length",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Max Sequence Length",
          "description": "Maximum sequence length for the prompt. Use 256 for schnell, 512 for dev.",
          "min": 1.0,
          "max": 512.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "black-forest-labs/FLUX.1-schnell",
          "type": "hf.flux",
          "name": "black-forest-labs/FLUX.1-schnell",
          "repo_id": "black-forest-labs/FLUX.1-schnell",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "scheduler/*",
            "vae/*",
            "text_encoder/*",
            "tokenizer/*",
            "tokenizer_2/*"
          ],
          "size_on_disk": 418780386,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "image-generation",
            "flux",
            "en",
            "license:apache-2.0",
            "endpoints_compatible",
            "diffusers:FluxPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 836664,
          "likes": 4416
        },
        {
          "id": "black-forest-labs/FLUX.1-dev",
          "type": "hf.flux",
          "name": "black-forest-labs/FLUX.1-dev",
          "repo_id": "black-forest-labs/FLUX.1-dev",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "scheduler/*",
            "vae/*",
            "text_encoder/*",
            "tokenizer/*",
            "tokenizer_2/*"
          ],
          "size_on_disk": 418780928,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "image-generation",
            "flux",
            "en",
            "license:other",
            "endpoints_compatible",
            "diffusers:FluxPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 1530950,
          "likes": 11862
        },
        {
          "id": "nunchaku-tech/nunchaku-flux.1-schnell:svdq-int4_r32-flux.1-schnell.safetensors",
          "type": "hf.flux",
          "name": "nunchaku-tech/nunchaku-flux.1-schnell",
          "repo_id": "nunchaku-tech/nunchaku-flux.1-schnell",
          "path": "svdq-int4_r32-flux.1-schnell.safetensors",
          "size_on_disk": 6747849760,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "SVDQuant",
            "FLUX.1-schnell",
            "FLUX.1",
            "Diffusion",
            "Quantization",
            "ICLR2025",
            "en",
            "dataset:mit-han-lab/svdquant-datasets",
            "arxiv:2411.05007",
            "base_model:black-forest-labs/FLUX.1-schnell",
            "base_model:quantized:black-forest-labs/FLUX.1-schnell",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 2503,
          "likes": 9
        },
        {
          "id": "nunchaku-tech/nunchaku-flux.1-schnell:svdq-fp4_r32-flux.1-schnell.safetensors",
          "type": "hf.flux",
          "name": "nunchaku-tech/nunchaku-flux.1-schnell",
          "repo_id": "nunchaku-tech/nunchaku-flux.1-schnell",
          "path": "svdq-fp4_r32-flux.1-schnell.safetensors",
          "size_on_disk": 7018246824,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "SVDQuant",
            "FLUX.1-schnell",
            "FLUX.1",
            "Diffusion",
            "Quantization",
            "ICLR2025",
            "en",
            "dataset:mit-han-lab/svdquant-datasets",
            "arxiv:2411.05007",
            "base_model:black-forest-labs/FLUX.1-schnell",
            "base_model:quantized:black-forest-labs/FLUX.1-schnell",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 2503,
          "likes": 9
        },
        {
          "id": "nunchaku-tech/nunchaku-flux.1-dev:svdq-int4_r32-flux.1-dev.safetensors",
          "type": "hf.flux",
          "name": "nunchaku-tech/nunchaku-flux.1-dev",
          "repo_id": "nunchaku-tech/nunchaku-flux.1-dev",
          "path": "svdq-int4_r32-flux.1-dev.safetensors",
          "size_on_disk": 6768309832,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "SVDQuant",
            "FLUX.1-dev",
            "FLUX.1",
            "Diffusion",
            "Quantization",
            "ICLR2025",
            "en",
            "dataset:mit-han-lab/svdquant-datasets",
            "arxiv:2411.05007",
            "base_model:black-forest-labs/FLUX.1-dev",
            "base_model:quantized:black-forest-labs/FLUX.1-dev",
            "license:other",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 26198,
          "likes": 39
        },
        {
          "id": "nunchaku-tech/nunchaku-flux.1-dev:svdq-fp4_r32-flux.1-dev.safetensors",
          "type": "hf.flux",
          "name": "nunchaku-tech/nunchaku-flux.1-dev",
          "repo_id": "nunchaku-tech/nunchaku-flux.1-dev",
          "path": "svdq-fp4_r32-flux.1-dev.safetensors",
          "size_on_disk": 7038706888,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "SVDQuant",
            "FLUX.1-dev",
            "FLUX.1",
            "Diffusion",
            "Quantization",
            "ICLR2025",
            "en",
            "dataset:mit-han-lab/svdquant-datasets",
            "arxiv:2411.05007",
            "base_model:black-forest-labs/FLUX.1-dev",
            "base_model:quantized:black-forest-labs/FLUX.1-dev",
            "license:other",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 26198,
          "likes": 39
        },
        {
          "id": "mit-han-lab/nunchaku-t5:awq-int4-flux.1-t5xxl.safetensors",
          "type": "hf.t5",
          "name": "mit-han-lab/nunchaku-t5",
          "repo_id": "mit-han-lab/nunchaku-t5",
          "path": "awq-int4-flux.1-t5xxl.safetensors",
          "size_on_disk": 2986819952,
          "pipeline_tag": "text-generation",
          "tags": [
            "transformers",
            "text-generation",
            "AWQ",
            "Quantization",
            "en",
            "dataset:mit-han-lab/svdquant-datasets",
            "arxiv:2411.05007",
            "base_model:google/t5-v1_1-xxl",
            "base_model:quantized:google/t5-v1_1-xxl",
            "license:apache-2.0",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 2,
          "likes": 19
        }
      ],
      "basic_fields": [
        "variant",
        "quantization",
        "prompt",
        "height",
        "width",
        "seed"
      ]
    },
    {
      "title": "Flux Control",
      "description": "Generates images using FLUX Control models with depth or other control guidance.\n    image, generation, AI, text-to-image, flux, control, depth, guidance\n\n    Use cases:\n    - Generate images with depth-based control guidance\n    - Create images following structural guidance from control images\n    - High-quality controlled generation with FLUX models\n    - Depth-aware image generation",
      "namespace": "huggingface.text_to_image",
      "node_type": "huggingface.text_to_image.FluxControl",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.controlnet_flux"
          },
          "default": {
            "type": "hf.controlnet_flux",
            "repo_id": "black-forest-labs/FLUX.1-Depth-dev",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model",
          "description": "The FLUX Control model to use for controlled image generation."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "A robot made of exotic candies and chocolates of different kinds. The background is filled with confetti and celebratory gifts.",
          "title": "Prompt",
          "description": "A text prompt describing the desired image."
        },
        {
          "name": "control_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Control Image",
          "description": "The control image to guide the generation process."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 10.0,
          "title": "Guidance Scale",
          "description": "The scale for classifier-free guidance.",
          "min": 0.0,
          "max": 30.0
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Width",
          "description": "The width of the generated image.",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Height",
          "description": "The height of the generated image.",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "The number of denoising steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload to reduce VRAM usage."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "black-forest-labs/FLUX.1-Depth-dev",
          "type": "hf.controlnet_flux",
          "name": "black-forest-labs/FLUX.1-Depth-dev",
          "repo_id": "black-forest-labs/FLUX.1-Depth-dev",
          "size_on_disk": 67823838679,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "image-generation",
            "flux",
            "diffusion-single-file",
            "en",
            "license:other",
            "diffusers:FluxControlPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 5455,
          "likes": 228
        },
        {
          "id": "black-forest-labs/FLUX.1-Canny-dev",
          "type": "hf.controlnet_flux",
          "name": "black-forest-labs/FLUX.1-Canny-dev",
          "repo_id": "black-forest-labs/FLUX.1-Canny-dev",
          "size_on_disk": 67823838991,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "image-generation",
            "flux",
            "diffusion-single-file",
            "en",
            "license:other",
            "diffusers:FluxControlPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 2051,
          "likes": 231
        },
        {
          "id": "nunchaku-tech/nunchaku-flux.1-depth-dev:svdq-int4_r32-flux.1-depth-dev.safetensors",
          "type": "hf.controlnet_flux",
          "name": "nunchaku-tech/nunchaku-flux.1-depth-dev",
          "repo_id": "nunchaku-tech/nunchaku-flux.1-depth-dev",
          "path": "svdq-int4_r32-flux.1-depth-dev.safetensors",
          "size_on_disk": 6768703136,
          "pipeline_tag": "image-to-image",
          "tags": [
            "diffusers",
            "image-to-image",
            "SVDQuant",
            "FLUX.1-Depth-dev",
            "FLUX.1",
            "Diffusion",
            "Quantization",
            "ICLR2025",
            "en",
            "dataset:mit-han-lab/svdquant-datasets",
            "arxiv:2411.05007",
            "base_model:black-forest-labs/FLUX.1-Depth-dev",
            "base_model:quantized:black-forest-labs/FLUX.1-Depth-dev",
            "license:other",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 871,
          "likes": 4
        },
        {
          "id": "nunchaku-tech/nunchaku-flux.1-depth-dev:svdq-fp4_r32-flux.1-depth-dev.safetensors",
          "type": "hf.controlnet_flux",
          "name": "nunchaku-tech/nunchaku-flux.1-depth-dev",
          "repo_id": "nunchaku-tech/nunchaku-flux.1-depth-dev",
          "path": "svdq-fp4_r32-flux.1-depth-dev.safetensors",
          "size_on_disk": 7039100192,
          "pipeline_tag": "image-to-image",
          "tags": [
            "diffusers",
            "image-to-image",
            "SVDQuant",
            "FLUX.1-Depth-dev",
            "FLUX.1",
            "Diffusion",
            "Quantization",
            "ICLR2025",
            "en",
            "dataset:mit-han-lab/svdquant-datasets",
            "arxiv:2411.05007",
            "base_model:black-forest-labs/FLUX.1-Depth-dev",
            "base_model:quantized:black-forest-labs/FLUX.1-Depth-dev",
            "license:other",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 871,
          "likes": 4
        },
        {
          "id": "nunchaku-tech/nunchaku-flux.1-canny-dev:svdq-int4_r32-flux.1-canny-dev.safetensors",
          "type": "hf.controlnet_flux",
          "name": "nunchaku-tech/nunchaku-flux.1-canny-dev",
          "repo_id": "nunchaku-tech/nunchaku-flux.1-canny-dev",
          "path": "svdq-int4_r32-flux.1-canny-dev.safetensors",
          "size_on_disk": 6768703136,
          "pipeline_tag": "image-to-image",
          "tags": [
            "diffusers",
            "image-to-image",
            "SVDQuant",
            "FLUX.1-Canny-dev",
            "FLUX.1",
            "Diffusion",
            "Quantization",
            "ICLR2025",
            "en",
            "dataset:mit-han-lab/svdquant-datasets",
            "arxiv:2411.05007",
            "base_model:black-forest-labs/FLUX.1-Canny-dev",
            "base_model:quantized:black-forest-labs/FLUX.1-Canny-dev",
            "license:other",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 712,
          "likes": 5
        },
        {
          "id": "nunchaku-tech/nunchaku-flux.1-canny-dev:svdq-fp4_r32-flux.1-canny-dev.safetensors",
          "type": "hf.controlnet_flux",
          "name": "nunchaku-tech/nunchaku-flux.1-canny-dev",
          "repo_id": "nunchaku-tech/nunchaku-flux.1-canny-dev",
          "path": "svdq-fp4_r32-flux.1-canny-dev.safetensors",
          "size_on_disk": 7039100192,
          "pipeline_tag": "image-to-image",
          "tags": [
            "diffusers",
            "image-to-image",
            "SVDQuant",
            "FLUX.1-Canny-dev",
            "FLUX.1",
            "Diffusion",
            "Quantization",
            "ICLR2025",
            "en",
            "dataset:mit-han-lab/svdquant-datasets",
            "arxiv:2411.05007",
            "base_model:black-forest-labs/FLUX.1-Canny-dev",
            "base_model:quantized:black-forest-labs/FLUX.1-Canny-dev",
            "license:other",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 712,
          "likes": 5
        },
        {
          "id": "mit-han-lab/nunchaku-t5:awq-int4-flux.1-t5xxl.safetensors",
          "type": "hf.t5",
          "name": "mit-han-lab/nunchaku-t5",
          "repo_id": "mit-han-lab/nunchaku-t5",
          "path": "awq-int4-flux.1-t5xxl.safetensors",
          "size_on_disk": 2986819952,
          "pipeline_tag": "text-generation",
          "tags": [
            "transformers",
            "text-generation",
            "AWQ",
            "Quantization",
            "en",
            "dataset:mit-han-lab/svdquant-datasets",
            "arxiv:2411.05007",
            "base_model:google/t5-v1_1-xxl",
            "base_model:quantized:google/t5-v1_1-xxl",
            "license:apache-2.0",
            "endpoints_compatible",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 2,
          "likes": 19
        }
      ],
      "basic_fields": [
        "model",
        "prompt",
        "control_image",
        "height",
        "width",
        "guidance_scale",
        "seed"
      ]
    },
    {
      "title": "Load Text To Image Model",
      "description": "Load HuggingFace model for image-to-image generation from a repo_id.\n\n    Use cases:\n    - Loads a pipeline directly from a repo_id\n    - Used for AutoPipelineForImage2Image",
      "namespace": "huggingface.text_to_image",
      "node_type": "huggingface.text_to_image.LoadTextToImageModel",
      "properties": [
        {
          "name": "repo_id",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Repo Id",
          "description": "The repository ID of the model to use for image-to-image generation."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "hf.text_to_image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "repo_id"
      ]
    },
    {
      "title": "Qwen-Image",
      "description": "Generates images from text prompts using Qwen-Image with support for Nunchaku quantization.\n    image, generation, AI, text-to-image, qwen, quantization\n\n    Use cases:\n    - High-quality, general-purpose text-to-image generation\n    - Memory-efficient generation using Nunchaku quantization\n    - Quick prototyping leveraging AutoPipeline\n    - Works out-of-the-box with the official Qwen model",
      "namespace": "huggingface.text_to_image",
      "node_type": "huggingface.text_to_image.QwenImage",
      "properties": [
        {
          "name": "quantization",
          "type": {
            "type": "enum",
            "values": [
              "fp16",
              "fp4",
              "int4"
            ],
            "type_name": "nodetool.nodes.huggingface.text_to_image.QwenQuantization"
          },
          "default": "int4",
          "title": "Quantization",
          "description": "The quantization level to use."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "A cat holding a sign that says hello world",
          "title": "Prompt",
          "description": "A text prompt describing the desired image."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "A text prompt describing what to avoid in the image."
        },
        {
          "name": "true_cfg_scale",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "True Cfg Scale",
          "description": "True CFG scale for Qwen-Image models.",
          "min": 0.0,
          "max": 10.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "The number of denoising steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Height",
          "description": "The height of the generated image.",
          "min": 256.0,
          "max": 2048.0
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Width",
          "description": "The width of the generated image.",
          "min": 256.0,
          "max": 2048.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload to reduce VRAM usage."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "recommended_models": [
        {
          "id": "Qwen/Qwen-Image",
          "type": "hf.qwen_image",
          "name": "Qwen/Qwen-Image",
          "repo_id": "Qwen/Qwen-Image",
          "allow_patterns": [
            "*.json",
            "*.txt",
            "scheduler/*",
            "vae/*",
            "text_encoder/*",
            "tokenizer/*",
            "tokenizer_2/*"
          ],
          "size_on_disk": 16843547133,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "en",
            "zh",
            "arxiv:2508.02324",
            "license:apache-2.0",
            "diffusers:QwenImagePipeline",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 244342,
          "likes": 2227
        },
        {
          "id": "nunchaku-tech/nunchaku-qwen-image:svdq-int4_r32-qwen-image.safetensors",
          "type": "hf.qwen_image",
          "name": "nunchaku-tech/nunchaku-qwen-image",
          "repo_id": "nunchaku-tech/nunchaku-qwen-image",
          "path": "svdq-int4_r32-qwen-image.safetensors",
          "size_on_disk": 11521979944,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "SVDQuant",
            "Qwen-Image",
            "Diffusion",
            "Quantization",
            "ICLR2025",
            "en",
            "dataset:mit-han-lab/svdquant-datasets",
            "arxiv:2411.05007",
            "base_model:Qwen/Qwen-Image",
            "base_model:quantized:Qwen/Qwen-Image",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 69955,
          "likes": 229
        },
        {
          "id": "nunchaku-tech/nunchaku-qwen-image:svdq-fp4_r32-qwen-image.safetensors",
          "type": "hf.qwen_image",
          "name": "nunchaku-tech/nunchaku-qwen-image",
          "repo_id": "nunchaku-tech/nunchaku-qwen-image",
          "path": "svdq-fp4_r32-qwen-image.safetensors",
          "size_on_disk": 11948923656,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "SVDQuant",
            "Qwen-Image",
            "Diffusion",
            "Quantization",
            "ICLR2025",
            "en",
            "dataset:mit-han-lab/svdquant-datasets",
            "arxiv:2411.05007",
            "base_model:Qwen/Qwen-Image",
            "base_model:quantized:Qwen/Qwen-Image",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 69955,
          "likes": 229
        }
      ],
      "basic_fields": [
        "quantization",
        "prompt",
        "negative_prompt",
        "height",
        "width",
        "num_inference_steps"
      ]
    },
    {
      "title": "Stable Diffusion",
      "description": "Generates images from text prompts using Stable Diffusion.\n    image, generation, AI, text-to-image, SD\n\n    Use cases:\n    - Creating custom illustrations for various projects\n    - Generating concept art for creative endeavors\n    - Producing unique visual content for marketing materials\n    - Exploring AI-generated art for personal or professional use",
      "namespace": "huggingface.text_to_image",
      "node_type": "huggingface.text_to_image.StableDiffusion",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.stable_diffusion"
          },
          "default": {
            "type": "hf.stable_diffusion",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model",
          "description": "The model to use for image generation."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt for image generation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to guide what should not appear in the generated image."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0,
          "max": 4294967295.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "Guidance scale for generation.",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "DPMSolverSDEScheduler",
              "EulerDiscreteScheduler",
              "LMSDiscreteScheduler",
              "DDIMScheduler",
              "DDPMScheduler",
              "HeunDiscreteScheduler",
              "DPMSolverMultistepScheduler",
              "DEISMultistepScheduler",
              "PNDMScheduler",
              "EulerAncestralDiscreteScheduler",
              "UniPCMultistepScheduler",
              "KDPM2DiscreteScheduler",
              "DPMSolverSinglestepScheduler",
              "KDPM2AncestralDiscreteScheduler"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionBaseNode.StableDiffusionScheduler"
          },
          "default": "EulerDiscreteScheduler",
          "title": "Scheduler",
          "description": "The scheduler to use for the diffusion process."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "hf.lora_sd_config"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "The LoRA models to use for image processing"
        },
        {
          "name": "ip_adapter_model",
          "type": {
            "type": "hf.ip_adapter"
          },
          "default": {
            "type": "hf.ip_adapter",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Ip Adapter Model",
          "description": "The IP adapter model to use for image processing"
        },
        {
          "name": "ip_adapter_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Ip Adapter Image",
          "description": "When provided the image will be fed into the IP adapter"
        },
        {
          "name": "ip_adapter_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Ip Adapter Scale",
          "description": "The strength of the IP adapter",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "latents",
          "type": {
            "type": "torch_tensor"
          },
          "default": {
            "type": "torch_tensor",
            "value": null,
            "dtype": "<i8",
            "shape": [
              1
            ]
          },
          "title": "Latents",
          "description": "Optional initial latents to start generation from."
        },
        {
          "name": "enable_attention_slicing",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Attention Slicing",
          "description": "Enable attention slicing for the pipeline. This can reduce VRAM usage."
        },
        {
          "name": "enable_tiling",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Tiling",
          "description": "Legacy VAE tiling flag (disabled in favor of PyTorch 2 attention optimizations)."
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage."
        },
        {
          "name": "output_type",
          "type": {
            "type": "enum",
            "values": [
              "Image",
              "Latent"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionBaseNode.StableDiffusionOutputType"
          },
          "default": "Image",
          "title": "Output Type",
          "description": "The type of output to generate."
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Width",
          "description": "Width of the generated image.",
          "min": 256.0,
          "max": 1024.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Height",
          "description": "Height of the generated image",
          "min": 256.0,
          "max": 1024.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "torch_tensor"
          },
          "name": "latent"
        }
      ],
      "recommended_models": [
        {
          "id": "h94/IP-Adapter:models/ip-adapter_sd15.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "models/ip-adapter_sd15.bin",
          "size_on_disk": 44642825,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "h94/IP-Adapter:models/ip-adapter_sd15_light.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "models/ip-adapter_sd15_light.bin",
          "size_on_disk": 44642819,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "h94/IP-Adapter:models/ip-adapter_sd15_vit-G.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "models/ip-adapter_sd15_vit-G.bin",
          "size_on_disk": 46215689,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "Lykon/DreamShaper:DreamShaper_6.2_BakedVae_pruned.safetensors",
          "type": "hf.stable_diffusion",
          "name": "Lykon/DreamShaper",
          "repo_id": "Lykon/DreamShaper",
          "path": "DreamShaper_6.2_BakedVae_pruned.safetensors",
          "size_on_disk": 2132625894,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "stable-diffusion",
            "stable-diffusion-diffusers",
            "text-to-image",
            "art",
            "artistic",
            "anime",
            "en",
            "doi:10.57967/hf/0453",
            "license:other",
            "autotrain_compatible",
            "diffusers:StableDiffusionPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 201878,
          "likes": 992
        }
      ],
      "basic_fields": [
        "model",
        "prompt",
        "width",
        "height"
      ]
    },
    {
      "title": "Stable Diffusion XL",
      "description": "Generates images from text prompts using Stable Diffusion XL.\n    image, generation, AI, text-to-image, SDXL\n\n    Use cases:\n    - Creating custom illustrations for marketing materials\n    - Generating concept art for game and film development\n    - Producing unique stock imagery for websites and publications\n    - Visualizing interior design concepts for clients",
      "namespace": "huggingface.text_to_image",
      "node_type": "huggingface.text_to_image.StableDiffusionXL",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.stable_diffusion_xl"
          },
          "default": {
            "type": "hf.stable_diffusion_xl",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model",
          "description": "The Stable Diffusion XL model to use for generation."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt for image generation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to guide what should not appear in the generated image."
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Width",
          "description": "Width of the generated image.",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 1024,
          "title": "Height",
          "description": "Height of the generated image",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator.",
          "min": -1.0,
          "max": 1000000.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Inference Steps",
          "description": "Number of inference steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.0,
          "title": "Guidance Scale",
          "description": "Guidance scale for generation.",
          "min": 0.0,
          "max": 20.0
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "DPMSolverSDEScheduler",
              "EulerDiscreteScheduler",
              "LMSDiscreteScheduler",
              "DDIMScheduler",
              "DDPMScheduler",
              "HeunDiscreteScheduler",
              "DPMSolverMultistepScheduler",
              "DEISMultistepScheduler",
              "PNDMScheduler",
              "EulerAncestralDiscreteScheduler",
              "UniPCMultistepScheduler",
              "KDPM2DiscreteScheduler",
              "DPMSolverSinglestepScheduler",
              "KDPM2AncestralDiscreteScheduler"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionXLBase.StableDiffusionScheduler"
          },
          "default": "EulerDiscreteScheduler",
          "title": "Scheduler",
          "description": "The scheduler to use for the diffusion process."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "hf.lora_sdxl_config"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "The LoRA models to use for image processing"
        },
        {
          "name": "lora_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Lora Scale",
          "description": "Strength of the LoRAs",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "ip_adapter_model",
          "type": {
            "type": "hf.ip_adapter"
          },
          "default": {
            "type": "hf.ip_adapter",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Ip Adapter Model",
          "description": "The IP adapter model to use for image processing"
        },
        {
          "name": "ip_adapter_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Ip Adapter Image",
          "description": "When provided the image will be fed into the IP adapter"
        },
        {
          "name": "ip_adapter_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Ip Adapter Scale",
          "description": "Strength of the IP adapter image",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "enable_attention_slicing",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Attention Slicing",
          "description": "Enable attention slicing for the pipeline. This can reduce VRAM usage."
        },
        {
          "name": "enable_tiling",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Tiling",
          "description": "Legacy VAE tiling flag (disabled in favor of PyTorch 2 attention optimizations)."
        },
        {
          "name": "enable_cpu_offload",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Cpu Offload",
          "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage."
        },
        {
          "name": "output_type",
          "type": {
            "type": "enum",
            "values": [
              "Image",
              "Latent"
            ],
            "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionXLBase.StableDiffusionOutputType"
          },
          "default": "Image",
          "title": "Output Type",
          "description": "The type of output to generate."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "torch_tensor"
          },
          "name": "latent"
        }
      ],
      "recommended_models": [
        {
          "id": "h94/IP-Adapter:sdxl_models/ip-adapter_sdxl.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "sdxl_models/ip-adapter_sdxl.bin",
          "size_on_disk": 702585097,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "h94/IP-Adapter:sdxl_models/ip-adapter_sdxl_vit-h.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "sdxl_models/ip-adapter_sdxl_vit-h.bin",
          "size_on_disk": 698390793,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "h94/IP-Adapter:sdxl_models/ip-adapter-plus_sdxl_vit-h.bin",
          "type": "hf.ip_adapter",
          "name": "h94/IP-Adapter",
          "repo_id": "h94/IP-Adapter",
          "path": "sdxl_models/ip-adapter-plus_sdxl_vit-h.bin",
          "size_on_disk": 1013454427,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "en",
            "arxiv:2308.06721",
            "license:apache-2.0",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 0,
          "likes": 1251
        },
        {
          "id": "stabilityai/stable-diffusion-xl-base-1.0:sd_xl_base_1.0.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "stabilityai/stable-diffusion-xl-base-1.0",
          "repo_id": "stabilityai/stable-diffusion-xl-base-1.0",
          "path": "sd_xl_base_1.0.safetensors",
          "size_on_disk": 6938078334,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "onnx",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "arxiv:2307.01952",
            "arxiv:2211.01324",
            "arxiv:2108.01073",
            "arxiv:2112.10752",
            "license:openrail++",
            "autotrain_compatible",
            "endpoints_compatible",
            "diffusers:StableDiffusionXLPipeline",
            "deploy:azure",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 2760051,
          "likes": 7146
        },
        {
          "id": "Lykon/dreamshaper-xl-v2-turbo:DreamShaperXL_Turbo_v2_1.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "Lykon/dreamshaper-xl-v2-turbo",
          "repo_id": "Lykon/dreamshaper-xl-v2-turbo",
          "path": "DreamShaperXL_Turbo_v2_1.safetensors",
          "size_on_disk": 6939220250,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "stable-diffusion",
            "stable-diffusion-diffusers",
            "stable-diffusion-xl",
            "stable-diffusion-xl-turbo",
            "text-to-image",
            "art",
            "artistic",
            "anime",
            "dreamshaper",
            "turbo",
            "lcm",
            "en",
            "license:openrail++",
            "autotrain_compatible",
            "endpoints_compatible",
            "diffusers:StableDiffusionXLPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 56786,
          "likes": 69
        },
        {
          "id": "RunDiffusion/Juggernaut-XL-v9:Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "RunDiffusion/Juggernaut-XL-v9",
          "repo_id": "RunDiffusion/Juggernaut-XL-v9",
          "path": "Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors",
          "size_on_disk": 7105348188,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "art",
            "people",
            "diffusion",
            "Cinematic",
            "Photography",
            "Landscape",
            "Interior",
            "Food",
            "Car",
            "Wildlife",
            "Architecture",
            "text-to-image",
            "en",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:finetune:stabilityai/stable-diffusion-xl-base-1.0",
            "license:creativeml-openrail-m",
            "autotrain_compatible",
            "endpoints_compatible",
            "diffusers:StableDiffusionXLPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 304515,
          "likes": 272
        },
        {
          "id": "dataautogpt3/ProteusV0.3:ProteusV0.3.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "dataautogpt3/ProteusV0.3",
          "repo_id": "dataautogpt3/ProteusV0.3",
          "path": "ProteusV0.3.safetensors",
          "size_on_disk": 6938040736,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "license:gpl-3.0",
            "autotrain_compatible",
            "endpoints_compatible",
            "diffusers:StableDiffusionXLPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 286459,
          "likes": 94
        },
        {
          "id": "John6666/prefect-illustrious-xl-v3-sdxl",
          "type": "hf.stable_diffusion_xl",
          "name": "John6666/prefect-illustrious-xl-v3-sdxl",
          "repo_id": "John6666/prefect-illustrious-xl-v3-sdxl",
          "size_on_disk": 6941387072,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "stable-diffusion-xl",
            "anime",
            "girls",
            "styles",
            "lighting",
            "texture",
            "clean",
            "color balance",
            "prompt understanding",
            "merge",
            "noobai",
            "Illustrious XL v1.0",
            "illustrious",
            "en",
            "base_model:Laxhar/noobai-XL-1.1",
            "base_model:merge:Laxhar/noobai-XL-1.1",
            "base_model:OnomaAIResearch/Illustrious-XL-v1.0",
            "base_model:merge:OnomaAIResearch/Illustrious-XL-v1.0",
            "license:other",
            "autotrain_compatible",
            "endpoints_compatible",
            "diffusers:StableDiffusionXLPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 314267,
          "likes": 0
        },
        {
          "id": "cagliostrolab/animagine-xl-4.0:animagine-xl-4.0-opt.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "cagliostrolab/animagine-xl-4.0",
          "repo_id": "cagliostrolab/animagine-xl-4.0",
          "path": "animagine-xl-4.0-opt.safetensors",
          "size_on_disk": 6938350040,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "text-to-image",
            "stable-diffusion",
            "stable-diffusion-xl",
            "en",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:finetune:stabilityai/stable-diffusion-xl-base-1.0",
            "license:openrail++",
            "autotrain_compatible",
            "endpoints_compatible",
            "diffusers:StableDiffusionXLPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 216454,
          "likes": 354
        },
        {
          "id": "SG161222/RealVisXL_V5.0:RealVisXL_V5.0_fp16.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "SG161222/RealVisXL_V5.0",
          "repo_id": "SG161222/RealVisXL_V5.0",
          "path": "RealVisXL_V5.0_fp16.safetensors",
          "size_on_disk": 6938065488,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "safetensors",
            "license:openrail++",
            "autotrain_compatible",
            "endpoints_compatible",
            "diffusers:StableDiffusionXLPipeline",
            "region:us"
          ],
          "has_model_index": true,
          "downloads": 49926,
          "likes": 115
        },
        {
          "id": "nunchaku-tech/nunchaku-sdxl:svdq-int4_r32-sdxl.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "nunchaku-tech/nunchaku-sdxl",
          "repo_id": "nunchaku-tech/nunchaku-sdxl",
          "path": "svdq-int4_r32-sdxl.safetensors",
          "size_on_disk": 2559021560,
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "SVDQuant",
            "SDXL",
            "Diffusion",
            "Quantization",
            "stable-diffusion",
            "en",
            "dataset:mit-han-lab/svdquant-datasets",
            "arxiv:2411.05007",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:quantized:stabilityai/stable-diffusion-xl-base-1.0",
            "license:openrail++",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 952,
          "likes": 24
        },
        {
          "id": "nunchaku-tech/nunchaku-sdxl:svdq-fp4_r32-sdxl.safetensors",
          "type": "hf.stable_diffusion_xl",
          "name": "nunchaku-tech/nunchaku-sdxl",
          "repo_id": "nunchaku-tech/nunchaku-sdxl",
          "path": "svdq-fp4_r32-sdxl.safetensors",
          "pipeline_tag": "text-to-image",
          "tags": [
            "diffusers",
            "text-to-image",
            "SVDQuant",
            "SDXL",
            "Diffusion",
            "Quantization",
            "stable-diffusion",
            "en",
            "dataset:mit-han-lab/svdquant-datasets",
            "arxiv:2411.05007",
            "base_model:stabilityai/stable-diffusion-xl-base-1.0",
            "base_model:quantized:stabilityai/stable-diffusion-xl-base-1.0",
            "license:openrail++",
            "region:us"
          ],
          "has_model_index": false,
          "downloads": 952,
          "likes": 24
        }
      ],
      "basic_fields": [
        "model",
        "prompt",
        "width",
        "height"
      ]
    },
    {
      "title": "Text to Image",
      "description": "Generates images from text prompts using AutoPipeline for automatic pipeline selection.\n    image, generation, AI, text-to-image, auto\n\n    Use cases:\n    - Automatic selection of the best pipeline for a given model\n    - Flexible image generation without pipeline-specific knowledge\n    - Quick prototyping with various text-to-image models\n    - Streamlined workflow for different model architectures",
      "namespace": "huggingface.text_to_image",
      "node_type": "huggingface.text_to_image.Text2Image",
      "properties": [
        {
          "name": "model",
          "type": {
            "type": "hf.text_to_image"
          },
          "default": {
            "type": "hf.text_to_image",
            "repo_id": "",
            "path": null,
            "variant": null,
            "allow_patterns": null,
            "ignore_patterns": null
          },
          "title": "Model",
          "description": "The model to use for text-to-image generation."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "A cat holding a sign that says hello world",
          "title": "Prompt",
          "description": "A text prompt describing the desired image."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "A text prompt describing what to avoid in the image."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "The number of denoising steps.",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "The scale for classifier-free guidance.",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "width",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Width",
          "description": "The width of the generated image.",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "height",
          "type": {
            "type": "int"
          },
          "default": 512,
          "title": "Height",
          "description": "The height of the generated image.",
          "min": 64.0,
          "max": 2048.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator. Use -1 for a random seed.",
          "min": -1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "torch_tensor"
          },
          "name": "latent"
        }
      ],
      "basic_fields": [
        "model",
        "prompt",
        "height",
        "width",
        "seed"
      ]
    }
  ],
  "assets": [
    {
      "package_name": "nodetool-huggingface",
      "name": "Image to Image.jpg",
      "path": ""
    },
    {
      "package_name": "nodetool-huggingface",
      "name": "Stable Diffusion.jpg",
      "path": ""
    },
    {
      "package_name": "nodetool-huggingface",
      "name": "Segmentation.jpg",
      "path": ""
    },
    {
      "package_name": "nodetool-huggingface",
      "name": "Pokemon Maker.jpg",
      "path": ""
    },
    {
      "package_name": "nodetool-huggingface",
      "name": "stable_diffusion_xl.jpg",
      "path": ""
    },
    {
      "package_name": "nodetool-huggingface",
      "name": "Audio To Image.jpg",
      "path": ""
    },
    {
      "package_name": "nodetool-huggingface",
      "name": "Re-Imagine.jpg",
      "path": ""
    },
    {
      "package_name": "nodetool-huggingface",
      "name": "Audio To Spectrogram.jpg",
      "path": ""
    },
    {
      "package_name": "nodetool-huggingface",
      "name": "Object Detection.jpg",
      "path": ""
    },
    {
      "package_name": "nodetool-huggingface",
      "name": "Add Subtitles To Video.jpg",
      "path": ""
    },
    {
      "package_name": "nodetool-huggingface",
      "name": "Upscaling.jpg",
      "path": ""
    },
    {
      "package_name": "nodetool-huggingface",
      "name": "Depth Estimation.jpg",
      "path": ""
    },
    {
      "package_name": "nodetool-huggingface",
      "name": "Movie Posters.jpg",
      "path": ""
    },
    {
      "package_name": "nodetool-huggingface",
      "name": "Piano Track.jpg",
      "path": ""
    },
    {
      "package_name": "nodetool-huggingface",
      "name": "Controlnet.jpg",
      "path": ""
    },
    {
      "package_name": "nodetool-huggingface",
      "name": "Summarize Audio.jpg",
      "path": ""
    },
    {
      "package_name": "nodetool-huggingface",
      "name": "Style Transfer.jpg",
      "path": ""
    }
  ],
  "examples": [
    {
      "id": "dfff77a8f38911ef919400004a056799",
      "name": "Upscaling",
      "description": "Upscale low-resolution images to higher quality using RealESRGAN, a powerful AI model that enhances details and clarity without artifacts.",
      "tags": [
        "image",
        "start",
        "huggingface"
      ]
    },
    {
      "id": "style_transfer",
      "name": "Style Transfer",
      "description": "Transform your images by applying artistic styles from reference images. This workflow relies on ControlNet to preserve structure while prompts and model choices guide the style. Perfect for creating artistic variations of portraits or other images.",
      "tags": [
        "huggingface",
        "image",
        "start"
      ]
    },
    {
      "id": "3ae8a1cd7aa511f08640000015d0df1b",
      "name": "Audio To Image",
      "description": "Transform spoken descriptions into images with this workflow. Record or upload audio, which is transcribed by Whisper and then visualized by Stable Diffusion. Perfect for quickly generating images from verbal ideas without typing.",
      "tags": [
        "huggingface",
        "multimodal",
        "start"
      ]
    },
    {
      "id": "controlnet",
      "name": "Controlnet",
      "description": "",
      "tags": [
        "start",
        "image"
      ]
    },
    {
      "id": "3b0fb4e4988711f0b47b00001790bda3",
      "name": "Movie Posters",
      "description": "Create cinematic movie posters using AI image generation",
      "tags": [
        "start",
        "image",
        "huggingface"
      ]
    },
    {
      "id": "3dc7a22e12f311f0a84600004c6eb2d5",
      "name": "Audio To Spectrogram",
      "description": "Create a spectrogram from an audio file and use creative upscaling to transform it into wall-worthy art.",
      "tags": [
        "audio",
        "multimodal",
        "start",
        "huggingface"
      ]
    },
    {
      "id": "d6d4ffd859da11f094f9000001d6cfc2",
      "name": "Image to Image",
      "description": "",
      "tags": [
        "start",
        "image"
      ]
    },
    {
      "id": "transcribe_audio",
      "name": "Transcribe Audio",
      "description": "Convert speech to text using Whisper model with word-level timestamps",
      "tags": [
        "start",
        "audio",
        "huggingface"
      ]
    },
    {
      "id": "object_detection",
      "name": "Object Detection",
      "description": "Detect objects in an image and visualize the detections",
      "tags": [
        "huggingface",
        "start"
      ]
    },
    {
      "id": "depth_estimation",
      "name": "Depth Estimation",
      "description": "Estimate the depth of an image",
      "tags": [
        "image",
        "huggingface"
      ]
    },
    {
      "id": "add_subtitles_to_video",
      "name": "Add Subtitles To Video",
      "description": "This workflow automatically transcribes speech in videos and adds subtitles. It extracts audio from the input video, uses OpenAI's Whisper model to generate word-level timestamps and transcriptions, and then renders the subtitles back onto the original video. Perfect for creating accessible content, adding captions to social media videos, or transcribing presentations.",
      "tags": [
        "start",
        "video",
        "huggingface"
      ]
    },
    {
      "id": "segmentation",
      "name": "Segmentation",
      "description": "Segment images and visualize the segments",
      "tags": [
        "huggingface",
        "image"
      ]
    },
    {
      "id": "f1d42e6a12fb11f0901100001aeb0d2f",
      "name": "Summarize Audio",
      "description": "Transcribe an audio file and summarize the text.",
      "tags": [
        "audio",
        "start",
        "huggingface"
      ]
    },
    {
      "id": "001b40e05a6d11f0aea400001cbe54c8",
      "name": "Re-Imagine",
      "description": "",
      "tags": [
        "start",
        "image"
      ]
    },
    {
      "id": "8675bdaa388a11f0951800006f96a7c6",
      "name": "Pokemon Maker",
      "description": "",
      "tags": []
    }
  ]
}
{
  "id": "001b40e05a6d11f0aea400001cbe54c8",
  "access": "public",
  "created_at": "2025-07-06T23:54:25.383646",
  "updated_at": "2025-07-06T23:54:25.383770",
  "name": "Re-Imagine",
  "description": "",
  "tags": ["start", "image"],
  "thumbnail": null,
  "thumbnail_url": null,
  "graph": {
    "nodes": [
      {
        "id": "b451eb65-21f1-445a-9669-0baaa356fc4c",
        "parent_id": null,
        "type": "huggingface.image_to_text.ImageToText",
        "data": {
          "max_new_tokens": 1024,
          "model": {
            "type": "hf.image_to_text",
            "repo_id": "Salesforce/blip-image-captioning-base"
          }
        },
        "ui_properties": {
          "position": {
            "x": 606,
            "y": 121
          },
          "zIndex": 0,
          "width": 200,
          "selectable": true
        },
        "dynamic_properties": {}
      },
      {
        "id": "aeb4fc31-0916-46db-a830-c4fdeea1a8ec",
        "parent_id": null,
        "type": "nodetool.constant.Image",
        "data": {
          "value": {
            "uri": "https://cdn.expertphotography.com/wp-content/uploads/2018/12/iconic-photos-leifer.jpg",
            "type": "image"
          }
        },
        "ui_properties": {
          "position": {
            "x": 146,
            "y": 117
          },
          "zIndex": 0,
          "width": 200,
          "selectable": true
        },
        "dynamic_properties": {}
      },
      {
        "id": "5a6cf4a8-baf3-4570-973f-f05098f70668",
        "parent_id": null,
        "type": "nodetool.workflows.base_node.Comment",
        "data": {
          "comment_lexical": {
            "root": {
              "children": [
                {
                  "children": [
                    {
                      "children": [
                        {
                          "detail": 0,
                          "format": 1,
                          "mode": "normal",
                          "style": "",
                          "text": "Image Input",
                          "type": "text",
                          "version": 1
                        },
                        {
                          "detail": 0,
                          "format": 0,
                          "mode": "normal",
                          "style": "",
                          "text": " - An anime-style landscape image showing a path leading to a castle on a hill is loaded as the starting point for the workflow",
                          "type": "text",
                          "version": 1
                        }
                      ],
                      "direction": "ltr",
                      "format": "",
                      "indent": 0,
                      "type": "listitem",
                      "version": 1,
                      "value": 1
                    },
                    {
                      "children": [
                        {
                          "detail": 0,
                          "format": 1,
                          "mode": "normal",
                          "style": "",
                          "text": "Image-to-Text Conversion",
                          "type": "text",
                          "version": 1
                        },
                        {
                          "detail": 0,
                          "format": 0,
                          "mode": "normal",
                          "style": "",
                          "text": " - The image is processed through a vision model (nipconnect/vit-gpt2-image-captioning) to generate a text description of the visual content",
                          "type": "text",
                          "version": 1
                        }
                      ],
                      "direction": "ltr",
                      "format": "",
                      "indent": 0,
                      "type": "listitem",
                      "version": 1,
                      "value": 2
                    },
                    {
                      "children": [
                        {
                          "detail": 0,
                          "format": 1,
                          "mode": "normal",
                          "style": "",
                          "text": "Text-to-Image Generation",
                          "type": "text",
                          "version": 1
                        },
                        {
                          "detail": 0,
                          "format": 0,
                          "mode": "normal",
                          "style": "",
                          "text": " - The generated text description is fed into a text-to-image model (dreamlike-art/dreamlike-photoreal-2.0) with specific parameters like 50 inference steps, guidance scale of 7.5, and 512x512 resolution",
                          "type": "text",
                          "version": 1
                        }
                      ],
                      "direction": "ltr",
                      "format": "",
                      "indent": 0,
                      "type": "listitem",
                      "version": 1,
                      "value": 3
                    },
                    {
                      "children": [
                        {
                          "detail": 0,
                          "format": 1,
                          "mode": "normal",
                          "style": "",
                          "text": "Preview Output",
                          "type": "text",
                          "version": 1
                        },
                        {
                          "detail": 0,
                          "format": 0,
                          "mode": "normal",
                          "style": "",
                          "text": " - The final generated image is displayed in a preview panel, completing the image-to-text-to-image transformation pipeline",
                          "type": "text",
                          "version": 1
                        }
                      ],
                      "direction": "ltr",
                      "format": "",
                      "indent": 0,
                      "type": "listitem",
                      "version": 1,
                      "value": 4
                    }
                  ],
                  "direction": "ltr",
                  "format": "",
                  "indent": 0,
                  "type": "list",
                  "version": 1,
                  "listType": "bullet",
                  "start": 1,
                  "tag": "ul"
                }
              ],
              "direction": "ltr",
              "format": "",
              "indent": 0,
              "type": "root",
              "version": 1,
              "textFormat": 1
            }
          }
        },
        "ui_properties": {
          "position": {
            "x": 135,
            "y": -184
          },
          "zIndex": 0,
          "width": 1011,
          "height": 162,
          "selectable": true
        },
        "dynamic_properties": {}
      },
      {
        "id": "70787364-169b-4945-baa7-b6c1303f0025",
        "parent_id": null,
        "type": "nodetool.image.Fit",
        "data": {
          "width": 512,
          "height": 512
        },
        "ui_properties": {
          "position": {
            "x": 376,
            "y": 144
          },
          "zIndex": 0,
          "width": 200,
          "selectable": true
        },
        "dynamic_properties": {}
      },
      {
        "id": "c02fb623-375d-47a7-adc0-4bb6b8a63ae3",
        "parent_id": null,
        "type": "nodetool.workflows.base_node.Preview",
        "data": {
          "name": "image_output"
        },
        "ui_properties": {
          "position": {
            "x": 1066,
            "y": 50
          },
          "zIndex": 0,
          "width": 334,
          "height": 367,
          "selectable": true
        },
        "dynamic_properties": {}
      },
      {
        "id": "f4d3f67b-9017-4e76-85ac-566ec2d41f94",
        "parent_id": null,
        "type": "huggingface.image_to_image.StableDiffusionImg2Img",
        "data": {
          "model": {
            "type": "hf.stable_diffusion",
            "repo_id": "SG161222/Realistic_Vision_V5.1_noVAE",
            "path": "Realistic_Vision_V5.1_fp16-no-ema.safetensors"
          },
          "negative_prompt": "",
          "seed": -1,
          "num_inference_steps": 25,
          "guidance_scale": 7.5,
          "scheduler": "EulerDiscreteScheduler",
          "loras": [],
          "ip_adapter_model": {},
          "ip_adapter_image": {},
          "ip_adapter_scale": 0.5,
          "pag_scale": 3,
          "detail_level": 0.5,
          "enable_tiling": false,
          "enable_cpu_offload": false,
          "upscaler": "None",
          "strength": 0.8
        },
        "ui_properties": {
          "position": {
            "x": 836,
            "y": 72
          },
          "zIndex": 0,
          "width": 200,
          "selectable": true
        },
        "dynamic_properties": {}
      }
    ],
    "edges": [
      {
        "id": "c4c3d3a1-4215-4454-8a5b-258435755937",
        "source": "70787364-169b-4945-baa7-b6c1303f0025",
        "sourceHandle": "output",
        "target": "b451eb65-21f1-445a-9669-0baaa356fc4c",
        "targetHandle": "image",
        "ui_properties": {
          "className": "image"
        }
      },
      {
        "id": "20978aa8-6be8-4fd6-bca0-d85c327dec5c",
        "source": "aeb4fc31-0916-46db-a830-c4fdeea1a8ec",
        "sourceHandle": "output",
        "target": "70787364-169b-4945-baa7-b6c1303f0025",
        "targetHandle": "image",
        "ui_properties": {
          "className": "image"
        }
      },
      {
        "id": "a9d80a3e-44c8-4ffa-b6a0-2bd5248e4404",
        "source": "b451eb65-21f1-445a-9669-0baaa356fc4c",
        "sourceHandle": "output",
        "target": "f4d3f67b-9017-4e76-85ac-566ec2d41f94",
        "targetHandle": "prompt",
        "ui_properties": {
          "className": "str"
        }
      },
      {
        "id": "ba742383-5930-49ca-9442-3217d2541340",
        "source": "f4d3f67b-9017-4e76-85ac-566ec2d41f94",
        "sourceHandle": "output",
        "target": "c02fb623-375d-47a7-adc0-4bb6b8a63ae3",
        "targetHandle": "value",
        "ui_properties": {
          "className": "image"
        }
      },
      {
        "id": "43cc3f27-2a61-4b08-815b-7de0bf2bfa7c",
        "source": "70787364-169b-4945-baa7-b6c1303f0025",
        "sourceHandle": "output",
        "target": "f4d3f67b-9017-4e76-85ac-566ec2d41f94",
        "targetHandle": "init_image",
        "ui_properties": {
          "className": "image"
        }
      }
    ]
  },
  "input_schema": null,
  "output_schema": null,
  "settings": null,
  "package_name": "nodetool-huggingface",
  "path": null,
  "run_mode": null
}
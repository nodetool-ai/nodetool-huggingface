# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.huggingface.image_classification
from nodetool.workflows.base_node import BaseNode


class ImageClassifier(
    SingleOutputGraphNode[dict[str, float]], GraphNode[dict[str, float]]
):
    """

    Classifies images into predefined categories using vision transformer models.
    image, classification, labeling, categorization, computer-vision

    Use cases:
    - Automatically tag and organize photo libraries
    - Detect inappropriate or NSFW content for moderation
    - Classify product images in e-commerce catalogs
    - Identify age, gender, or other attributes in photos
    - Sort images by scene type, object presence, or style
    """

    model: types.HFImageClassification | OutputHandle[types.HFImageClassification] = (
        connect_field(
            default=types.HFImageClassification(
                type="hf.image_classification",
                repo_id="",
                path=None,
                variant=None,
                allow_patterns=None,
                ignore_patterns=None,
            ),
            description="The image classification model. ViT and ResNet models offer general classification; specialized models exist for NSFW detection, age estimation, etc.",
        )
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The image to classify. Supports common formats like JPEG, PNG, WebP.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.huggingface.image_classification.ImageClassifier

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.huggingface.image_classification
from nodetool.workflows.base_node import BaseNode


class ZeroShotImageClassifier(
    SingleOutputGraphNode[dict[str, float]], GraphNode[dict[str, float]]
):
    """

    Classifies images into custom categories without requiring task-specific training data.
    image, classification, labeling, categorization, zero-shot, flexible

    Use cases:
    - Categorize images with custom, user-defined labels on the fly
    - Quickly prototype image classification systems without training
    - Identify objects or scenes without predefined model categories
    - Build flexible image tagging workflows with dynamic categories
    - Test hypotheses about image content using natural language labels
    """

    model: (
        types.HFZeroShotImageClassification
        | OutputHandle[types.HFZeroShotImageClassification]
    ) = connect_field(
        default=types.HFZeroShotImageClassification(
            type="hf.zero_shot_image_classification",
            repo_id="",
            path=None,
            variant=None,
            allow_patterns=None,
            ignore_patterns=None,
        ),
        description="The zero-shot classification model. CLIP-based models (OpenAI, LAION) enable flexible label matching using vision-language understanding.",
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The image to classify. Supports common formats like JPEG, PNG, WebP.",
    )
    candidate_labels: str | OutputHandle[str] = connect_field(
        default="",
        description="Comma-separated list of labels to classify against (e.g., 'cat,dog,bird,fish'). Use descriptive labels for better results.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.huggingface.image_classification.ZeroShotImageClassifier

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()

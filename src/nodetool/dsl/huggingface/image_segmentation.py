# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.huggingface.image_segmentation
from nodetool.workflows.base_node import BaseNode


class FindSegment(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

    Extracts a specific segment mask by label from a list of segmentation results.
    image, segmentation, object-detection, mask, filter

    Use cases:
    - Extract a specific object mask (e.g., 'person', 'car') from segmentation output
    - Filter segmentation results to focus on a single category
    - Isolate regions for further processing or compositing
    """

    segments: (
        list[types.ImageSegmentationResult]
        | OutputHandle[list[types.ImageSegmentationResult]]
    ) = connect_field(
        default=[],
        description="List of segmentation results from Segmentation or SAM2Segmentation nodes.",
    )
    segment_label: str | OutputHandle[str] = connect_field(
        default="",
        description="The exact label name to find (e.g., 'person', 'wall', 'sky'). Must match a label in the segments list.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.huggingface.image_segmentation.FindSegment

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.huggingface.image_segmentation
from nodetool.workflows.base_node import BaseNode


class SAM2Segmentation(
    SingleOutputGraphNode[list[types.ImageRef]], GraphNode[list[types.ImageRef]]
):
    """

    Performs automatic instance segmentation using Meta's Segment Anything Model 2 (SAM2).
    image, segmentation, object-detection, scene-parsing, mask, SAM2

    Use cases:
    - Automatically segment all distinct objects in an image
    - Generate high-quality masks without manual prompts
    - Extract individual objects for image editing workflows
    - Build interactive segmentation applications
    - Enable precise object selection in creative tools
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The image to segment. SAM2 automatically identifies and masks all distinct objects.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.huggingface.image_segmentation.SAM2Segmentation

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.huggingface.image_segmentation
from nodetool.workflows.base_node import BaseNode


class Segmentation(
    SingleOutputGraphNode[list[types.ImageSegmentationResult]],
    GraphNode[list[types.ImageSegmentationResult]],
):
    """

    Performs semantic segmentation on images, identifying and labeling different regions with pixel-level precision.
    image, segmentation, object-detection, scene-parsing, computer-vision

    Use cases:
    - Segment and identify objects, people, or regions in images
    - Extract clothing items or body parts for fashion applications
    - Parse indoor/outdoor scenes into semantic components
    - Enable background removal or replacement in photos
    - Build autonomous driving perception systems
    """

    model: types.HFImageSegmentation | OutputHandle[types.HFImageSegmentation] = (
        connect_field(
            default=types.HFImageSegmentation(
                type="hf.image_segmentation",
                repo_id="nvidia/segformer-b3-finetuned-ade-512-512",
                path=None,
                variant=None,
                allow_patterns=None,
                ignore_patterns=None,
            ),
            description="The segmentation model. SegFormer-ADE for general scenes, specialized models for clothing or body parts.",
        )
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The input image to segment. Larger images may require more processing time.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.huggingface.image_segmentation.Segmentation

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.huggingface.image_segmentation
from nodetool.workflows.base_node import BaseNode


class VisualizeSegmentation(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """

    Renders segmentation masks as colored overlays on the original image with labeled regions.
    image, segmentation, visualization, mask, annotation

    Use cases:
    - Visualize and verify segmentation model results
    - Create labeled images for documentation or presentations
    - Compare different segmentation techniques visually
    - Generate annotated images for training data review
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The original image to overlay segmentation masks on.",
    )
    segments: (
        list[types.ImageSegmentationResult]
        | OutputHandle[list[types.ImageSegmentationResult]]
    ) = connect_field(
        default=[],
        description="List of segmentation results to visualize. Each segment gets a distinct color and label.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.huggingface.image_segmentation.VisualizeSegmentation

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()

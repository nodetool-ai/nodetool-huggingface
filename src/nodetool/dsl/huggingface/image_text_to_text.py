# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode


class ImageTextToText(GraphNode):
    """
    Answers questions or follows instructions given both an image and text.
    image, text, visual question answering, multimodal, VLM

    Use cases:
    - Visual question answering with free-form reasoning
    - Zero-shot object localization or structure extraction via instructions
    - OCR-free document understanding when combined with prompts
    - Multi-turn, instruction-following conversations grounded in an image
    """

    model: types.HFImageTextToText | GraphNode | tuple[GraphNode, str] = Field(
        default=types.HFImageTextToText(
            type="hf.image_text_to_text",
            repo_id="",
            path=None,
            variant=None,
            allow_patterns=None,
            ignore_patterns=None,
        ),
        description="The image-text-to-text model to use.",
    )
    image: types.ImageRef | GraphNode | tuple[GraphNode, str] = Field(
        default=types.ImageRef(type="image", uri="", asset_id=None, data=None),
        description="The image to analyze.",
    )
    prompt: str | GraphNode | tuple[GraphNode, str] = Field(
        default="Describe this image.",
        description="Instruction or question for the model about the image.",
    )
    max_new_tokens: int | GraphNode | tuple[GraphNode, str] = Field(
        default=256, description="Maximum number of tokens to generate."
    )

    @classmethod
    def get_node_type(cls):
        return "huggingface.image_text_to_text.ImageTextToText"


class LoadImageTextToTextModel(GraphNode):
    """
    Load a Hugging Face image-text-to-text model/pipeline by repo_id.

    Use cases:
    - Produces a configurable `HFImageTextToText` model reference for downstream nodes
    - Ensures the selected model can be loaded with the "image-text-to-text" task
    """

    repo_id: str | GraphNode | tuple[GraphNode, str] = Field(
        default="",
        description="The model repository ID to use for image-text-to-text generation.",
    )

    @classmethod
    def get_node_type(cls):
        return "huggingface.image_text_to_text.LoadImageTextToTextModel"

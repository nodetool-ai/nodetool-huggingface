# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.huggingface.image_text_to_text
from nodetool.workflows.base_node import BaseNode


class ImageTextToText(SingleOutputGraphNode[str], GraphNode[str]):
    """

    Answers questions or follows instructions given both an image and text.
    image, text, visual question answering, multimodal, VLM

    Use cases:
    - Visual question answering with free-form reasoning
    - Zero-shot object localization or structure extraction via instructions
    - OCR-free document understanding when combined with prompts
    - Multi-turn, instruction-following conversations grounded in an image
    """

    model: types.HFImageTextToText | OutputHandle[types.HFImageTextToText] = (
        connect_field(
            default=types.HFImageTextToText(
                type="hf.image_text_to_text",
                repo_id="",
                path=None,
                variant=None,
                allow_patterns=None,
                ignore_patterns=None,
            ),
            description="The image-text-to-text model to use.",
        )
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(type="image", uri="", asset_id=None, data=None),
        description="The image to analyze.",
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="Describe this image.",
        description="Instruction or question for the model about the image.",
    )
    max_new_tokens: int | OutputHandle[int] = connect_field(
        default=256, description="Maximum number of tokens to generate."
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.huggingface.image_text_to_text.ImageTextToText

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.huggingface.image_text_to_text
from nodetool.workflows.base_node import BaseNode


class LoadImageTextToTextModel(
    SingleOutputGraphNode[types.HFImageTextToText], GraphNode[types.HFImageTextToText]
):
    """

    Load a Hugging Face image-text-to-text model/pipeline by repo_id.

    Use cases:
    - Produces a configurable `HFImageTextToText` model reference for downstream nodes
    - Ensures the selected model can be loaded with the "image-text-to-text" task
    """

    repo_id: str | OutputHandle[str] = connect_field(
        default="",
        description="The model repository ID to use for image-text-to-text generation.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.huggingface.image_text_to_text.LoadImageTextToTextModel

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()

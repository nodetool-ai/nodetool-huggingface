# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.huggingface.token_classification
from nodetool.workflows.base_node import BaseNode


class TokenClassification(
    SingleOutputGraphNode[types.DataframeRef], GraphNode[types.DataframeRef]
):
    """

    Performs token-level classification tasks such as Named Entity Recognition (NER).
    text, token-classification, NER, NLP, entity-extraction

    Use cases:
    - Extract named entities (people, organizations, locations) from text
    - Identify parts of speech in sentences
    - Perform chunking and shallow parsing for text analysis
    - Extract structured information from unstructured documents
    - Build information extraction pipelines for documents
    """

    AggregationStrategy: typing.ClassVar[type] = (
        nodetool.nodes.huggingface.token_classification.TokenClassification.AggregationStrategy
    )

    model: types.HFTokenClassification | OutputHandle[types.HFTokenClassification] = (
        connect_field(
            default=types.HFTokenClassification(
                type="hf.token_classification",
                repo_id="dbmdz/bert-large-cased-finetuned-conll03-english",
                path=None,
                variant=None,
                allow_patterns=["*.bin", "*.json", "**/*.json", "*.safetensors"],
                ignore_patterns=None,
            ),
            description="The token classification model. BERT-large-cased-finetuned-conll03 offers high-quality NER for English text.",
        )
    )
    inputs: str | OutputHandle[str] = connect_field(
        default="", description="The text to extract entities from."
    )
    aggregation_strategy: (
        nodetool.nodes.huggingface.token_classification.TokenClassification.AggregationStrategy
    ) = Field(
        default=nodetool.nodes.huggingface.token_classification.TokenClassification.AggregationStrategy.SIMPLE,
        description="How to combine token predictions into entities: 'simple' merges adjacent tokens; 'first'/'average'/'max' control subword handling.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.huggingface.token_classification.TokenClassification

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()

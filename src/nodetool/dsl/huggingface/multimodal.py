# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.huggingface.multimodal
from nodetool.workflows.base_node import BaseNode


class ImageToText(SingleOutputGraphNode[str], GraphNode[str]):
    """

    Generates text descriptions from images.
    image, text, captioning, vision-language

    Use cases:
    - Automatic image captioning
    - Assisting visually impaired users
    - Enhancing image search capabilities
    - Generating alt text for web images
    """

    model: types.HFImageToText | OutputHandle[types.HFImageToText] = connect_field(
        default=types.HFImageToText(
            type="hf.image_to_text",
            repo_id="",
            path=None,
            variant=None,
            allow_patterns=None,
            ignore_patterns=None,
        ),
        description="The model ID to use for image-to-text generation",
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(type="image", uri="", asset_id=None, data=None),
        description="The image to generate text from",
    )
    max_new_tokens: int | OutputHandle[int] = connect_field(
        default=50, description="The maximum number of tokens to generate"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.huggingface.multimodal.ImageToText

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.huggingface.multimodal
from nodetool.workflows.base_node import BaseNode


class VisualQuestionAnswering(SingleOutputGraphNode[str], GraphNode[str]):
    """

    Answers questions about images.
    image, text, question answering, multimodal

    Use cases:
    - Image content analysis
    - Automated image captioning
    - Visual information retrieval
    - Accessibility tools for visually impaired users
    """

    model: (
        types.HFVisualQuestionAnswering | OutputHandle[types.HFVisualQuestionAnswering]
    ) = connect_field(
        default=types.HFVisualQuestionAnswering(
            type="hf.visual_question_answering",
            repo_id="",
            path=None,
            variant=None,
            allow_patterns=None,
            ignore_patterns=None,
        ),
        description="The model ID to use for visual question answering",
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(type="image", uri="", asset_id=None, data=None),
        description="The image to analyze",
    )
    question: str | OutputHandle[str] = connect_field(
        default="", description="The question to be answered about the image"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.huggingface.multimodal.VisualQuestionAnswering

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()

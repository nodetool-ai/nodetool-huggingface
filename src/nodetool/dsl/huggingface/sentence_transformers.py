# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.huggingface.sentence_transformers
from nodetool.workflows.base_node import BaseNode


class SplitSentences(
    GraphNode[
        nodetool.nodes.huggingface.sentence_transformers.SplitSentences.OutputType
    ]
):
    """

    Splits text into sentences using LangChain's SentenceTransformersTokenTextSplitter.
    sentences, split, nlp

    Use cases:
    - Natural sentence-based text splitting
    - Creating semantically meaningful chunks
    - Processing text for sentence-level analysis
    """

    document: types.DocumentRef | OutputHandle[types.DocumentRef] = connect_field(
        default=types.DocumentRef(
            type="document", uri="", asset_id=None, data=None, metadata=None
        ),
        description=None,
    )
    chunk_size: int | OutputHandle[int] = connect_field(
        default=40, description="Maximum number of tokens per chunk"
    )
    chunk_overlap: int | OutputHandle[int] = connect_field(
        default=5, description="Number of tokens to overlap between chunks"
    )

    @property
    def out(self) -> "SplitSentencesOutputs":
        return SplitSentencesOutputs(self)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.huggingface.sentence_transformers.SplitSentences

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


class SplitSentencesOutputs(OutputsProxy):
    @property
    def text(self) -> OutputHandle[str]:
        return typing.cast(OutputHandle[str], self["text"])

    @property
    def source_id(self) -> OutputHandle[str]:
        return typing.cast(OutputHandle[str], self["source_id"])

    @property
    def start_index(self) -> OutputHandle[int]:
        return typing.cast(OutputHandle[int], self["start_index"])
